
@article{bocci_placing_nodate,
	title = {Placing {FaaS} in the Fog, Securely},
	abstract = {Placing {FaaS} applications onto Fog infrastructures is an open problem presenting various challenges. It requires considering hardware and software requirements of single functions as well as Quality of Service requirements of the overall application. In this article, we propose a declarative methodology to address the placement of {FaaS} applications onto Fog infrastructures, supported by a running prototype. Our methodology considers hardware and software requirements, and latency constraints on functionfunction and function-service interactions. Particular attention is given to information flow security constraints and trust relations among the involved stakeholders, to rank eligible output placements. A lifelike motivating example from augmented reality is used to showcase the prototype.},
	pages = {14},
	author = {Bocci, Alessandro and Forti, Stefano and Ferrari, Gian-Luigi and Brogi, Antonio},
	langid = {english},
	file = {Bocci et al. - Placing FaaS in the Fog, Securely.pdf:/home/volodia/Zotero/storage/ZUJBPD36/Bocci et al. - Placing FaaS in the Fog, Securely.pdf:application/pdf},
}

@article{ahmed_fog_2019,
	title = {Fog Computing Applications: Taxonomy and Requirements},
	url = {http://arxiv.org/abs/1907.11621},
	shorttitle = {Fog Computing Applications},
	abstract = {Fog computing was designed to support the specific needs of latency-critical applications such as augmented reality, and {IoT} applications which produce massive volumes of data that are impractical to send to faraway cloud data centers for analysis. However this also created new opportunities for a wider range of applications which in turn impose their own requirements on future fog computing platforms. This article presents a study of a representative set of 30 fog computing applications and the requirements that a general-purpose fog computing platform should support.},
	journaltitle = {{arXiv}:1907.11621 [cs]},
	author = {Ahmed, Arif and Arkian, {HamidReza} and Battulga, Davaadorj and Fahs, Ali J. and Farhadi, Mozhdeh and Giouroukis, Dimitrios and Gougeon, Adrien and Gutierrez, Felipe Oliveira and Pierre, Guillaume and Souza Jr, Paulo R. and Tamiru, Mulugeta Ayalew and Wu, Li},
	urldate = {2022-02-08},
	date = {2019-07-26},
	eprinttype = {arxiv},
	eprint = {1907.11621},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv Fulltext PDF:/home/volodia/Zotero/storage/UDEUAY8V/Ahmed et al. - 2019 - Fog Computing Applications Taxonomy and Requireme.pdf:application/pdf;arXiv.org Snapshot:/home/volodia/Zotero/storage/J6UM2AEC/1907.html:text/html},
}

@inproceedings{hu_live_2017,
	location = {New York, {NY}, {USA}},
	title = {Live Synthesis of Vehicle-Sourced Data Over 4G {LTE}},
	isbn = {978-1-4503-5162-1},
	url = {https://doi.org/10.1145/3127540.3127543},
	doi = {10.1145/3127540.3127543},
	series = {{MSWiM} '17},
	abstract = {Accurate, up-to-date maps of transient traffic and hazards are invaluable to drivers, city managers, and the emerging class of self-driving vehicles. We present {LiveMap}, a scalable, automated system for acquiring, curating, and disseminating detailed, continually-updated road conditions in a region. {LiveMap} leverages in-vehicle cameras, sensors, and processors to crowd-source hazard detection without human intervention. We build a real-time simulation framework that allows a mix of real and simulated components to be tested together at scale. We demonstrate that {LiveMap} can work well at city scales within the limits of today's cellular network bandwidth. We also show the feasibility of accurate, in-vehicle, computer-vision-based hazard detection.},
	pages = {161--170},
	booktitle = {Proceedings of the 20th {ACM} International Conference on Modelling, Analysis and Simulation of Wireless and Mobile Systems},
	publisher = {Association for Computing Machinery},
	author = {Hu, Wenlu and Feng, Ziqiang and Chen, Zhuo and Harkes, Jan and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
	urldate = {2022-02-08},
	date = {2017-11-21},
	keywords = {automotive systems, cloud computing, cloudlet, driverless cars, edge computing, maps, situational awareness, vehicular systems},
	file = {Full Text PDF:/home/volodia/Zotero/storage/UDIMPW48/Hu et al. - 2017 - Live Synthesis of Vehicle-Sourced Data Over 4G LTE.pdf:application/pdf},
}

@article{hu_survey_2017,
	title = {Survey on fog computing: architecture, key technologies, applications and open issues},
	volume = {98},
	issn = {1084-8045},
	url = {https://www.sciencedirect.com/science/article/pii/S1084804517302953},
	doi = {10.1016/j.jnca.2017.09.002},
	shorttitle = {Survey on fog computing},
	abstract = {The emergence of Internet of Things ({IoT}) has enabled the interconnection and intercommunication among massive ubiquitous things, which caused an unprecedented generation of huge and heterogeneous amount of data, known as data explosions. On the other hand, although that cloud computing has served as an efficient way to process and store these data, however, challenges, such as the increasing demands of real time or latency-sensitive applications and the limitation of network bandwidth, still cannot be solved by using only cloud computing. Therefore, a new computing paradigm, known as fog computing, has been proposed as a complement to the cloud solution. Fog computing extends the cloud services to the edge of network, and makes computation, communication and storage closer to edge devices and end-users, which aims to enhance low-latency, mobility, network bandwidth, security and privacy. In this paper, we will overview and summarize fog computing model architecture, key technologies, applications, challenges and open issues. Firstly, we will present the hierarchical architecture of fog computing and its characteristics, and compare it with cloud computing and edge computing to emphasize the similarities and differences. Then, the key technologies like computing, communication and storage technologies, naming, resource management, security and privacy protection are introduced to present how to support its deployment and application in a detailed manner. Several application cases like health care, augmented reality, brain machine interface and gaming, smart environments and vehicular fog computing are also presented to further explain fog computing application scenarios. Finally, based on the observation, we propose some challenges and open issues which are worth further in-depth study and research in fog computing development.},
	pages = {27--42},
	journaltitle = {Journal of Network and Computer Applications},
	shortjournal = {Journal of Network and Computer Applications},
	author = {Hu, Pengfei and Dhelim, Sahraoui and Ning, Huansheng and Qiu, Tie},
	urldate = {2022-02-09},
	date = {2017-11-15},
	langid = {english},
	keywords = {Application, Architecture, Cloud computing, Edge computing, Fog computing, Internet of Things({IoT})},
	file = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/QYXKR4MG/S1084804517302953.html:text/html},
}

@software{smartfog_fogflow_2022,
	title = {{FogFlow}},
	rights = {{BSD}-3-Clause},
	url = {https://github.com/smartfog/fogflow},
	abstract = {{FogFlow} is a standard-based {IoT} fog computing framework that supports serverless computing and edge computing with advanced programming models},
	author = {smartfog},
	urldate = {2022-02-09},
	date = {2022-01-24},
	note = {original-date: 2017-11-14T22:30:18Z},
	keywords = {edge-computing, fiware, fog-computing, function-as-a-service, intent-based, iot, ngsi, ngsi-ld, programming-model, serverless-computing, serverless-functions},
}

@software{noauthor_healthfog_2022,
	title = {{HealthFog}},
	rights = {{GPL}-3.0},
	url = {https://github.com/Cloudslab/HealthFog},
	abstract = {[{FGCS}'20] An ensemble deep learning based smart healthcare system for automatic diagnosis of heart diseases in integrated {IoT} and Fog computing environments},
	publisher = {The Cloud Computing and Distributed Systems ({CLOUDS}) Laboratory},
	urldate = {2022-02-09},
	date = {2022-01-17},
	note = {original-date: 2019-06-07T04:38:25Z},
	keywords = {fog-computing, deep-learning, fogbus, healthcare},
}

@online{noauthor_ewall_nodate,
	title = {{eWALL} Project {EU}},
	url = {https://github.com/ewallprojecteu},
	abstract = {{eWALL} is the outcome of a {EC}-funded project that contributes to the prolongation of independent living of various patients types and senior citizens. - {eWALL} Project {EU}},
	titleaddon = {{GitHub}},
	urldate = {2022-02-09},
	langid = {english},
	keywords = {bancale},
	file = {Snapshot:/home/volodia/Zotero/storage/F8V6ZR4H/ewallprojecteu.html:text/html},
}

@software{woods_sisyphus_2018,
	title = {Sisyphus :  A Fog of Serverless Functions},
	rights = {Apache-2.0},
	url = {https://github.com/woodsmc/sisyphus},
	shorttitle = {Sisyphus},
	abstract = {Research framework for a Fog of {FaaS}},
	author = {Woods, Chris},
	urldate = {2022-02-09},
	date = {2018-05-09},
	note = {original-date: 2018-03-22T00:57:03Z},
	keywords = {idea},
}

@article{cicconetti_faas_2021,
	title = {{FaaS} Execution Models for Edge Applications},
	url = {http://arxiv.org/abs/2111.06595},
	abstract = {In this paper, we address the problem of supporting stateful workﬂows following a Function-as-a-Service ({FaaS}) model in edge networks. In particular we focus on the problem of data transfer, which can be a performance bottleneck due to the limited speed of communication links in some edge scenarios and we propose three different schemes: a pure {FaaS} implementation, {StateProp}, i.e., propagation of the application state throughout the entire chain of functions, and {StateLocal}, i.e., a solution where the state is kept local to the workers that run functions and retrieved only as needed. We then extend the proposed schemes to the more general case of applications modeled as Directed Acyclic Graphs ({DAGs}), which cover a broad range of practical applications, e.g., in the Internet of Things ({IoT}) area. Our contribution is validated via a prototype implementation. Experiments in emulated conditions show that applying the data locality principle reduces signiﬁcantly the volume of network trafﬁc required and improves the end-to-end delay performance, especially with local caching on edge nodes and low link speeds.},
	journaltitle = {{arXiv}:2111.06595 [cs]},
	author = {Cicconetti, Claudio and Conti, Marco and Passarella, Andrea},
	urldate = {2022-02-09},
	date = {2021-11-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2111.06595},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file = {Cicconetti et al. - 2021 - FaaS Execution Models for Edge Applications.pdf:/home/volodia/Zotero/storage/W5M7QWRG/Cicconetti et al. - 2021 - FaaS Execution Models for Edge Applications.pdf:application/pdf},
}

@software{cicconetti_ccicconettiserverlessonedge_2022,
	title = {ccicconetti/serverlessonedge},
	rights = {{MIT}},
	url = {https://github.com/ccicconetti/serverlessonedge},
	abstract = {Decentralized framework for the distribution of lambda functions to multiple serverless platforms},
	author = {Cicconetti, Claudio},
	urldate = {2022-02-09},
	date = {2022-01-30},
	note = {original-date: 2020-02-26T10:13:42Z},
	keywords = {edge-computing, distributed-computing, serverless-framework},
}

@online{noauthor_how_nodate,
	title = {How the Actor Model Meets the Needs of Modern, Distributed Systems • Akka Documentation},
	url = {https://doc.akka.io/docs/akka/current/typed/guide/actors-intro.html?language=scala},
	urldate = {2022-02-09},
}

@online{noauthor_does_nodate,
	title = {Does it make sense to use actor/agent oriented programming in Function as a Service environment?},
	url = {https://stackoverflow.com/questions/46878548/does-it-make-sense-to-use-actor-agent-oriented-programming-in-function-as-a-serv},
	titleaddon = {Stack Overflow},
	urldate = {2022-02-09},
	file = {Snapshot:/home/volodia/Zotero/storage/U6EU2RBD/does-it-make-sense-to-use-actor-agent-oriented-programming-in-function-as-a-serv.html:text/html},
}

@software{bermbach_faas4fogsim_2021,
	title = {{FaaS}4FogSim},
	rights = {{GPL}-3.0},
	url = {https://github.com/dbermbach/faas4fogsim},
	author = {Bermbach, David},
	urldate = {2022-02-09},
	date = {2021-05-12},
	note = {original-date: 2019-07-30T10:21:29Z},
}

@online{noauthor_developers_2018,
	title = {Developers Catalogue - {FIWARE}},
	url = {https://www.fiware.org/developers/catalogue/},
	abstract = {{FIWARE} brings a curated framework of open source software platform components which can be assembled together and with other third-party components to build},
	urldate = {2022-02-09},
	date = {2018-05-07},
	langid = {american},
	file = {Snapshot:/home/volodia/Zotero/storage/647W8XBD/catalogue.html:text/html},
}

@article{araujo_performance_2019,
	title = {Performance evaluation of {FIWARE}: A cloud-based {IoT} platform for smart cities},
	volume = {132},
	issn = {0743-7315},
	url = {https://www.sciencedirect.com/science/article/pii/S0743731519300164},
	doi = {10.1016/j.jpdc.2018.12.010},
	shorttitle = {Performance evaluation of {FIWARE}},
	abstract = {As the Internet of Things ({IoT}) becomes a reality, millions of devices will be connected to {IoT} platforms in smart cities. These devices will cater to several areas within a smart city such as healthcare, logistics, and transportation. These devices are expected to generate significant amounts of data requests at high data rates, therefore, necessitating the performance benchmarking of {IoT} platforms to ascertain whether they can efficiently handle such devices. In this article, we present our results gathered from extensive performance evaluation of the cloud-based {IoT} platform, {FIWARE}. In particular, to study {FIWARE}’s performance, we developed a testbed and generated {CoAP} and {MQTT} data to emulate large-scale {IoT} deployments, crucial for future smart cities. We performed extensive tests and studied {FIWARE}’s performance regarding vertical and horizontal scalability. We present bottlenecks and limitations regarding {FIWARE} components and their cloud deployment. Finally, we discuss cost-efficient {FIWARE} deployment strategies that can be extremely beneficial to stakeholders aiming to deploy {FIWARE} as an {IoT} platform for smart cities.},
	pages = {250--261},
	journaltitle = {Journal of Parallel and Distributed Computing},
	shortjournal = {Journal of Parallel and Distributed Computing},
	author = {Araujo, Victor and Mitra, Karan and Saguna, Saguna and Åhlund, Christer},
	urldate = {2022-02-09},
	date = {2019-10-01},
	langid = {english},
	keywords = {Cloud computing, Benchmarking, Internet of things, Middleware, Quality of service, Smart cities},
	file = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/LJEI5WI3/S0743731519300164.html:text/html},
}

@online{noauthor_new_nodate,
	title = {A New Era for Cities with Fog Computing},
	url = {https://ieeexplore.ieee.org/abstract/document/7867722/},
	abstract = {In this article, the authors dissect the technical challenges that cities face when implementing smart city plans and outlines the design principles and lessons learned after they carried out a flagship initiative on fog computing in Barcelona. In particular, they analyze what they call the Quadruple Silo ({QS}) problem -- that is, four categories of silos that cities confront after deploying commercially available solutions. Those silo categories are: physical (hardware) silos, data silos, and service management silos, and the implications of the three silos in administrative silos. The authors show how their converged cloud/fog paradigm not only helps solve the {QS} problem, but also meets the requirements of a growing number of decentralized services -- an area in which traditional cloud models fall short. The article exposes cases in which fog computing is a must, and shows that the reasons for deploying fog are centered much more on operational requirements than on performance issues related to the cloud.},
	urldate = {2022-02-09},
	langid = {american},
	file = {Snapshot:/home/volodia/Zotero/storage/3CWXGHKP/7867722.html:text/html},
}

@online{noauthor_smartfog_nodate,
	title = {smartfog - Overview},
	url = {https://github.com/smartfog},
	abstract = {smartfog has 7 repositories available. Follow their code on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2022-02-09},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/CYXKE5AG/smartfog.html:text/html},
}

@article{cheng_fogflow_2018,
	title = {{FogFlow}: Easy Programming of {IoT} Services Over Cloud and Edges for Smart Cities},
	volume = {5},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2017.2747214},
	shorttitle = {{FogFlow}},
	abstract = {Smart city infrastructure is forming a large scale Internet of Things ({IoT}) system with widely deployed {IoT} devices, such as sensors and actuators that generate a huge volume of data. Given this large scale and geo-distributed nature of such {IoT} systems, fog computing has been considered as an affordable and sustainable computing paradigm to enable smart city {IoT} services. However, it is still a major challenge for developers to program their services to leverage benefits of fog computing. Developers have to figure out many details, such as how to dynamically configure and manage data processing tasks over cloud and edges and how to optimize task allocation for minimal latency and bandwidth consumption. In addition, most of the existing fog computing frameworks either lack service programming models or define a programming model only based on their own private data model and interfaces; therefore, as a smart city platform, they are quite limited in terms of openness and interoperability. To tackle these problems, we propose a standard-based approach to design and implement a new fog computing-based framework, namely {FogFlow}, for {IoT} smart city platforms. {FogFlow}’s programming model allows {IoT} service developers to program elastic {IoT} services easily over cloud and edges. Moreover, it supports standard interfaces to share and reuse contextual data across services. To showcase how smart city use cases can be realized with {FogFlow}, we describe three use cases and implement an example application for anomaly detection of energy consumption in smart cities. We also analyze {FogFlow}’s performance based on microbenchmarking results for message propagation latency, throughput, and scalability.},
	pages = {696--707},
	number = {2},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Cheng, Bin and Solmaz, Gürkan and Cirillo, Flavio and Kovacs, Ernö and Terasawa, Kazuyuki and Kitazawa, Atsushi},
	date = {2018-04},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Cloud computing, Edge computing, Smart cities, Computational modeling, Data models, Internet of Things ({IoT}), Logic gates, parallel programming, Programming},
	file = {Cheng et al_2018_FogFlow.pdf:/home/volodia/Zotero/storage/XWK3PRQ6/Cheng et al_2018_FogFlow.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/S2VFG65M/8022859.html:text/html},
}

@article{cheng_fog_2019,
	title = {Fog Function: Serverless Fog Computing for Data Intensive {IoT} Services},
	url = {http://arxiv.org/abs/1907.08278},
	shorttitle = {Fog Function},
	abstract = {Fog computing can support {IoT} services with fast response time and low bandwidth usage by moving computation from the cloud to edge devices. However, existing fog computing frameworks have limited ﬂexibility to support dynamic service composition with a data-oriented approach. Functionas-a-Service ({FaaS}) is a promising programming model for fog computing to enhance ﬂexibility, but the current event- or topic-based design of function triggering and the separation of data management and function execution result in inefﬁciency for data-intensive {IoT} services. To achieve both ﬂexibility and efﬁciency, we propose a data-centric programming model called Fog Function and also introduce its underlying orchestration mechanism that leverages three types of contexts: data context, system context, and usage context. Moreover, we showcase a concrete use case for smart parking where Fog Function allows service developers to easily model their service logic with reduced learning efforts compared to a static service topology. Our performance evaluation results show that the Fog Function can be scaled to hundreds of fog nodes. Fog Function can improve system efﬁciency by saving 95\% of the internal data trafﬁc over cloud function and it can reduce service latency by 30\% over edge function.},
	journaltitle = {{arXiv}:1907.08278 [cs]},
	author = {Cheng, Bin and Fürst, Jonathan and Solmaz, Gurkan and Sanada, Takuya},
	urldate = {2022-02-09},
	date = {2019-07-18},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.08278},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Cheng et al. - 2019 - Fog Function Serverless Fog Computing for Data In.pdf:/home/volodia/Zotero/storage/CUAVLX92/Cheng et al. - 2019 - Fog Function Serverless Fog Computing for Data In.pdf:application/pdf},
}

@article{hu_survey_2017-1,
	title = {Survey on fog computing: architecture, key technologies, applications and open issues},
	volume = {98},
	issn = {1084-8045},
	url = {https://www.sciencedirect.com/science/article/pii/S1084804517302953},
	doi = {10.1016/j.jnca.2017.09.002},
	shorttitle = {Survey on fog computing},
	abstract = {The emergence of Internet of Things ({IoT}) has enabled the interconnection and intercommunication among massive ubiquitous things, which caused an unprecedented generation of huge and heterogeneous amount of data, known as data explosions. On the other hand, although that cloud computing has served as an efficient way to process and store these data, however, challenges, such as the increasing demands of real time or latency-sensitive applications and the limitation of network bandwidth, still cannot be solved by using only cloud computing. Therefore, a new computing paradigm, known as fog computing, has been proposed as a complement to the cloud solution. Fog computing extends the cloud services to the edge of network, and makes computation, communication and storage closer to edge devices and end-users, which aims to enhance low-latency, mobility, network bandwidth, security and privacy. In this paper, we will overview and summarize fog computing model architecture, key technologies, applications, challenges and open issues. Firstly, we will present the hierarchical architecture of fog computing and its characteristics, and compare it with cloud computing and edge computing to emphasize the similarities and differences. Then, the key technologies like computing, communication and storage technologies, naming, resource management, security and privacy protection are introduced to present how to support its deployment and application in a detailed manner. Several application cases like health care, augmented reality, brain machine interface and gaming, smart environments and vehicular fog computing are also presented to further explain fog computing application scenarios. Finally, based on the observation, we propose some challenges and open issues which are worth further in-depth study and research in fog computing development.},
	pages = {27--42},
	journaltitle = {Journal of Network and Computer Applications},
	shortjournal = {Journal of Network and Computer Applications},
	author = {Hu, Pengfei and Dhelim, Sahraoui and Ning, Huansheng and Qiu, Tie},
	urldate = {2022-02-09},
	date = {2017-11-15},
	langid = {english},
	keywords = {Application, Architecture, Cloud computing, Edge computing, Fog computing, Internet of Things({IoT})},
	file = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/Q8UDNSIN/S1084804517302953.html:text/html},
}

@software{noauthor_yomo_2022,
	title = {{YoMo}},
	rights = {Apache-2.0},
	url = {https://github.com/yomorun/yomo},
	abstract = {🦖 Serverless Streaming Framework for Low-latency Edge Computing applications, running atop {QUIC} protocol, as Metaverse infrastructure, engaging 5G technology.},
	publisher = {{YoMo}},
	urldate = {2022-02-09},
	date = {2022-02-08},
	note = {original-date: 2020-07-01T05:48:28Z},
	keywords = {edge-computing, iot, 5g, distributed-cloud, edge-ai, edge-mesh, functional-reactive-programming, geodistributedsystems, low-latency, metaverse, metaverse-infrastructure, networking, quic, realtime, serverless, stream-processing},
}

@software{noauthor_baetyl_2022,
	title = {{BAETYL} v2},
	rights = {Apache-2.0},
	url = {https://github.com/baetyl/baetyl},
	abstract = {Extend cloud computing, data and service seamlessly to edge devices.},
	publisher = {baetyl},
	urldate = {2022-02-09},
	date = {2022-02-07},
	note = {original-date: 2018-09-11T09:31:22Z},
	keywords = {edge-computing, iot, container, docker, edge, faas, functions-as-a-service, golang, micro-service, ml-in-production, mqtt},
}

@online{noauthor_k3s_nodate,
	title = {K3s: Lightweight Kubernetes},
	url = {https://k3s.io/},
	urldate = {2022-02-09},
	file = {K3s\: Lightweight Kubernetes:/home/volodia/Zotero/storage/WEWA8DQM/k3s.io.html:text/html},
}

@software{noauthor_kubeedge_2022,
	title = {{KubeEdge}},
	rights = {Apache-2.0},
	url = {https://github.com/kubeedge/kubeedge},
	abstract = {Kubernetes Native Edge Computing Framework (project under {CNCF})},
	publisher = {{KubeEdge}},
	urldate = {2022-02-09},
	date = {2022-02-09},
	note = {original-date: 2018-09-28T08:57:49Z},
	keywords = {edge-computing, iot, container, docker, golang, mqtt, cloud-native, cncf, device-management, kubernetes, mosquitto},
}

@article{brzoza-woch_holistic_2015,
	title = {Holistic Approach to Urgent Computing for Flood Decision Support},
	volume = {51},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915012223},
	doi = {10.1016/j.procs.2015.05.414},
	series = {International Conference On Computational Science, {ICCS} 2015},
	abstract = {This paper presents the concept of holistic approach to urgent computing which extends resources management in situation of emergency from computational resources to Data Acquisition and Preprocessing System. The layered structure of this system is presented in detail and its rearrangement in case of emergency is proposed. This process is harmonized with large scale computation using Urgent Service Profile. The proposed approach was validated by practical work performed under {ISMOP} project. Concrete examples of Urgent Service Profile definition have been discussed. Results of preliminary experiments related to energy management and data transmission optimization in case of emergency have been presented.},
	pages = {2387--2396},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Brzoza-Woch, Robert and Konieczny, Marek and Kwolek, Bartosz and Nawrocki, Piotr and Szydło, Tomasz and Zieliński, Krzysztof},
	urldate = {2022-02-09},
	date = {2015-01-01},
	langid = {english},
	keywords = {flood decision support, fog computing, software reconfiguration, telemetry networks, Urgent computing, wireless sensor networks},
	file = {Brzoza-Woch et al_2015_Holistic Approach to Urgent Computing for Flood Decision Support.pdf:/home/volodia/Zotero/storage/FL7B7XB2/Brzoza-Woch et al_2015_Holistic Approach to Urgent Computing for Flood Decision Support.pdf:application/pdf;ScienceDirect Snapshot:/home/volodia/Zotero/storage/C29EHR5X/S1877050915012223.html:text/html},
}

@inproceedings{aazam_e-hamc_2015,
	title = {E-{HAMC}: Leveraging Fog computing for emergency alert service},
	doi = {10.1109/PERCOMW.2015.7134091},
	shorttitle = {E-{HAMC}},
	abstract = {Timeliness is one the most important factors in emergency management. Emergency notification mechanism has to be hassle free and quick, in order to have efficient response for any disaster, health-fix, act of terrorism, etc. In this paper, we present service architecture for emergency alert, using Fog computing. Fog computing brings cloud resources close to the underlying devices and {IoTs}, which makes it ideal for latency sensitive services. Furthermore, Fog is used for offloading resource constrained devices. Our smart phone based service, known as Emergency Help Alert Mobile Cloud (E-{HAMC}) provides a quick way of notifying the relevant emergency dealing department, utilizing the services of Fog for offloading as well as pre-processing purposes. The service sends the location of incident and contacts the appropriate emergency dealing department automatically through already stored contact numbers. The emergency related information is then synchronized automatically from Fog to the Cloud, allowing further analysis and improvement in safety of the people and creates extended portfolio of services for the concerned authorities as well as the users. Performance in most certain scenarios is also evaluated and presented in this study, which shows the applicability of our system and its future prospects.},
	eventtitle = {2015 {IEEE} International Conference on Pervasive Computing and Communication Workshops ({PerCom} Workshops)},
	pages = {518--523},
	booktitle = {2015 {IEEE} International Conference on Pervasive Computing and Communication Workshops ({PerCom} Workshops)},
	author = {Aazam, Mohammad and Huh, Eui-Nam},
	date = {2015-03},
	keywords = {Cloud computing, Fog computing, Accidents, Delays, Edge Computing, emergency alert, Emergency services, M2M, Micro Data Center ({MDC}), mobile cloud computing, Mobile communication, Synchronization, Vehicles},
	file = {Aazam_Huh_2015_E-HAMC.pdf:/home/volodia/Zotero/storage/RKXLSADS/Aazam_Huh_2015_E-HAMC.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/ZI2AFNRR/7134091.html:text/html},
}

@inproceedings{hossain_efficient_2021,
	title = {Efficient Task Offloading for {MEC}-Enabled Vehicular Networks: A Non-Cooperative Game Theoretic Approach},
	doi = {10.1109/ICUFN49451.2021.9528673},
	shorttitle = {Efficient Task Offloading for {MEC}-Enabled Vehicular Networks},
	abstract = {Vehicular Edge Computing ({VEC}) is a new leading technology to enhance the vehicular performance through task offloading where resource-confined vehicles offload their computing task to the vehicular multi-access edge computing ({MEC}) networks in proximity. However, the environment of vehicular task offloading is extremely dynamic and faces some challenges to determine the location of processing the offloaded task. As a result, to achieve optimal performance by using traditional {VEC} system is difficult because in advance we don't know the demand of vehicles. Therefore, a non-cooperative game theory-based efficient task offloading ({NGTO}) scheme is proposed in this study where the offloading decisions are taken either the {MEC} server or remote cloud server through the game-theoretic approach. To reduce the processing latency of the vehicles' computation tasks and assure the maximum utility of each vehicle, we used a distributed best response offloading strategy. Our proposed strategy accommodates its offloading probability to achieve a unique equilibrium under certain conditions. Detailed performance evaluation affirms that our proposed {NGTO} scheme can outperform in all scenarios. It can minimize the response time at almost 41.2 \% and average task failure rate at approximately 56.3\% when compared with a local roadside unit computing ({LRC}) scheme. The reduced response time and task failure rates are approximately 25.2\% and 20.4\%, respectively, when compared with a collaborative ({LRC} with cloud via roadside unit) offloading scheme.},
	eventtitle = {2021 Twelfth International Conference on Ubiquitous and Future Networks ({ICUFN})},
	pages = {11--16},
	booktitle = {2021 Twelfth International Conference on Ubiquitous and Future Networks ({ICUFN})},
	author = {Hossain, Md Delowar and Khanal, Subina and Huh, Eui-Nam},
	date = {2021-08},
	note = {{ISSN}: 2165-8536},
	keywords = {Collaboration, game theory, Games, Performance evaluation, Real-time systems, Servers, Simulation, task of-floading, Time factors, vehicular edge computing, vehicular networks},
	file = {Hossain et al_2021_Efficient Task Offloading for MEC-Enabled Vehicular Networks.pdf:/home/volodia/Zotero/storage/AT67FZHP/Hossain et al_2021_Efficient Task Offloading for MEC-Enabled Vehicular Networks.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/UMLHST8A/9528673.html:text/html},
}

@inproceedings{li_ehopes_2015,
	title = {{EHOPES}: Data-centered Fog platform for smart living},
	doi = {10.1109/ATNAC.2015.7366831},
	shorttitle = {{EHOPES}},
	abstract = {Nowadays, smart environments (e.g., smart home, smart city) are built heavily relying on Cloud computing for the coordination and collaboration among smart objects. Cloud is typically centralized but smart objects are ubiquitously distributed, thus, data transmission latency (i.e., end-to-end delay or response time) between Cloud and smart objects is a critical issue especially to the applications that have strict delay requirements. To address the concern, a new Fog computing paradigm is recently proposed by the industry, while the detailed Fog platform is yet to be developed. The key idea is to bring the computing power from the remote Cloud closer to the users, which further enables real-time interaction and location-based services. In particular, the local processing capability of Fog computing significantly scales down the data volume towards the Cloud, and it in turn has great impacts on the entire Internet. In this paper, a data-centered Fog platform is developed to support smart living together with dataflow analysis. Case studies are also conducted to validate and evaluate the proposed platform.},
	eventtitle = {2015 International Telecommunication Networks and Applications Conference ({ITNAC})},
	pages = {308--313},
	booktitle = {2015 International Telecommunication Networks and Applications Conference ({ITNAC})},
	author = {Li, Jianhua and Jin, Jiong and Yuan, Dong and Palaniswami, Marimuthu and Moessner, Klaus},
	date = {2015-11},
	keywords = {Cloud computing, Real-time systems, Servers, Cloud Computing, Fog Computing, Medical services, Robots, Smart Living},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/99P95UVP/7366831.html:text/html;Li et al_2015_EHOPES.pdf:/home/volodia/Zotero/storage/2LZ5TWYR/Li et al_2015_EHOPES.pdf:application/pdf},
}

@inproceedings{chakraborty_fog_2016,
	title = {Fog Networks in Healthcare Application},
	doi = {10.1109/MASS.2016.065},
	abstract = {Fog computing is a recently proposed computing paradigm that extends Cloud computing and services to the edge of the network. The new features offered by fog computing (e.g., distributed analytics and edge intelligence), if successfully applied for time-sensitive healthcare applications, has great potential to accelerate the discovery of early notification of emergency situations to support smart decision making. While promising, how to design and develop real-world fog computing-based data monitoring system is still an open question. As a first step to answer this question, in this research, we employ a fog-based cloud paradigm for time-sensitive medical applications and also propose to show the practical applicability and significance of such a novel system. The ubiquitous deployment of mobile and sensor devices is creating a new environment, namely the Internet of Things ({IoT}) that enables a wide range of future Internet applications. In this work, we present dynamic Fog, a high level programming model for time-sensitive applications that are geospatially distributed, large-scale, and latency-sensitive. We also analyze our fog model with healthcare data, more specifically with Heartrate data that is one of the most time-sensitive medical data which deals with life and death situations. Our experiments show that our proposed system achieves minimum delay while it also achieves the data accuracy and data consistency which are very important in many applications like medical data.},
	eventtitle = {2016 {IEEE} 13th International Conference on Mobile Ad Hoc and Sensor Systems ({MASS})},
	pages = {386--387},
	booktitle = {2016 {IEEE} 13th International Conference on Mobile Ad Hoc and Sensor Systems ({MASS})},
	author = {Chakraborty, Suryadip and Bhowmick, Satyajit and Talaga, Paul and Agrawal, Dharma P.},
	date = {2016-10},
	note = {{ISSN}: 2155-6814},
	keywords = {Cloud computing, Edge computing, Logic gates, Delays, Mobile communication, Medical services, Delay, Fog networks, Healthcare data, {IoT}, Monitoring},
	file = {Chakraborty et al_2016_Fog Networks in Healthcare Application.pdf:/home/volodia/Zotero/storage/WKSLDCVH/Chakraborty et al_2016_Fog Networks in Healthcare Application.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/I7Y989BR/7815059.html:text/html},
}

@unpublished{biren_gandhi_fog_nodate,
	title = {Fog Computing Reality Check: Real World Applications and Architectures},
	url = {https://www.slideshare.net/biren_gandhi/fog-computing-reality-check-real-world-applications-and-architectures},
	shorttitle = {Fog Computing Reality Check},
	author = {Biren Gandhi},
	urldate = {2022-02-09},
}

@online{noauthor_clouds_nodate,
	title = {The {CLOUDS} Lab: Flagship Projects - Gridbus and Cloudbus},
	url = {http://www.cloudbus.org/cloudsim/},
	urldate = {2022-02-09},
	file = {The CLOUDS Lab\: Flagship Projects - Gridbus and Cloudbus:/home/volodia/Zotero/storage/S5BYJGLY/cloudsim.html:text/html},
}

@inproceedings{etemad_using_2017,
	title = {Using {DEVS} for modeling and simulating a Fog Computing environment},
	doi = {10.1109/ICCNC.2017.7876242},
	abstract = {With the increase in popularity of Internet of Things ({IoT}), pervasive computing, healthcare services, sensor networks, and mobile devices, a lot of data is being generated at the perception layer. Cloud is the most viable solution for data storage, processing, and management. Cloud also helps in the creation of further services, refined according to the context and requirement. However, being reachable through the Internet, cloud is not efficient enough for latency sensitive multimedia services and other time-sensitive services, like emergency and healthcare. Fog, an extended cloud lying within the proximity of underlying nodes, can mitigate the issues traditional cloud cannot solve being standalone. Fog can provide quick response to the requiring applications. Moreover, it can preprocess and filter data according to the requirements. Trimmed data is then sent to the cloud for further analysis and enhanced service provisioning. However, how much better is it to have a fog in any particular scenario instead of a standalone cloud working without fog is a question right now. In this paper, we provide an answer by analyzing both cloud-only and cloud-fog scenarios in the context of processing delay and power consumption according to increasing number of users, on the basis of varying server load. The simulation is done through Discrete Event System Specification ({DEVS}). Simulation results demonstrate that by the use of fog networks, users experienced lower waiting times and increased data rates.},
	eventtitle = {2017 International Conference on Computing, Networking and Communications ({ICNC})},
	pages = {849--854},
	booktitle = {2017 International Conference on Computing, Networking and Communications ({ICNC})},
	author = {Etemad, Mohammad and Aazam, Mohammad and St-Hilaire, Marc},
	date = {2017-01},
	keywords = {cloud computing, Fog computing, Simulation, {DEVS}, performance evaluation},
	file = {Etemad et al_2017_Using DEVS for modeling and simulating a Fog Computing environment.pdf:/home/volodia/Zotero/storage/YI52LUAM/Etemad et al_2017_Using DEVS for modeling and simulating a Fog Computing environment.pdf:application/pdf},
}

@article{tuli_fogbus_2019,
	title = {{FogBus}: A Blockchain-based Lightweight Framework for Edge and Fog Computing},
	volume = {154},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121219300822},
	doi = {10.1016/j.jss.2019.04.050},
	shorttitle = {{FogBus}},
	pages = {22--36},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Tuli, Shreshth and Mahmud, Redowan and Tuli, Shikhar and Buyya, Rajkumar},
	urldate = {2022-02-09},
	date = {2019-08},
	langid = {english},
	keywords = {paas},
	file = {Tuli et al. - 2019 - FogBus A Blockchain-based Lightweight Framework f.pdf:/home/volodia/Zotero/storage/D2MSANHJ/Tuli et al. - 2019 - FogBus A Blockchain-based Lightweight Framework f.pdf:application/pdf},
}

@software{noauthor_fogbus_2021,
	title = {{FogBus}},
	rights = {{GPL}-2.0},
	url = {https://github.com/Cloudslab/FogBus},
	abstract = {[{JSS}'19] A Blockchain-based Lightweight Framework for Edge and Fog Computing},
	publisher = {The Cloud Computing and Distributed Systems ({CLOUDS}) Laboratory},
	urldate = {2022-02-09},
	date = {2021-12-26},
	note = {original-date: 2018-09-02T13:58:59Z},
	keywords = {edge-computing, fog-computing, blockchain, cloud-computing, iot-application},
}

@software{noauthor_fogbus2_2021,
	title = {{FogBus}2 Framework},
	url = {https://github.com/Cloudslab/FogBus2},
	abstract = {{FogBus}2: A Lightweight and Distributed Container-based Framework for Integration of {IoT}-enabled Systems with Edge and Cloud Computing},
	publisher = {The Cloud Computing and Distributed Systems ({CLOUDS}) Laboratory},
	urldate = {2022-02-09},
	date = {2021-12-07},
	note = {original-date: 2021-07-31T14:28:33Z},
	keywords = {paas},
}

@online{noauthor_how_nodate-1,
	title = {How to set public {SSH} key for root user on server?},
	url = {https://serverfault.com/questions/140421/how-to-set-public-ssh-key-for-root-user-on-server},
	titleaddon = {Server Fault},
	urldate = {2022-02-09},
	file = {Snapshot:/home/volodia/Zotero/storage/P4WZ3J7W/how-to-set-public-ssh-key-for-root-user-on-server.html:text/html},
}

@online{ltd_learn_2021,
	title = {Learn how to build functions faster using Rancher’s kim and K3s},
	url = {https://www.openfaas.com/blog/kim/},
	abstract = {Learn how the kim tool from Rancher can be used to build functions directly into a K3s cluster},
	titleaddon = {{OpenFaaS} - Serverless Functions Made Simple},
	author = {Ltd, {OpenFaaS}},
	urldate = {2022-02-09},
	date = {2021-05-12},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/EEPJRG5F/kim.html:text/html},
}

@article{fernandez-carames_fog_2018,
	title = {A Fog Computing and Cloudlet Based Augmented Reality System for the Industry 4.0 Shipyard},
	volume = {18},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/18/6/1798},
	doi = {10.3390/s18061798},
	abstract = {Augmented Reality ({AR}) is one of the key technologies pointed out by Industry 4.0 as a tool for enhancing the next generation of automated and computerized factories. {AR} can also help shipbuilding operators, since they usually need to interact with information (e.g., product datasheets, instructions, maintenance procedures, quality control forms) that could be handled easily and more efficiently through {AR} devices. This is the reason why Navantia, one of the 10 largest shipbuilders in the world, is studying the application of {AR} (among other technologies) in different shipyard environments in a project called “Shipyard 4.0”. This article presents Navantia’s industrial {AR} ({IAR}) architecture, which is based on cloudlets and on the fog computing paradigm. Both technologies are ideal for supporting physically-distributed, low-latency and {QoS}-aware applications that decrease the network traffic and the computational load of traditional cloud computing systems. The proposed {IAR} communications architecture is evaluated in real-world scenarios with payload sizes according to demanding Microsoft {HoloLens} applications and when using a cloud, a cloudlet and a fog computing system. The results show that, in terms of response delay, the fog computing system is the fastest when transferring small payloads (less than 128 {KB}), while for larger file sizes, the cloudlet solution is faster than the others. Moreover, under high loads (with many concurrent {IAR} clients), the cloudlet in some cases is more than four times faster than the fog computing system in terms of response delay.},
	pages = {1798},
	number = {6},
	journaltitle = {Sensors},
	author = {Fernández-Caramés, Tiago M. and Fraga-Lamas, Paula and Suárez-Albela, Manuel and Vilar-Montesinos, Miguel},
	urldate = {2022-02-10},
	date = {2018-06},
	langid = {english},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cloudlet, fog computing, augmented reality, {IIoT}, industrial augmented reality, industrial operator support, Industry 4.0, Microsoft {HoloLens}, shipyard},
	file = {Fernández-Caramés et al_2018_A Fog Computing and Cloudlet Based Augmented Reality System for the Industry 4.pdf:/home/volodia/Zotero/storage/IKDAAMKI/Fernández-Caramés et al_2018_A Fog Computing and Cloudlet Based Augmented Reality System for the Industry 4.pdf:application/pdf;Snapshot:/home/volodia/Zotero/storage/XNR2ZNYJ/htm.html:text/html},
}

@online{noauthor_dhcp_nodate,
	title = {{DHCP} not working on Fedora rawhide · Issue \#1448 · canonical/multipass},
	url = {https://github.com/canonical/multipass/issues/1448},
	abstract = {Describe the bug Trying to package a snap using snapcraft on Fedora rawhide. Initially this failed with a permission error on /var/snap/multipass/common/multipass\_socket \$ ls -lh /var/snap/multipas...},
	titleaddon = {{GitHub}},
	urldate = {2022-02-10},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/2Y95MUAB/1448.html:text/html},
}

@article{ascigil_resource_2021,
	title = {Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds},
	issn = {1939-1374},
	doi = {10.1109/TSC.2021.3052139},
	abstract = {Edge computing has emerged as a new paradigm to bring cloud applications closer to users for increased performance. Unlike back-end cloud systems which consolidate their resources in a centralized data center location with virtually unlimited capacity, edge-clouds comprise distributed resources at various computation spots, each with very limited capacity. In this paper, we consider Function-as-a-Service ({FaaS}) edge-clouds where application providers deploy their latency-critical functions that process user requests with strict response time deadlines. In this setting, we investigate the problem of resource provisioning and allocation. After formulating the optimal solution, we propose resource allocation and provisioning algorithms across the spectrum of fully-centralized to fully-decentralized. We evaluate the performance of these algorithms in terms of their ability to utilize {CPU} resources and meet request deadlines under various system parameters. Our results indicate that practical decentralized strategies, which require no coordination among computation spots, achieve performance that is close to the optimal fully-centralized strategy with coordination overheads.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Ascigil, Onur and Tasiopoulos, Argyrios and Phan, Truong Khoa and Sourlas, Vasilis and Psaras, Ioannis and Pavlou, George},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Services Computing},
	keywords = {Cloud computing, Delays, Containers, {FAA}, Image edge detection, Resource management, Routing},
	file = {Ascigil et al_2021_Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds.pdf:/home/volodia/Zotero/storage/AKF6XZIN/Ascigil et al_2021_Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds.pdf:application/pdf},
}

@online{262588213843476_setup_nodate,
	title = {Setup a k3s kubernetes cluster using Multipass {VMs}},
	url = {https://gist.github.com/lucj/5a0e2286b40130d02388a264e6924ed4},
	abstract = {Setup a k3s kubernetes cluster using Multipass {VMs} - k3s-multipass.sh},
	titleaddon = {Gist},
	author = {262588213843476},
	urldate = {2022-02-10},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/2SJ594ZF/5a0e2286b40130d02388a264e6924ed4.html:text/html},
}

@online{juggery_local_2019,
	title = {Local K3s Cluster Made Easy With Multipass},
	url = {https://betterprogramming.pub/local-k3s-cluster-made-easy-with-multipass-108bf6ce577c},
	abstract = {Its integration with low-level hypervisors makes it a good choice to deploy multiple {VMs} locally},
	titleaddon = {Medium},
	author = {Juggery, Luc},
	urldate = {2022-02-10},
	date = {2019-12-17},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/NQKALFL7/local-k3s-cluster-made-easy-with-multipass-108bf6ce577c.html:text/html},
}

@software{noauthor_faasd_2022,
	title = {faasd - a lightweight \& portable faas engine},
	rights = {{MIT}},
	url = {https://github.com/openfaas/faasd/blob/95c41ea758e31154327b89124e4a678b8d633cbb/docs/MULTIPASS.md},
	abstract = {A lightweight \& portable faas engine},
	publisher = {{OpenFaaS}},
	urldate = {2022-02-10},
	date = {2022-02-10},
	note = {original-date: 2019-12-20T12:55:07Z},
}

@online{noauthor_create_nodate,
	title = {Create functions - {OpenFaaS}},
	url = {https://docs.openfaas.com/cli/templates/},
	urldate = {2022-02-10},
	file = {Create functions - OpenFaaS:/home/volodia/Zotero/storage/8I7VBIV7/templates.html:text/html},
}

@article{eismann_state_2021,
	title = {The State of Serverless Applications: Collection, Characterization, and Community Consensus},
	issn = {1939-3520},
	doi = {10.1109/TSE.2021.3113940},
	shorttitle = {The State of Serverless Applications},
	abstract = {Over the last five years, all major cloud platform providers have increased their serverless offerings. Many early adopters report significant benefits for serverless-based over traditional applications, and many companies are considering moving to serverless themselves. However, currently there exist only few, scattered, and sometimes even conflicting reports on when serverless applications are well suited and what the best practices for their implementation are. We address this problem in the present study about the state of serverless applications. We collect descriptions of 89 serverless applications from open-source projects, academic literature, industrial literature, and domain-specific feedback. We analyze 16 characteristics that describe why and when successful adopters are using serverless applications, and how they are building them. We further compare the results of our characterization study to 10 existing, mostly industrial, studies and datasets; this allows us to identify points of consensus across multiple studies, investigate points of disagreement, and overall confirm the validity of our results. The results of this study can help managers to decide if they should adopt serverless technology, engineers to learn about current practices of building serverless applications, and researchers and platform providers to better understand the current landscape of serverless applications.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Eismann, Simon and Scheuner, Joel and Van Eyk, Erwin and Schwinger, Maximilian and Grohmann, Johannes and Herbst, Nikolas and Abad, Cristina and Iosup, Alexandru},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
	keywords = {Logic gates, Buildings, Computer architecture, Open source software, Production, Software engineering, Systematics},
	file = {Eismann et al_2021_The State of Serverless Applications.pdf:/home/volodia/Zotero/storage/3K8SAQ3P/Eismann et al_2021_The State of Serverless Applications.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/6W2VTXC6/9543531.html:text/html},
}

@online{noauthor_tinyfaas_nodate,
	title = {{tinyFaaS}: A Lightweight {FaaS} Platform for Edge Environments {\textbar} {IEEE} Conference Publication {\textbar} {IEEE} Xplore},
	url = {https://ieeexplore.ieee.org/abstract/document/9103476},
	urldate = {2022-02-10},
	file = {tinyFaaS\: A Lightweight FaaS Platform for Edge Environments | IEEE Conference Publication | IEEE Xplore:/home/volodia/Zotero/storage/6JCYTRZQ/9103476.html:text/html},
}

@article{tasiopoulos_fogspot_2021,
	title = {{FogSpot}: Spot Pricing for Application Provisioning in Edge/Fog Computing},
	volume = {14},
	issn = {1939-1374},
	doi = {10.1109/TSC.2019.2895037},
	shorttitle = {{FogSpot}},
	abstract = {An increasing number of Low Latency Applications ({LLAs}) in the entertainment, {IoT}, and automotive domains require response times that challenge the traditional application provisioning using distant Data Centres. The fog computing paradigm extends cloud computing at the edge and middle-tier locations of the network, providing response times an order of magnitude smaller than those that can be achieved by the current “client-to-cloud” network model. Here, we address the challenges of provisioning heavily stateful {LLA} in the setting where fog infrastructure consists of third-party computing resources, i.e., cloudlets, that come in the form of “data centres in the box”. We introduce {FogSpot}, a charging mechanism for on-path, on-demand, application provisioning. In {FogSpot}, cloudlets offer their resources in the form of Virtual Machines ({VMs}) via markets, collocated with the cloudlets, that interact with forwarded users’ application requests for {VMs} in real time. {FogSpot} associates each cloudlet with a price based on applications’ demand. The proposed mechanism’s design takes into account the characteristics of cloudlets’ resources, such as their limited elasticity, and {LLAs}’ attributes, like their expected {QoS} gain and engagement duration. Lastly, {FogSpot} guarantees the end users’ requests truthfulness while focusing in maximising either each cloudlet’s revenue or resource utilisation.},
	pages = {1781--1795},
	number = {6},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Tasiopoulos, Argyrios G. and Ascigil, Onur and Psaras, Ioannis and Toumpis, Stavros and Pavlou, George},
	date = {2021-11},
	note = {Conference Name: {IEEE} Transactions on Services Computing},
	keywords = {Cloud computing, Edge computing, Quality of service, application provisioning, Data centers, decentralised cloud applications, Economics, Edge/Fog computing, Elasticity, network economics, pricing, Pricing, quality of service, Task analysis},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/D79FGMSS/8625439.html:text/html;Tasiopoulos et al_2021_FogSpot.pdf:/home/volodia/Zotero/storage/DA4DW29G/Tasiopoulos et al_2021_FogSpot.pdf:application/pdf},
}

@inproceedings{xu_towards_2016,
	title = {Towards {SDN}-based fog computing: {MQTT} broker virtualization for effective and reliable delivery},
	doi = {10.1109/COMSNETS.2016.7439974},
	shorttitle = {Towards {SDN}-based fog computing},
	abstract = {Performance of data analytics in Internet of Things ({IoTs}) depends on effective transport services offered by the underlying network. Fog computing enables independent data-plane computational features at the edge-switches, which serves as a platform for performing certain critical analytics required at the {IoT} source. To this end, in this paper, we implement a working prototype of Fog computing node based on Software-Defined Networking ({SDN}). Message Queuing Telemetry Transport ({MQTT}) is chosen as the candidate {IoT} protocol that transports data generated from {IoT} devices (a:k:a: {MQTT} publishers) to a remote host (called {MQTT} broker). We implement the {MQTT} broker functionalities integrated at the edge-switches, that serves as a platform to perform simple message-based analytics at the switches, and also deliver messages in a reliable manner to the end-host for post-delivery analytics. We mathematically validate the improved delivery performance as offered by the proposed switch-embedded brokers.},
	eventtitle = {2016 8th International Conference on Communication Systems and Networks ({COMSNETS})},
	pages = {1--6},
	booktitle = {2016 8th International Conference on Communication Systems and Networks ({COMSNETS})},
	author = {Xu, Yiming and Mahendran, V. and Radhakrishnan, Sridhar},
	date = {2016-01},
	note = {{ISSN}: 2155-2509},
	keywords = {Performance evaluation, Computer architecture, Big data, Conferences, Control systems, Ports (Computers), Throughput},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/I6YQRB5H/7439974.html:text/html;Xu et al_2016_Towards SDN-based fog computing.pdf:/home/volodia/Zotero/storage/5UZVADE2/Xu et al_2016_Towards SDN-based fog computing.pdf:application/pdf},
}

@article{salman_iot_2018,
	title = {{IoT} survey: An {SDN} and fog computing perspective},
	volume = {143},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128618305395},
	doi = {10.1016/j.comnet.2018.07.020},
	shorttitle = {{IoT} survey},
	abstract = {Recently, there has been an increasing interest in the Internet of Things ({IoT}). While some analysts disvalue the {IoT} hype, several technology leaders, governments, and researchers are putting serious efforts to develop solutions enabling wide {IoT} deployment. Thus, the huge amount of generated data, the high network scale, the security and privacy concerns, the new requirements in terms of {QoS}, and the heterogeneity in this ubiquitous network of networks make its implementation a very challenging task. {SDN}, a new networking paradigm, has revealed its usefulness in reducing the management complexities in today's networks. Additionally, {SDN}, having a global view of the network, has presented effective security solutions. On the other hand, fog computing, a new data service platform, consists of pushing the data to the network edge reducing the cost (in terms of bandwidth consumption and high latency) of “big data” transportation through the core network. In this paper, we critically review the {SDN} and fog computing-based solutions to overcome the {IoT} main challenges, highlighting their advantages, and exposing their weaknesses. Thus, we make recommendations at the end of this paper for the upcoming research work.},
	pages = {221--246},
	journaltitle = {Computer Networks},
	shortjournal = {Computer Networks},
	author = {Salman, Ola and Elhajj, Imad and Chehab, Ali and Kayssi, Ayman},
	urldate = {2022-02-10},
	date = {2018-10-09},
	langid = {english},
	keywords = {{IoT}, 5G, Cloud, Fog, {SDN}, Survey},
	file = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/3375APN4/S1389128618305395.html:text/html},
}

@inreference{noauthor_software-defined_2022,
	title = {Software-defined networking},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Software-defined_networking&oldid=1070889880},
	abstract = {Software-defined networking ({SDN}) technology is an approach to network management that enables dynamic, programmatically efficient network configuration in order to improve network performance and monitoring, making it more like cloud computing than traditional network management. {SDN} is meant to address the static architecture of traditional networks. {SDN} attempts to centralize network intelligence in one network component by disassociating the forwarding process of network packets (data plane) from the routing process (control plane). The control plane consists of one or more controllers, which are considered the brain of the {SDN} network where the whole intelligence is incorporated. However, centralization has its own drawbacks when it comes to security, scalability and elasticity and this is the main issue of {SDN}.{SDN} was commonly associated with the {OpenFlow} protocol (for remote communication with network plane elements for the purpose of determining the path of network packets across network switches) since the latter's emergence in 2011. However, since 2012, proprietary  systems also used the term. These include Cisco Systems' Open Network Environment and Nicira's network virtualization platform.
{SD}-{WAN} applies similar technology to a wide area network ({WAN}).},
	booktitle = {Wikipedia},
	urldate = {2022-02-10},
	date = {2022-02-09},
	langid = {english},
	note = {Page Version {ID}: 1070889880},
	file = {Snapshot:/home/volodia/Zotero/storage/R47RGRS7/Software-defined_networking.html:text/html},
}

@online{networks_lets_nodate,
	title = {Let's build our own Software Defined Network!},
	url = {https://northboundnetworks.com/blogs/sdn/lets-build-our-own-software-defined-network},
	abstract = {In Part 3 of this series we are going to build an actual Software Defined Network.},
	titleaddon = {Northbound Networks},
	author = {Networks, Northbound},
	urldate = {2022-02-10},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/KQPWJF4X/lets-build-our-own-software-defined-network.html:text/html},
}

@article{espinel_sarmiento_decentralized_2021,
	title = {Decentralized {SDN} Control Plane for a Distributed Cloud-Edge Infrastructure: A Survey},
	volume = {23},
	issn = {1553-877X},
	doi = {10.1109/COMST.2021.3050297},
	shorttitle = {Decentralized {SDN} Control Plane for a Distributed Cloud-Edge Infrastructure},
	abstract = {Today's emerging needs (Internet of Things applications, Network Function Virtualization services, Mobile Edge computing, etc.) are challenging the classic approach of deploying a few large data centers to provide cloud services. A massively distributed Cloud-Edge architecture could better fit these new trends' requirements and constraints by deploying on-demand infrastructure services in Point-of-Presences within backbone networks. In this context, a key feature is establishing connectivity among several resource managers in charge of operating, each one a subset of the infrastructure. After explaining the networking management challenges related to distributed Cloud-Edge infrastructures, this article surveys and analyzes the characteristics and limitations of existing technologies in the Software Defined Network field that could be used to provide the inter-site connectivity feature. We also introduce Kubernetes, the new de facto container orchestrator platform, and analyze its use in the proposed context. This survey is concluded by providing a discussion about some research directions in the field of {SDN} applied to distributed Cloud-Edge infrastructures' management.},
	pages = {256--281},
	number = {1},
	journaltitle = {{IEEE} Communications Surveys Tutorials},
	author = {Espinel Sarmiento, David and Lebre, Adrien and Nussbaum, Lucas and Chari, Abdelhadi},
	date = {2021},
	note = {Conference Name: {IEEE} Communications Surveys Tutorials},
	keywords = {Cloud computing, Quality of service, networking, Routing, Computer architecture, {SDN}, automation, {IaaS}, Neutrons, Tutorials, virtualization, Wide area networks},
	file = {Espinel Sarmiento et al_2021_Decentralized SDN Control Plane for a Distributed Cloud-Edge Infrastructure.pdf:/home/volodia/Zotero/storage/7QYZ8JYM/Espinel Sarmiento et al_2021_Decentralized SDN Control Plane for a Distributed Cloud-Edge Infrastructure.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/IJ5KGGXD/9319748.html:text/html},
}

@article{eismann_state_2021-1,
	title = {The State of Serverless Applications: Collection, Characterization, and Community Consensus},
	issn = {1939-3520},
	doi = {10.1109/TSE.2021.3113940},
	shorttitle = {The State of Serverless Applications},
	abstract = {Over the last five years, all major cloud platform providers have increased their serverless offerings. Many early adopters report significant benefits for serverless-based over traditional applications, and many companies are considering moving to serverless themselves. However, currently there exist only few, scattered, and sometimes even conflicting reports on when serverless applications are well suited and what the best practices for their implementation are. We address this problem in the present study about the state of serverless applications. We collect descriptions of 89 serverless applications from open-source projects, academic literature, industrial literature, and domain-specific feedback. We analyze 16 characteristics that describe why and when successful adopters are using serverless applications, and how they are building them. We further compare the results of our characterization study to 10 existing, mostly industrial, studies and datasets; this allows us to identify points of consensus across multiple studies, investigate points of disagreement, and overall confirm the validity of our results. The results of this study can help managers to decide if they should adopt serverless technology, engineers to learn about current practices of building serverless applications, and researchers and platform providers to better understand the current landscape of serverless applications.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Eismann, Simon and Scheuner, Joel and Van Eyk, Erwin and Schwinger, Maximilian and Grohmann, Johannes and Herbst, Nikolas and Abad, Cristina and Iosup, Alexandru},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
	keywords = {Logic gates, Buildings, Computer architecture, Open source software, Production, Software engineering, Systematics},
	file = {Eismann et al_2021_The State of Serverless Applications.pdf:/home/volodia/Zotero/storage/U3PNMFUC/Eismann et al_2021_The State of Serverless Applications.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/GJXX5QMI/9543531.html:text/html},
}

@incollection{jin_lessons_2021,
	location = {New York, {NY}, {USA}},
	title = {Lessons learned from migrating complex stateful applications onto serverless platforms},
	isbn = {978-1-4503-8698-2},
	url = {https://doi.org/10.1145/3476886.3477510},
	abstract = {Serverless computing is increasingly seen as a pivot cloud computing paradigm that has great potential to simplify application development while removing the burden of operational tasks from developers. Despite these advantages, the use of serverless computing has been limited to few application scenarios exhibiting stateless and parallel executions. In addition, the significant effort and cost associated with rearchitecting existing codebase limits the range of these applications and hinder efforts to enhance serverless computing platforms to better suit the needs of current applications. In this paper, we report our experience and observations from migrating four complex and stateful microservice applications (involving 8 programming languages, 5 application frameworks, and 40 application logic services) to {ApacheOpenWhisk}, a widely used serverless computing platform. We highlight a number of patterns and guidelines that facilitate this migration with minimal code changes and practical performance considerations, and imply a path towards further automating this process. We hope our guidelines will help increase the applicability of serverless computing and improve serverless platforms to be more application friendly.},
	pages = {89--96},
	booktitle = {Proceedings of the 12th {ACM} {SIGOPS} Asia-Pacific Workshop on Systems},
	publisher = {Association for Computing Machinery},
	author = {Jin, Zewen and Zhu, Yiming and Zhu, Jiaan and Yu, Dongbo and Li, Cheng and Chen, Ruichuan and Akkus, Istemi Ekin and Xu, Yinlong},
	urldate = {2022-02-11},
	date = {2021-08-24},
	file = {Jin et al_2021_Lessons learned from migrating complex stateful applications onto serverless.pdf:/home/volodia/Zotero/storage/TEYNBVCS/Jin et al_2021_Lessons learned from migrating complex stateful applications onto serverless.pdf:application/pdf},
}

@inproceedings{eskandani_wonderless_2021,
	title = {The Wonderless Dataset for Serverless Computing},
	doi = {10.1109/MSR52588.2021.00075},
	abstract = {Function as a Service ({FaaS}) has grown in popularity in recent years, with an increasing number of applications following the Serverless computing model. Serverless computing supports out of the box autoscaling in a pay-as-you-go manner, letting developers focus on the application logic rather than worrying about resource management. With the increasing adoption of the this model, researchers have started studying a wide variety of aspects of Serverless computing, including communication, security, performance, and cost optimization. Yet, we still know very little of how Serverless computing is used in practice.In this paper, we introduce Wonderless, a novel dataset of open-source Serverless applications. Wonderless consists of 1,877 real-world Serverless applications extracted from {GitHub}, and it can be used as a data source for further research in the Serverless ecosystem, such as performance evaluation and software mining. To the best of our knowledge, Wonderless is currently the most diverse and largest dataset for research on Serverless computing.},
	eventtitle = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
	pages = {565--569},
	booktitle = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
	author = {Eskandani, Nafise and Salvaneschi, Guido},
	date = {2021-05},
	note = {{ISSN}: 2574-3864},
	keywords = {Computational modeling, Performance evaluation, Cloud Computing, {FAA}, Resource management, Data mining, Ecosystems, {FaaS}, Function as a Service, Security, Serverless},
	file = {Eskandani_Salvaneschi_2021_The Wonderless Dataset for Serverless Computing.pdf:/home/volodia/Zotero/storage/QDZHVUPF/Eskandani_Salvaneschi_2021_The Wonderless Dataset for Serverless Computing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/UWXXRL7P/9463099.html:text/html},
}

@software{noauthor_befaas_2021,
	title = {{BeFaaS}},
	rights = {Apache-2.0},
	url = {https://github.com/Be-FaaS/BeFaaS-framework},
	abstract = {Main repository of the {BeFaaS} project},
	publisher = {{BeFaaS}},
	urldate = {2022-02-11},
	date = {2021-03-20},
	note = {original-date: 2020-11-11T12:44:57Z},
}

@software{noauthor_kmu-bigdataserverless-faas-workbench_2022,
	title = {kmu-bigdata/serverless-faas-workbench},
	rights = {Apache-2.0},
	url = {https://github.com/kmu-bigdata/serverless-faas-workbench},
	abstract = {{FunctionBench}},
	publisher = {{BigData} Lab. in {KMU}},
	urldate = {2022-02-11},
	date = {2022-02-11},
	note = {original-date: 2019-01-28T05:19:01Z},
	keywords = {serverless, faas, benchmark, function-bench, serverless-faas, workbench},
}

@software{copik_sebs_2021,
	title = {{SeBS}: serverless benchmarks suite},
	rights = {{BSD}-3-Clause},
	url = {https://github.com/spcl/serverless-benchmarks},
	shorttitle = {{SeBS}},
	abstract = {{SeBS}: serverless benchmarking suite for automatic performance analysis of {FaaS} platforms.},
	version = {1.0},
	author = {Copik, Marcin},
	urldate = {2022-02-11},
	date = {2021-07},
	note = {original-date: 2019-12-13T11:04:54Z},
}

@online{noauthor_faasprofiler_nodate,
	title = {{FaaSProfiler}},
	url = {http://parallel.princeton.edu/FaaSProfiler.html},
	urldate = {2022-02-11},
}

@software{noauthor_serverlessbench_2022,
	title = {{ServerlessBench}},
	url = {https://github.com/SJTU-IPADS/ServerlessBench},
	abstract = {A benchmark suite for serverless computing},
	publisher = {{IPADS}},
	urldate = {2022-02-11},
	date = {2022-02-06},
	note = {original-date: 2020-08-09T11:53:43Z},
}

@software{wlloyduw_saaf_2022,
	title = {{SAAF} - Serverless Application Analytics Framework},
	url = {https://github.com/wlloyduw/SAAF},
	abstract = {Serverless Application Analytics Framework},
	author = {wlloyduw},
	urldate = {2022-02-11},
	date = {2022-01-14},
	note = {original-date: 2018-10-19T00:36:28Z},
}

@software{bschitter_benchmark-suite-serverless-computing_2021,
	title = {benchmark-suite-serverless-computing},
	url = {https://github.com/Bschitter/benchmark-suite-serverless-computing},
	abstract = {Repository used for the master thesis "A Benchmark Suite for Serverless Computing".},
	author = {Bschitter},
	urldate = {2022-02-11},
	date = {2021-10-06},
	note = {original-date: 2019-02-27T12:27:11Z},
}

@software{noauthor_overview_2022,
	title = {Overview},
	url = {https://github.com/Azure/AzurePublicDataset},
	abstract = {Microsoft Azure Traces},
	publisher = {Microsoft Azure},
	urldate = {2022-02-11},
	date = {2022-02-10},
	note = {original-date: 2017-08-18T17:37:45Z},
}

@software{noauthor_create_2018,
	title = {Create a Serverless Pipeline for Video Frame Analysis and Alerting},
	url = {https://github.com/serverless-projects/serverless-rekognition-video-analyzer},
	abstract = {A working prototype for capturing frames off of a live {MJPEG} video stream, identifying objects in near real-time using deep learning, and triggering actions based on an objects watch list.},
	publisher = {serverless projects},
	urldate = {2022-02-11},
	date = {2018-04-11},
	note = {original-date: 2018-04-11T11:49:45Z},
	keywords = {serverless, rekognition},
}

@software{noauthor_lambci_2022,
	title = {{LambCI}},
	rights = {{MIT}},
	url = {https://github.com/lambci/lambci},
	abstract = {A continuous integration system built on {AWS} Lambda},
	publisher = {{LambCI}},
	urldate = {2022-02-11},
	date = {2022-02-02},
	note = {original-date: 2016-06-12T21:53:34Z},
}

@software{noauthor_streamalert_2022,
	title = {{StreamAlert} - Serverless, Realtime Data Analysis Framework},
	rights = {Apache-2.0},
	url = {https://github.com/airbnb/streamalert},
	abstract = {{StreamAlert} is a serverless, realtime data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using datasources and alerting logic you define.},
	publisher = {Airbnb},
	urldate = {2022-02-11},
	date = {2022-02-07},
	note = {original-date: 2017-01-22T01:10:56Z},
	keywords = {serverless, analysis, aws, kinesis, lambda, rules, security, terraform},
}

@software{noauthor_goad_2022,
	title = {Goad},
	rights = {{MIT}},
	url = {https://github.com/goadapp/goad},
	abstract = {Goad is an {AWS} Lambda powered, highly distributed, load testing tool},
	publisher = {Goad},
	urldate = {2022-02-11},
	date = {2022-02-07},
	note = {original-date: 2016-01-22T19:21:26Z},
}

@software{noauthor_async-coap_2022,
	title = {async-coap: An experimental, asynchronous {CoAP} library},
	rights = {Apache-2.0},
	url = {https://github.com/google/rust-async-coap},
	shorttitle = {async-coap},
	abstract = {A flexible, asynchronous library for using and serving {CoAP} resources in Rust.},
	publisher = {Google},
	urldate = {2022-02-11},
	date = {2022-02-01},
	note = {original-date: 2019-08-21T20:23:02Z},
}

@article{silva_performance_2021,
	title = {A Performance Analysis of Internet of Things Networking Protocols: Evaluating {MQTT}, {CoAP}, {OPC} {UA}},
	volume = {11},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/11/11/4879},
	doi = {10.3390/app11114879},
	shorttitle = {A Performance Analysis of Internet of Things Networking Protocols},
	abstract = {{IoT} data exchange is supported today by different communication protocols and different protocolar frameworks, each of which with its own advantages and disadvantages, and often co-existing in a way that is mandated by vendor policies. Although different protocols are relevant in different domains, there is not a protocol that provides better performance (jitter, latency, energy consumption) across different scenarios. The focus of this work is two-fold. First, to provide a comparison of the different available solutions in terms of protocolar features such as type of transport, type of communication pattern support, security aspects, including Named-data networking as relevant example of an Information-centric networking architecture. Secondly, the work focuses on evaluating three of the most popular protocols used both in Consumer as well as in Industrial {IoT} environments: {MQTT}, {CoAP}, and {OPC} {UA}. The experimentation has been carried out first on a local testbed for {MQTT}, {COAP} and {OPC} {UA}. Then, larger experiments have been carried out for {MQTT} and {CoAP}, based on the large-scale {FIT}-{IoT} testbed. Results show that {CoAP} is the protocol that achieves across all scenarios lowest time-to-completion, while {OPC} {UA}, albeit exhibiting less variability, resulted in higher time-to-completion in comparison to {CoAP} or {MQTT}.},
	pages = {4879},
	number = {11},
	journaltitle = {Applied Sciences},
	author = {Silva, Daniel and Carvalho, Liliana I. and Soares, José and Sofia, Rute C.},
	urldate = {2022-02-11},
	date = {2021-01},
	langid = {english},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {performance evaluation, Internet of Things, networking architectures, networking protocols},
	file = {Silva et al_2021_A Performance Analysis of Internet of Things Networking Protocols.pdf:/home/volodia/Zotero/storage/XVNJPECM/Silva et al_2021_A Performance Analysis of Internet of Things Networking Protocols.pdf:application/pdf},
}

@software{noauthor_seastar_2022,
	title = {Seastar},
	rights = {Apache-2.0},
	url = {https://github.com/scylladb/seastar},
	abstract = {High performance server-side application framework},
	publisher = {{ScyllaDB}},
	urldate = {2022-02-11},
	date = {2022-02-11},
	note = {original-date: 2014-08-18T07:01:07Z},
	keywords = {aio, async, c-plus-plus, dpdk, seastar},
}

@software{noauthor_wonderless_2021,
	title = {Wonderless},
	url = {https://github.com/prg-grp/wonderless},
	abstract = {A dataset to shed light upon Serverless computing.},
	publisher = {prg-grp},
	urldate = {2022-02-11},
	date = {2021-11-27},
	note = {original-date: 2021-03-19T13:15:57Z},
}

@inproceedings{tadakamalla_characterization_2019,
	location = {Cham},
	title = {Characterization of {IoT} Workloads},
	isbn = {978-3-030-23374-7},
	doi = {10.1007/978-3-030-23374-7_1},
	series = {Lecture Notes in Computer Science},
	abstract = {Workload characterization is a fundamental step in carrying out performance and Quality of Service engineering studies. The workload of a system is defined as the set of all inputs received by the system from its environment during one or more time windows. The characterization of the workload entails determining the nature of its basic components as well as a quantitative and probabilistic description of the workload components in terms of both the arrival process, event counts, and service demands. Several workload characterization studies were presented for a variety of domains, except for {IoT} workloads. This is precisely the main contribution of this paper, which also presents a capacity planning study based on one of the workload characterizations presented here.},
	pages = {1--15},
	booktitle = {Edge Computing – {EDGE} 2019},
	publisher = {Springer International Publishing},
	author = {Tadakamalla, Uma and Menascé, Daniel A.},
	editor = {Zhang, Tao and Wei, Jinpeng and Zhang, Liang-Jie},
	date = {2019},
	langid = {english},
	keywords = {Internet of Things, Capacity planning, G/G/n queue, Quality of Service in edge computing, Workload characterization},
	file = {Tadakamalla_Menascé_2019_Characterization of IoT Workloads.pdf:/home/volodia/Zotero/storage/L9X9FRLY/Tadakamalla_Menascé_2019_Characterization of IoT Workloads.pdf:application/pdf},
}

@incollection{zhang_characterization_2019,
	location = {Cham},
	title = {Characterization of {IoT} Workloads},
	volume = {11520},
	isbn = {978-3-030-23373-0 978-3-030-23374-7},
	url = {http://link.springer.com/10.1007/978-3-030-23374-7_1},
	pages = {1--15},
	booktitle = {Edge Computing – {EDGE} 2019},
	publisher = {Springer International Publishing},
	author = {Tadakamalla, Uma and Menascé, Daniel A.},
	editor = {Zhang, Tao and Wei, Jinpeng and Zhang, Liang-Jie},
	urldate = {2022-02-11},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-23374-7_1},
	note = {Series Title: Lecture Notes in Computer Science},
}

@inproceedings{pfandzelter_tinyfaas_2020,
	title = {{tinyFaaS}: A Lightweight {FaaS} Platform for Edge Environments},
	doi = {10.1109/ICFC49376.2020.00011},
	shorttitle = {{tinyFaaS}},
	abstract = {The Function-as-a-Service ({FaaS}) model is a great fit for data and event processing in the Internet of Things ({IoT}). Sending all data to a cloud-based {FaaS} platform, however, may cause performance and privacy issues. While these issues could be mitigated using edge computing, existing {FaaS} approaches, designed for the cloud, are too heavyweight to run on small, constrained edge nodes. In this paper, we propose {tinyFaaS}, a new {FaaS} system that is specifically designed for edge environments and their unique challenges. Our platform is lightweight enough to run on low-performance single machine edge nodes, provides a {CoAP} endpoint to support communication with low-power devices, and uses Docker containers to isolate tenants. We evaluate {tinyFaaS} through a proof-of-concept implementation that we benchmark and compare to state-of-the-art {FaaS} platforms. For {IoT} processing scenarios, we find that {tinyFaaS} outperforms existing systems by at least an order of magnitude.},
	eventtitle = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	pages = {17--24},
	booktitle = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	author = {Pfandzelter, Tobias and Bermbach, David},
	date = {2020-04},
	keywords = {Cloud computing, Edge computing, Edge Computing, Servers, {IoT}, Containers, {FAA}, {FaaS}, Serverless, Protocols, Runtime},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/36CB5A7P/9103476.html:text/html;Pfandzelter_Bermbach_2020_tinyFaaS.pdf:/home/volodia/Zotero/storage/KRCS6WXM/Pfandzelter_Bermbach_2020_tinyFaaS.pdf:application/pdf},
}

@inproceedings{pfandzelter_tinyfaas_2020-1,
	title = {{tinyFaaS}: A Lightweight {FaaS} Platform for Edge Environments},
	doi = {10.1109/ICFC49376.2020.00011},
	shorttitle = {{tinyFaaS}},
	abstract = {The Function-as-a-Service ({FaaS}) model is a great fit for data and event processing in the Internet of Things ({IoT}). Sending all data to a cloud-based {FaaS} platform, however, may cause performance and privacy issues. While these issues could be mitigated using edge computing, existing {FaaS} approaches, designed for the cloud, are too heavyweight to run on small, constrained edge nodes. In this paper, we propose {tinyFaaS}, a new {FaaS} system that is specifically designed for edge environments and their unique challenges. Our platform is lightweight enough to run on low-performance single machine edge nodes, provides a {CoAP} endpoint to support communication with low-power devices, and uses Docker containers to isolate tenants. We evaluate {tinyFaaS} through a proof-of-concept implementation that we benchmark and compare to state-of-the-art {FaaS} platforms. For {IoT} processing scenarios, we find that {tinyFaaS} outperforms existing systems by at least an order of magnitude.},
	eventtitle = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	pages = {17--24},
	booktitle = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	author = {Pfandzelter, Tobias and Bermbach, David},
	date = {2020-04},
	keywords = {Cloud computing, Edge computing, Edge Computing, Servers, {IoT}, Containers, {FAA}, {FaaS}, Serverless, Protocols, Runtime},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/8LHB9N9A/9103476.html:text/html;Pfandzelter_Bermbach_2020_tinyFaaS.pdf:/home/volodia/Zotero/storage/N6NF4WBE/Pfandzelter_Bermbach_2020_tinyFaaS.pdf:application/pdf},
}

@article{van_lingen_unavoidable_2017,
	title = {The Unavoidable Convergence of {NFV}, 5G, and Fog: A Model-Driven Approach to Bridge Cloud and Edge},
	volume = {55},
	issn = {1558-1896},
	doi = {10.1109/MCOM.2017.1600907},
	shorttitle = {The Unavoidable Convergence of {NFV}, 5G, and Fog},
	abstract = {The interplay between cloud and fog computing is crucial for the evolution of {IoT}, but the reach and specification of such interplay is an open problem. Meanwhile, the advances made in managing hyper-distributed infrastructures involving the cloud and the network edge are leading to the convergence of {NFV} and 5G, supported mainly by {ETSI}'s {MANO} architecture. This article argues that fog computing will become part of that convergence, and introduces an open and converged architecture based on {MANO} that offers uniform management of {IoT} services spanning the continuum from the cloud to the edge. More specifically, we created the first {YANG} models for fog nodes, for {IoT} services involving cloud, network, and/or fog, and expanded the concept of "orchestrated assurance" to provision carrier-grade service assurance in {IoT}. The article also discusses the application of our model in a flagship pilot in the city of Barcelona.},
	pages = {28--35},
	number = {8},
	journaltitle = {{IEEE} Communications Magazine},
	author = {van Lingen, Frank and Yannuzzi, Marcelo and Jain, Anuj and Irons-Mclean, Rik and Lluch, Oriol and Carrera, David and Perez, Juan Luis and Gutierrez, Alberto and Montero, Diego and Marti, Josep and Maso, Ricard and Rodriguez and Pedro, Juan},
	date = {2017-08},
	note = {Conference Name: {IEEE} Communications Magazine},
	keywords = {Cloud computing, Edge computing, Data models, Computer architecture, 5G mobile communication, Analytical models, Convergence},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/32ZIRUGT/8004150.html:text/html;van Lingen et al_2017_The Unavoidable Convergence of NFV, 5G, and Fog.pdf:/home/volodia/Zotero/storage/GSEX2HB2/van Lingen et al_2017_The Unavoidable Convergence of NFV, 5G, and Fog.pdf:application/pdf},
}

@inproceedings{vilalta_control_2018,
	title = {Control and Management of a Connected Car Using {SDN}/{NFV}, Fog Computing and {YANG} data models},
	doi = {10.1109/NETSOFT.2018.8460131},
	abstract = {There are several use cases that claim the need for a connected car. Among them there is the need for connectivity between vehicles and information sources, or V2V and V2X exchanges for accident prevention. In order to cope with the need for novel applications running on top of an interconnected network, the concept of fog computing appears as a realistic solution for both intra-car and inter-car data processing and decision making. This paper describes the proposed architecture and experimental evaluation of an innovative proof-of-concept ({PoC}) for a connected car, modeled with {YANG}, which can be remotely controlled using {SDN}/{NFV} and fog computing technologies. As an example, the remote control of the car might be based on a service application running on a fog node, which can be located close to a road side unit ({RSU}). We also propose a fog architecture in order to enable cooperative perception between connected cars. Finally, the performance evaluation uses a {RESTCONF} server installed in a Raspberry Pi aboard of a small car. This server is responsible for the sensors and actuators of the car and allows for its remote control from a user terminal (e.g., a smartphone, tablet, or laptop) and through the fog node, running a control application as a service.},
	eventtitle = {2018 4th {IEEE} Conference on Network Softwarization and Workshops ({NetSoft})},
	pages = {378--383},
	booktitle = {2018 4th {IEEE} Conference on Network Softwarization and Workshops ({NetSoft})},
	author = {Vilalta, Ricard and Vía, Selva and Mira, Fermín and Casellas, Ramon and Muñoz, Raul and Alonso-Zarate, Jesus and Kousaridas, Apostolos and Dillinger, Markus},
	date = {2018-06},
	keywords = {Cloud computing, Edge computing, Data models, Computer architecture, 5G, {SDN}, Protocols, Automobiles, Connected Car, {NFV}, Sensors, {YANG}},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/U7EYV6TK/8460131.html:text/html;Vilalta et al_2018_Control and Management of a Connected Car Using SDN-NFV, Fog Computing and YANG.pdf:/home/volodia/Zotero/storage/E92DZC7F/Vilalta et al_2018_Control and Management of a Connected Car Using SDN-NFV, Fog Computing and YANG.pdf:application/pdf},
}

@article{mouradian_application_2019,
	title = {Application Component Placement in {NFV}-Based Hybrid Cloud/Fog Systems With Mobile Fog Nodes},
	volume = {37},
	issn = {1558-0008},
	doi = {10.1109/JSAC.2019.2906790},
	abstract = {Fog computing reduces the latency induced by distant clouds by enabling the deployment of some application components at the edge of the network, on fog nodes, while keeping others in the cloud. Application components can be implemented as Virtual Network Functions ({VNFs}) and their execution sequences can be modeled by a combination of sub-structures like sequence, parallel, selection, and loops. Efficient placement algorithms are required to map the application components onto the infrastructure nodes. Current solutions do not consider the mobility of fog nodes, a phenomenon which may happen in real systems. In this paper, we use the random waypoint mobility model for fog nodes to calculate the expected makespan and application execution cost. We then model the problem as an Integer Linear Programming ({ILP}) formulation which minimizes an aggregated weighted function of the makespan and cost. We propose a Tabu Search-based Component Placement ({TSCP}) algorithm to find sub-optimal placements. The results show that the proposed algorithm improves the makespan and the application execution cost.},
	pages = {1130--1143},
	number = {5},
	journaltitle = {{IEEE} Journal on Selected Areas in Communications},
	author = {Mouradian, Carla and Kianpisheh, Somayeh and Abu-Lebdeh, Mohammad and Ebrahimnezhad, Fereshteh and Jahromi, Narjes Tahghigh and Glitho, Roch H.},
	date = {2019-05},
	note = {Conference Name: {IEEE} Journal on Selected Areas in Communications},
	keywords = {cloud computing, Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Data centers, Sensors, Component placement, Drones, Earthquakes, Network function virtualization, Network Functions Virtualization ({NFV}), optimization, Tabu Search},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/BQN6GB9Y/8673549.html:text/html;Mouradian et al_2019_Application Component Placement in NFV-Based Hybrid Cloud-Fog Systems With.pdf:/home/volodia/Zotero/storage/HNSS4AEE/Mouradian et al_2019_Application Component Placement in NFV-Based Hybrid Cloud-Fog Systems With.pdf:application/pdf},
}

@article{bi_mobility_2018,
	title = {Mobility Support for Fog Computing: An {SDN} Approach},
	volume = {56},
	issn = {1558-1896},
	doi = {10.1109/MCOM.2018.1700908},
	shorttitle = {Mobility Support for Fog Computing},
	abstract = {The emerging real-time and computation-intensive services driven by the Internet of Things, augmented reality, automatic driving, and so on, have tight quality of service and quality of experience requirements, which can hardly be supported by conventional cloud computing. Fog computing, which migrates the features of cloud computing to the network edge, guarantees low latency for location-aware services. However, due to the locality feature of fog computing, maintaining service continuity when mobile users travel across different access networks has become a challenging issue. In this article, we propose a novel software-defined-networking-based fog computing architecture by decoupling mobility control and data forwarding. Under the proposed architecture, we design efficient signaling operations to provide seamless and transparent mobility support to mobile users, and present an efficient route optimization algorithm by considering the performance gain in data communications and system overhead in mobile fog computing. Numerical results from extensive simulations have demonstrated that the proposed scheme can not only guarantee service continuity, but also greatly improve handover performance and achieve high data communication efficiency in mobile fog computing.},
	pages = {53--59},
	number = {5},
	journaltitle = {{IEEE} Communications Magazine},
	author = {Bi, Yuanguo and Han, Guangjie and Lin, Chuan and Deng, Qingxu and Guo, Lei and Li, Fuliang},
	date = {2018-05},
	note = {Conference Name: {IEEE} Communications Magazine},
	keywords = {Edge computing, Routing, Computer architecture, Internet of Things, Energy efficiency, Frequency selective surfaces, Handover},
	file = {Bi et al_2018_Mobility Support for Fog Computing.pdf:/home/volodia/Zotero/storage/7DL4HGHQ/Bi et al_2018_Mobility Support for Fog Computing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/P637ZCWW/8360850.html:text/html},
}

@inproceedings{khakimov_iot-fog_2018,
	location = {New York, {NY}, {USA}},
	title = {{IoT}-fog based system structure with {SDN} enabled},
	isbn = {978-1-4503-6428-7},
	url = {https://doi.org/10.1145/3231053.3231129},
	doi = {10.1145/3231053.3231129},
	series = {{ICFNDS} '18},
	abstract = {{IoT} is a new communication paradigm that gains a very high importance in the past few years. Fog computing is a form of edge computing that is developed to provide the computing, storage and management capabilities near to users. Employing Fog computing in {IoT} networks as an intermediate layer between {IoT} devices and the remote cloud becomes a demand to make use of the edge computing benefits. In this work, we provide a framework for {IoT} system structure that employs an edge computing layer of Fog nodes. The system employs {SDN} network with a centralized controller and distributed {OpenFlow} switches; these switches are enabled with limited computing and processing capabilities. The network is operated based on a data offloading algorithm, that allocates certain processing and computing tasks to some {OpenFlow} switches that has unused resources. The proposed work achieves various benefits to the {IoT} network such as the latency reduction and higher efficiency of resources utilization. We perform an experiment over a developed testbed to validate the proposed system and results show that the proposed system achieves higher efficiency in terms of latency and resource utilization.},
	pages = {1--6},
	booktitle = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
	publisher = {Association for Computing Machinery},
	author = {Khakimov, Abdukodir and Ateya, Abdelhamied A. and Muthanna, Ammar and Gudkova, Irina and Markova, Ekaterina and Koucheryavy, Andrey},
	urldate = {2022-02-14},
	date = {2018-06-26},
	keywords = {fog computing, {SDN}, internet of things, latency, openflow},
	file = {Khakimov et al_2018_IoT-fog based system structure with SDN enabled.pdf:/home/volodia/Zotero/storage/TJGKMWQH/Khakimov et al_2018_IoT-fog based system structure with SDN enabled.pdf:application/pdf},
}

@article{dabbagh_software-defined_2015,
	title = {Software-defined networking security: pros and cons},
	volume = {53},
	issn = {1558-1896},
	doi = {10.1109/MCOM.2015.7120048},
	shorttitle = {Software-defined networking security},
	abstract = {Software-defined networking ({SDN}) is a new networking paradigm that decouples the forwarding and control planes, traditionally coupled with one another, while adopting a logically centralized architecture aiming to increase network agility and programability. While many efforts are currently being made to standardize this emerging paradigm, careful attention needs to be paid to security at this early design stage too, rather than waiting until the technology becomes mature, thereby potentially avoiding previous pitfalls made when designing the Internet in the 1980s. This article focuses on the security aspects of {SDN} networks. We begin by discussing the new security advantages that {SDN} brings and by showing how some of the long-lasting issues in network security can be addressed by exploiting {SDN} capabilities. Then we describe the new security threats that {SDN} is faced with and discuss possible techniques that can be used to prevent and mitigate such threats.},
	pages = {73--79},
	number = {6},
	journaltitle = {{IEEE} Communications Magazine},
	author = {Dabbagh, Mehiar and Hamdaoui, Bechir and Guizani, Mohsen and Rayes, Ammar},
	date = {2015-06},
	note = {Conference Name: {IEEE} Communications Magazine},
	keywords = {5G mobile communication, Communication standards, {IEEE} standards, Network security, Software radio, Standards, Telecommunication traffic},
	file = {Dabbagh et al_2015_Software-defined networking security.pdf:/home/volodia/Zotero/storage/7C3QD4HS/Dabbagh et al_2015_Software-defined networking security.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/H9HY4IBM/7120048.html:text/html},
}

@inproceedings{winzinger_model-based_2019,
	title = {Model-Based Analysis of Serverless Applications},
	doi = {10.1109/MiSE.2019.00020},
	abstract = {Serverless computing is a relatively new execution model where the cloud platform provider manages the allocation of resources for containerized functions dynamically. This evolving paradigm is called Function as a Service ({FaaS}). The statelessness of these functions enables the application to be scaled up elastically in the case of peak loads. They can be tested easily in isolation, but the behavior arising by integrating them to an application is both hard to predict and test. The parallel execution of the functions and the shift of its state to data storages can cause several workflows accessing the same data. These workflows are hard to detect, particularly for complex applications. Therefore, we suggest an approach for modelling an existing serverless application based on a specialized graph holding all relevant features. Our serverless-specific model can be applied during the whole life cycle of a complex application and offers a good basis for this specific class of applications. It helps to optimize an existing system by identifying hot spots, supports the generation of test cases and can be used to monitor an existing system. Furthermore, we show how the generation of the model can be automated by realizing a tool supporting Amazon's {AWS} Lambda.},
	eventtitle = {2019 {IEEE}/{ACM} 11th International Workshop on Modelling in Software Engineering ({MiSE})},
	pages = {82--88},
	booktitle = {2019 {IEEE}/{ACM} 11th International Workshop on Modelling in Software Engineering ({MiSE})},
	author = {Winzinger, Stefan and Wirtz, Guido},
	date = {2019-05},
	note = {{ISSN}: 2575-4475},
	keywords = {Cloud computing, Computational modeling, Data models, Analytical models, Memory, serverless computing, {FaaS}, dependency graph, model-driven testing, integration testing, cloud functions, Testing, Tools},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/GUHTQ9RF/8877078.html:text/html;Winzinger_Wirtz_2019_Model-Based Analysis of Serverless Applications.pdf:/home/volodia/Zotero/storage/CBRF47LV/Winzinger_Wirtz_2019_Model-Based Analysis of Serverless Applications.pdf:application/pdf},
}

@article{ascigil_resource_2021-1,
	title = {Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds},
	issn = {1939-1374},
	doi = {10.1109/TSC.2021.3052139},
	abstract = {Edge computing has emerged as a new paradigm to bring cloud applications closer to users for increased performance. Unlike back-end cloud systems which consolidate their resources in a centralized data center location with virtually unlimited capacity, edge-clouds comprise distributed resources at various computation spots, each with very limited capacity. In this paper, we consider Function-as-a-Service ({FaaS}) edge-clouds where application providers deploy their latency-critical functions that process user requests with strict response time deadlines. In this setting, we investigate the problem of resource provisioning and allocation. After formulating the optimal solution, we propose resource allocation and provisioning algorithms across the spectrum of fully-centralized to fully-decentralized. We evaluate the performance of these algorithms in terms of their ability to utilize {CPU} resources and meet request deadlines under various system parameters. Our results indicate that practical decentralized strategies, which require no coordination among computation spots, achieve performance that is close to the optimal fully-centralized strategy with coordination overheads.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Ascigil, Onur and Tasiopoulos, Argyrios and Phan, Truong Khoa and Sourlas, Vasilis and Psaras, Ioannis and Pavlou, George},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Services Computing},
	keywords = {Cloud computing, Delays, Containers, {FAA}, Image edge detection, Resource management, Routing},
	file = {Full Text:/home/volodia/Zotero/storage/Q8IQDZ83/Ascigil et al. - 2021 - Resource Provisioning and Allocation in Function-a.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/LQJY3YQR/9326369.html:text/html;Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds:/home/volodia/Zotero/storage/5729PYGA/ascigil2021.pdf.pdf:application/pdf},
}

@article{das_performance_2020,
	title = {Performance Optimization for Edge-Cloud Serverless Platforms via Dynamic Task Placement},
	url = {http://arxiv.org/abs/2003.01310},
	abstract = {We present a framework for performance optimization in serverless edge-cloud platforms using dynamic task placement. We focus on applications for smart edge devices, for example, smart cameras or speakers, that need to perform processing tasks on input data in real to near-real time. Our framework allows the user to specify cost and latency requirements for each application task, and for each input, it determines whether to execute the task on the edge device or in the cloud. Further, for cloud executions, the framework identifies the container resource configuration needed to satisfy the performance goals. We have evaluated our framework in simulation using measurements collected from serverless applications in {AWS} Lambda and {AWS} Greengrass. In addition, we have implemented a prototype of our framework that runs in these same platforms. In experiments with our prototype, our models can predict average end-to-end latency with less than 6\% error, and we obtain almost three orders of magnitude reduction in end-to-end latency compared to edge-only execution.},
	journaltitle = {{arXiv}:2003.01310 [cs]},
	author = {Das, Anirban and Imai, Shigeru and Wittie, Mike P. and Patterson, Stacy},
	urldate = {2021-11-15},
	date = {2020-05-19},
	eprinttype = {arxiv},
	eprint = {2003.01310},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file = {arXiv.org Snapshot:/home/volodia/Zotero/storage/5N7GKWLT/2003.html:text/html;Das et al_2020_Performance Optimization for Edge-Cloud Serverless Platforms via Dynamic Task.pdf:/home/volodia/Zotero/storage/BR2RNJQY/Das et al_2020_Performance Optimization for Edge-Cloud Serverless Platforms via Dynamic Task.pdf:application/pdf},
}

@inproceedings{palade_swarm-based_2020,
	title = {A Swarm-based Approach for Function Placement in Federated Edges},
	doi = {10.1109/SCC49832.2020.00013},
	abstract = {Multi-access Edge Computing ({MEC}) provides cloud computing capabilities at the edge by offloading users' service requests on {MEC} servers deployed at Base Stations ({BS}). Optimising the resource allocation on such distributed units in a physical area such as a city, especially for compute-intensive and latency-critical services, is a key challenge. We propose a swarm-based approach for placing functions in the edge using a serverless architecture, which does not require services to pre-occupy the required computing resources. The approach uses a probabilistic model to decide where to place the functions while considering the resources available at each {MEC} server and the latency between the physical servers and the application requester. A central controller with a federated view of available {MEC} servers orchestrates functions' deployment and deals changes available resources. We compare our approach against the Best-Fit, Max-Fit, {MultiOpt}, {ILP} and Random baselines. Results show that our approach can reduce the latency of applications with limited effect on the resource utilisation.},
	eventtitle = {2020 {IEEE} International Conference on Services Computing ({SCC})},
	pages = {48--50},
	booktitle = {2020 {IEEE} International Conference on Services Computing ({SCC})},
	author = {Palade, Andrei and Mukhopadhyay, Atri and Kazmi, Aqeel and Cabrera, Christian and Nomayo, Evelyn and Iosifidis, Georgios and Ruffini, Marco and Clarke, Siobhán},
	date = {2020-11},
	note = {{ISSN}: 2474-2473},
	keywords = {Edge computing, Edge Computing, Servers, Resource management, Conferences, Serverless, Probabilistic logic, Service computing, Service Placement, Urban areas},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/TXWAJXA3/9284644.html:text/html;Palade et al_2020_A Swarm-based Approach for Function Placement in Federated Edges.pdf:/home/volodia/Zotero/storage/KPL2VXZU/Palade et al_2020_A Swarm-based Approach for Function Placement in Federated Edges.pdf:application/pdf},
}

@inproceedings{kaffes_centralized_2019,
	location = {New York, {NY}, {USA}},
	title = {Centralized Core-granular Scheduling for Serverless Functions},
	isbn = {978-1-4503-6973-2},
	url = {https://doi.org/10.1145/3357223.3362709},
	doi = {10.1145/3357223.3362709},
	series = {{SoCC} '19},
	abstract = {In recent years, many applications have started using serverless computing platforms primarily due to the ease of deployment and cost efficiency they offer. However, the existing scheduling mechanisms of serverless platforms fall short in catering to the unique characteristics of such applications: burstiness, short and variable execution times, statelessness and use of a single core. Specifically, the existing mechanisms fall short in meeting the requirements generated due to the combined effect of these characteristics: scheduling at a scale of millions of function invocations per second while achieving predictable performance. In this paper, we argue for a cluster-level centralized and core-granular scheduler for serverless functions. By maintaining a global view of the cluster resources, the centralized approach eliminates queue imbalances while the core granularity reduces interference; together these properties enable reduced performance variability. We expect such a scheduler to increase the adoption of serverless computing platforms by various latency and throughput sensitive applications.},
	pages = {158--164},
	booktitle = {Proceedings of the {ACM} Symposium on Cloud Computing},
	publisher = {Association for Computing Machinery},
	author = {Kaffes, Kostis and Yadwadkar, Neeraja J. and Kozyrakis, Christos},
	urldate = {2021-12-01},
	date = {2019-11-20},
	keywords = {cloud computing, resource allocation, scheduling, serverless computing},
	file = {Kaffes et al_2019_Centralized Core-granular Scheduling for Serverless Functions.pdf:/home/volodia/Zotero/storage/P2XMJCTY/Kaffes et al_2019_Centralized Core-granular Scheduling for Serverless Functions.pdf:application/pdf},
}

@article{wang_lass_2021,
	title = {{LaSS}: Running Latency Sensitive Serverless Computations at the Edge},
	url = {http://arxiv.org/abs/2104.14087},
	doi = {10.1145/3431379.3460646},
	shorttitle = {{LaSS}},
	abstract = {Serverless computing has emerged as a new paradigm for running short-lived computations in the cloud. Due to its ability to handle {IoT} workloads, there has been considerable interest in running serverless functions at the edge. However, the constrained nature of the edge and the latency sensitive nature of workloads result in many challenges for serverless platforms. In this paper, we present {LaSS}, a platform that uses model-driven approaches for running latency-sensitive serverless computations on edge resources. {LaSS} uses principled queuing-based methods to determine an appropriate allocation for each hosted function and auto-scales the allocated resources in response to workload dynamics. {LaSS} uses a fair-share allocation approach to guarantee a minimum of allocated resources to each function in the presence of overload. In addition, it utilizes resource reclamation methods based on container deflation and termination to reassign resources from over-provisioned functions to under-provisioned ones. We implement a prototype of our approach on an {OpenWhisk} serverless edge cluster and conduct a detailed experimental evaluation. Our results show that {LaSS} can accurately predict the resources needed for serverless functions in the presence of highly dynamic workloads, and reprovision container capacity within hundreds of milliseconds while maintaining fair share allocation guarantees.},
	pages = {239--251},
	journaltitle = {Proceedings of the 30th International Symposium on High-Performance Parallel and Distributed Computing},
	author = {Wang, Bin and Ali-Eldin, Ahmed and Shenoy, Prashant},
	urldate = {2021-11-15},
	date = {2021-06-21},
	eprinttype = {arxiv},
	eprint = {2104.14087},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv Fulltext PDF:/home/volodia/Zotero/storage/YMF25NCK/Wang et al. - 2021 - LaSS Running Latency Sensitive Serverless Computa.pdf:application/pdf;arXiv.org Snapshot:/home/volodia/Zotero/storage/NGMSBFPU/2104.html:text/html;LaSS\: Running Latency Sensitive Serverless Computations at the Edge:/home/volodia/Zotero/storage/8BKPI2W8/wang2020.pdf.pdf:application/pdf},
}

@article{rausch_optimized_2021,
	title = {Optimized container scheduling for data-intensive serverless edge computing},
	volume = {114},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X2030399X},
	doi = {10.1016/j.future.2020.07.017},
	abstract = {Operating data-intensive applications on edge systems is challenging, due to the extreme workload and device heterogeneity, as well as the geographic dispersion of compute and storage infrastructure. Serverless computing has emerged as a compelling model to manage the complexity of such systems, by decoupling the underlying infrastructure and scaling mechanisms from applications. Although serverless platforms have reached a high level of maturity, we have found several limiting factors that inhibit their use in an edge setting. This paper presents a container scheduling system that enables such platforms to make efficient use of edge infrastructures. Our scheduler makes heuristic trade-offs between data and computation movement, and considers workload-specific compute requirements such as {GPU} acceleration. Furthermore, we present a method to automatically fine-tune the weights of scheduling constraints to optimize high-level operational objectives such as minimizing task execution time, uplink usage, or cloud execution cost. We implement a prototype that targets the container orchestration system Kubernetes, and deploy it on an edge testbed we have built. We evaluate our system with trace-driven simulations in different infrastructure scenarios, using traces generated from running representative workloads on our testbed. Our results show that (a) our scheduler significantly improves the quality of task placement compared to the state-of-the-art scheduler of Kubernetes, and (b) our method for fine-tuning scheduling parameters helps significantly in meeting operational goals.},
	pages = {259--271},
	journaltitle = {Future Generation Computer Systems},
	shortjournal = {Future Generation Computer Systems},
	author = {Rausch, Thomas and Rashed, Alexander and Dustdar, Schahram},
	urldate = {2021-11-15},
	date = {2021-01-01},
	langid = {english},
	keywords = {Edge computing, Serverless, Container scheduling, Machine learning},
	file = {Rausch et al_2021_Optimized container scheduling for data-intensive serverless edge computing.pdf:/home/volodia/Zotero/storage/B8B774HQ/Rausch et al_2021_Optimized container scheduling for data-intensive serverless edge computing.pdf:application/pdf},
}

@inproceedings{elgamal_costless_2018,
	title = {Costless: Optimizing Cost of Serverless Computing through Function Fusion and Placement},
	doi = {10.1109/SEC.2018.00029},
	shorttitle = {Costless},
	abstract = {Serverless computing has recently experienced significant adoption by several applications, especially Internet of Things ({IoT}) applications. In serverless computing, rather than deploying and managing dedicated virtual machines, users are able to deploy individual functions, and pay only for the time that their code is actually executing. However, since serverless platforms are relatively new, they have a completely different pricing model that depends on the memory, duration, and the number of executions of a sequence/workflow of functions. In this paper we present an algorithm that optimizes the price of serverless applications in {AWS} Lambda. We first describe the factors affecting price of serverless applications which include: (1) fusing a sequence of functions, (2) splitting functions across edge and cloud resources, and (3) allocating the memory for each function. We then present an efficient algorithm to explore different function fusion-placement solutions and find the solution that optimizes the application's price while keeping the latency under a certain threshold. Our results on image processing workflows show that the algorithm can find solutions optimizing the price by more than 35\%-57\% with only 5\%-15\% increase in latency. We also show that our algorithm can find non-trivial memory configurations that reduce both latency and price.},
	eventtitle = {2018 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	pages = {300--312},
	booktitle = {2018 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	author = {Elgamal, Tarek},
	date = {2018-10},
	keywords = {Cloud computing, Edge computing, Computational modeling, Cloud Computing, Pricing, Serverless, Internet of Things, {AWS} Lambda, Cost Optimization, Face, Fuses, Memory management},
	file = {Costless\: Optimizing Cost of Serverless Computing through Function Fusion and Placement:/home/volodia/Zotero/storage/XKJGBAUJ/df7ac33bf08b28a3b6cfdd661c3b41c4.pdf.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/8VA9QMDH/8567674.html:text/html;Submitted Version:/home/volodia/Zotero/storage/GVC95K96/Elgamal - 2018 - Costless Optimizing Cost of Serverless Computing .pdf:application/pdf},
}

@inproceedings{george_nanolambda_2020,
	location = {San Jose, {CA}, {USA}},
	title = {{NanoLambda}: Implementing Functions as a Service at All Resource Scales for the Internet of Things.},
	isbn = {978-1-72815-943-0},
	url = {https://ieeexplore.ieee.org/document/9355717/},
	doi = {10.1109/SEC50012.2020.00035},
	shorttitle = {{NanoLambda}},
	abstract = {Internet of Things ({IoT}) devices are becoming increasingly prevalent in our environment, yet the process of programming these devices and processing the data they produce remains difﬁcult. Typically, data is processed on device, involving arduous work in low level languages, or data is moved to the cloud, where abundant resources are available for Functions as a Service ({FaaS}) or other handlers. {FaaS} is an emerging category of ﬂexible computing services, where developers deploy self-contained functions to be run in portable and secure containerized environments; however, at the moment, these functions are limited to running in the cloud or in some cases at the “edge” of the network using resource rich, Linux-based systems.},
	eventtitle = {2020 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	pages = {220--231},
	booktitle = {2020 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	publisher = {{IEEE}},
	author = {George, Gareth and Bakir, Fatih and Wolski, Rich and Krintz, Chandra},
	urldate = {2021-11-15},
	date = {2020-11},
	langid = {english},
	file = {George et al. - 2020 - NanoLambda Implementing Functions as a Service at.pdf:/home/volodia/Zotero/storage/QNJP57CD/George et al. - 2020 - NanoLambda Implementing Functions as a Service at.pdf:application/pdf;NanoLambda\: Implementing Functions as a Service at All Resource Scales for the Internet of Things.:/home/volodia/Zotero/storage/34MGUTFD/george2020.pdf.pdf:application/pdf},
}

@online{qiu_is_2021,
	title = {Is Function-as-a-Service a Good Fit for Latency-Critical Services?},
	url = {https://haoran-qiu.com/publication/wosc-2021/},
	abstract = {Function-as-a-Service ({FaaS}) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher server utilization, often at the cost of higher end-toend function request latency. Interestingly, a key aspect of serverless latency management has not been well studied: the trade-off between application developers’ latency goals and the {FaaS} providers’ utilization goals. This paper presents a multi-faceted, measurement-driven study of latency variation in serverless platforms that elucidates this trade-off space. We obtained production measurements by executing {FaaS} benchmarks on {IBM} Cloud and a private cloud to study the impact of workload consolidation, queuing delay, and cold starts on the end-to-end function request latency. We draw several conclusions. For example, increasing a container’s allocated memory limit from 128 {MB} to 256 {MB} reduces the tail latency by 2x but has 1.75x higher power consumption and 59\% lower {CPU} utilization.},
	titleaddon = {Haoran Qiu @Illinois {CS}},
	author = {Qiu, Haoran},
	urldate = {2021-12-01},
	date = {2021-11-19},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/VL7NA5CI/wosc-2021.html:text/html},
}

@inproceedings{shahrad_architectural_2019,
	location = {New York, {NY}, {USA}},
	title = {Architectural Implications of Function-as-a-Service Computing},
	isbn = {978-1-4503-6938-1},
	url = {https://doi.org/10.1145/3352460.3358296},
	doi = {10.1145/3352460.3358296},
	series = {{MICRO} '52},
	abstract = {Serverless computing is a rapidly growing cloud application model, popularized by Amazon's Lambda platform. Serverless cloud services provide fine-grained provisioning of resources, which scale automatically with user demand. Function-as-a-Service ({FaaS}) applications follow this serverless model, with the developer providing their application as a set of functions which are executed in response to a user- or system-generated event. Functions are designed to be short-lived and execute inside containers or virtual machines, introducing a range of system-level overheads. This paper studies the architectural implications of this emerging paradigm. Using the commercial-grade Apache {OpenWhisk} {FaaS} platform on real servers, this work investigates and identifies the architectural implications of {FaaS} serverless computing. The workloads, along with the way that {FaaS} inherently interleaves short functions from many tenants frustrates many of the locality-preserving architectural structures common in modern processors. In particular, we find that: {FaaS} containerization brings up to 20x slowdown compared to native execution, cold-start can be over 10x a short function's execution time, branch mispredictions per kilo-instruction are 20x higher for short functions, memory bandwidth increases by 6x due to the invocation pattern, and {IPC} decreases by as much as 35\% due to inter-function interference. We open-source {FaaSProfiler}, the {FaaS} testing and profiling platform that we developed for this work.},
	pages = {1063--1075},
	booktitle = {Proceedings of the 52nd Annual {IEEE}/{ACM} International Symposium on Microarchitecture},
	publisher = {Association for Computing Machinery},
	author = {Shahrad, Mohammad and Balkind, Jonathan and Wentzlaff, David},
	urldate = {2021-12-01},
	date = {2019-10-12},
	keywords = {function-as-a-service, serverless, faas, architecture, cloud, {OpenWhisk}},
	file = {Architectural Implications of Function-as-a-Service Computing:/home/volodia/Zotero/storage/58FAH3KK/shahrad2019.pdf.pdf:application/pdf;Full Text PDF:/home/volodia/Zotero/storage/2CIB3CHF/Shahrad et al. - 2019 - Architectural Implications of Function-as-a-Servic.pdf:application/pdf},
}

@inproceedings{shen_defuse_2021,
	title = {Defuse: A Dependency-Guided Function Scheduler to Mitigate Cold Starts on {FaaS} Platforms},
	doi = {10.1109/ICDCS51616.2021.00027},
	shorttitle = {Defuse},
	abstract = {Function-as-a-Service ({FaaS}) is becoming a prevalent paradigm in developing cloud applications. With {FaaS}, clients can develop applications as serverless functions, leaving the burden of resource management to cloud providers. However, {FaaS} platforms suffer from the performance degradation caused by the cold starts of serverless functions. Cold starts happen when serverless functions are invoked before they have been loaded into the memory. The problem is unavoidable because the memory in datacenters is typically too limited to hold all serverless functions simultaneously. The latency of cold function invocations will greatly degenerate the performance of {FaaS} platforms. Currently, {FaaS} platforms employ various scheduling methods to reduce the occurrences of cold starts. However, they do not consider the ubiquitous dependencies between serverless functions. Observing the potential of using dependencies to mitigate cold starts, we propose Defuse, a Dependency-guided Function Scheduler on {FaaS} platforms. Specifically, Defuse identifies two types of dependencies between serverless functions, i.e., strong dependencies and weak ones. It uses frequent pattern mining and positive point-wise mutual information to mine such dependencies respectively from function invocation histories. In this way, Defuse constructs a function dependency graph. The connected components (i.e., dependent functions) on the graph can be scheduled to diminish the occurrences of cold starts. We evaluate the effectiveness of Defuse by applying it to an industrial serverless dataset. The experimental results show that Defuse can reduce 22\% of memory usage while having a 35\% decrease in function cold-start rates compared with the state-of-the-art method.},
	eventtitle = {2021 {IEEE} 41st International Conference on Distributed Computing Systems ({ICDCS})},
	pages = {194--204},
	booktitle = {2021 {IEEE} 41st International Conference on Distributed Computing Systems ({ICDCS})},
	author = {Shen, Jiacheng and Yang, Tianyi and Su, Yuxin and Zhou, Yangfan and Lyu, Michael R.},
	date = {2021-07},
	note = {{ISSN}: 2575-8411},
	keywords = {Cloud Computing, {FAA}, Resource management, {FaaS}, Serverless, Memory management, Cold Start, Job shop scheduling, Processor scheduling, Schedules, Service Dependency, System improvement},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DNB45QNE/9546470.html:text/html;Shen et al_2021_Defuse.pdf:/home/volodia/Zotero/storage/7WMQRQEE/Shen et al_2021_Defuse.pdf:application/pdf},
}

@inproceedings{rossi_gofs_2021,
	title = {{GOFS}: Geo-distributed Scheduling in {OpenFaaS}},
	doi = {10.1109/ISCC53001.2021.9631492},
	shorttitle = {{GOFS}},
	abstract = {{OpenFaaS} is a popular open-source serverless platform in the academic and industrial world. Based on Ku-bernetes, {OpenFaaS} includes a simple scheduling policy that spreads functions on cluster computing resources. As such, it is not well-suited for managing latency-sensitive applications in a geo-distributed environment, where network latencies are nonnegligible and negatively affect the application response time. To overcome this issue, in this paper we present {GOFS} (Geo-distributed Scheduling in {OpenFaaS}), which extends {OpenFaaS} with network-aware scheduling capabilities. {GOFS} addresses the serverless application scheduling in a geo-distributed environment by either solving a suitable integer linear programming problem or using a greedy network-aware heuristic. However, its modular architecture facilitates the integration of other custom scheduling policies. A wide set of prototype-based results shows the advantages of the proposed network-aware solutions over other benchmark scheduling policies.},
	eventtitle = {2021 {IEEE} Symposium on Computers and Communications ({ISCC})},
	pages = {1--6},
	booktitle = {2021 {IEEE} Symposium on Computers and Communications ({ISCC})},
	author = {Rossi, Fabiana and Falvo, Simone and Cardellini, Valeria},
	date = {2021-09},
	note = {{ISSN}: 2642-7389},
	keywords = {Computer architecture, Job shop scheduling, Processor scheduling, Fault tolerant systems, Geo-distributed, Measurement, {OpenFaaS}, Optical fibers, Optimal scheduling, Scheduling},
	file = {Rossi et al_2021_GOFS.pdf:/home/volodia/Zotero/storage/AUN6EEQT/Rossi et al_2021_GOFS.pdf:application/pdf},
}

@article{bocci_secure_2021,
	title = {Secure {FaaS} orchestration in the fog: how far are we?},
	volume = {103},
	issn = {1436-5057},
	url = {https://doi.org/10.1007/s00607-021-00924-y},
	doi = {10.1007/s00607-021-00924-y},
	shorttitle = {Secure {FaaS} orchestration in the fog},
	abstract = {Function-as-a-Service ({FaaS}) allows developers to define, orchestrate and run modular event-based pieces of code on virtualised resources, without the burden of managing the underlying infrastructure nor the life-cycle of such pieces of code. Indeed, {FaaS} providers offer resource auto-provisioning, auto-scaling and pay-per-use billing at no costs for idle time. This makes it easy to scale running code and it represents an effective and increasingly adopted way to deliver software. This article aims at offering an overview of the existing literature in the field of next-gen {FaaS} from three different perspectives: (i) the definition of {FaaS} orchestrations, (ii) the execution of {FaaS} orchestrations in Fog computing environments, and (iii) the security of {FaaS} orchestrations. Our analysis identify trends and gaps in the literature, paving the way to further research on securing {FaaS} orchestrations in Fog computing landscapes.},
	pages = {1025--1056},
	number = {5},
	journaltitle = {Computing},
	shortjournal = {Computing},
	author = {Bocci, Alessandro and Forti, Stefano and Ferrari, Gian-Luigi and Brogi, Antonio},
	urldate = {2022-02-15},
	date = {2021-05-01},
	langid = {english},
	file = {Bocci et al_2021_Secure FaaS orchestration in the fog.pdf:/home/volodia/Zotero/storage/YRBG4I3M/Bocci et al_2021_Secure FaaS orchestration in the fog.pdf:application/pdf},
}

@article{yang_edgebench_2020,
	title = {{EdgeBench}: A Workflow-based Benchmark for Edge Computing},
	url = {http://arxiv.org/abs/2010.14027},
	shorttitle = {{EdgeBench}},
	abstract = {Edge computing has been developed to utilize multiple tiers of resources for privacy, cost and Quality of Service ({QoS}) reasons. Edge workloads have the characteristics of data-driven and latency-sensitive. Because of this, edge systems have developed to be both heterogeneous and distributed. The unique characteristics of edge workloads and edge systems have motivated {EdgeBench}, a workflow-based benchmark aims to provide the ability to explore the full design space of edge workloads and edge systems. {EdgeBench} is both customizable and representative. It allows users to customize the workflow logic of edge workloads, the data storage backends, and the distribution of the individual workflow stages to different computing tiers. To illustrate the usability of {EdgeBench}, we also implements two representative edge workflows, a video analytics workflow and an {IoT} hub workflow that represents two distinct but common edge workloads. Both workflows are evaluated using the workflow-level and function-level metrics reported by {EdgeBench} to illustrate both the performance bottlenecks of the edge systems and the edge workloads.},
	journaltitle = {{arXiv}:2010.14027 [cs]},
	author = {Yang, Qirui and Jin, Runyu and Gandhi, Nabil and Ge, Xiongzi and Khouzani, Hoda Aghaei and Zhao, Ming},
	urldate = {2022-02-15},
	date = {2020-10-26},
	eprinttype = {arxiv},
	eprint = {2010.14027},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance},
	file = {arXiv.org Snapshot:/home/volodia/Zotero/storage/WGHQMXGA/2010.html:text/html;Yang et al_2020_EdgeBench.pdf:/home/volodia/Zotero/storage/TSP9M9VC/Yang et al_2020_EdgeBench.pdf:application/pdf},
}

@inproceedings{persson_kappa_2017,
	location = {New York, {NY}, {USA}},
	title = {Kappa: serverless {IoT} deployment},
	isbn = {978-1-4503-5434-9},
	url = {https://doi.org/10.1145/3154847.3154853},
	doi = {10.1145/3154847.3154853},
	series = {{WoSC} '17},
	shorttitle = {Kappa},
	abstract = {A recent evolution in cloud computing is the move to serverless applications, where the separation between the server platform and the application is complete, and developers can fully focus on the application, leaving all provisioning details to a cloud provider. In this paper we look at how the serverless computing model can be adopted all the way to the edge devices using the Kappa framework, built on the Calvin platform for distributed cloud and {IoT} applications. Combining the resource management of the platform, where capabilities of nodes are matched with the requirements of the execution units, with a {RESTful} {API} it is possible to build an {IoT} system with a straightforward intuitive interface while still retaining the flexibility of the Calvin platform. We also give examples of how the framework can be used in an industrial {IoT} setting.},
	pages = {16--21},
	booktitle = {Proceedings of the 2nd International Workshop on Serverless Computing},
	publisher = {Association for Computing Machinery},
	author = {Persson, Per and Angelsmark, Ola},
	urldate = {2022-02-15},
	date = {2017-12-11},
	keywords = {cloud computing, serverless, {IoT}, {FaaS}, actor model, data flow},
	file = {Persson_Angelsmark_2017_Kappa.pdf:/home/volodia/Zotero/storage/EPZ6BE5R/Persson_Angelsmark_2017_Kappa.pdf:application/pdf},
}

@inproceedings{tarneberg_experiences_2016,
	title = {Experiences Creating a Framework for Smart Traffic Control Using {AWS} {IOT}},
	abstract = {Public clouds such as Amazon Web Services ({AWS}) and Microsoft's Azure provide excellent capabilities for scalable Web applications and Hadoop-based processing. Recent additions to public clouds to support connected devices and {IoT} have the potential to similarly disrupt emerging home-grown and/or proprietary approaches. While early public cloud {IoT} success stories have focused on smaller-scale scenarios such as connected houses, it is unclear to what extent these new public cloud mechanisms and abstractions are suitable and effective for larger-scale and/or scientific scenarios, which often have a different set of constraints or requirements. In this paper, the design and implementation of a representative cloud-based {IoT} infrastructure in a specific public cloud – {AWS} – is presented. The system created is for dynamic vehicle traffic control based on vehicle volumes/patterns and public transport punctuality. We find that constructing server-less, stateful, and data driven {IoT} applications in {AWS} that can operate in real-time is non-trivial. The primary challenges span application manageability and design, latency performance, asynchronicity, and scalability.},
	eventtitle = {2016 {IEEE}/{ACM} 9th International Conference on Utility and Cloud Computing ({UCC})},
	pages = {63--69},
	booktitle = {2016 {IEEE}/{ACM} 9th International Conference on Utility and Cloud Computing ({UCC})},
	author = {Tärneberg, William and Chandrasekaran, Vishal and Humphrey, Marty},
	date = {2016-12},
	keywords = {{IoT}, Cloud, Automatic control, {AWS}, Connected vehicles, Data analysis, Data collection, {PaaS}, Public transport, Smart Cities, Tra c, Traffic Signal Priority},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/FAD4VP3G/7881617.html:text/html;Tärneberg et al_2016_Experiences Creating a Framework for Smart Traffic Control Using AWS IOT.pdf:/home/volodia/Zotero/storage/A7E52T4I/Tärneberg et al_2016_Experiences Creating a Framework for Smart Traffic Control Using AWS IOT.pdf:application/pdf},
}

@inproceedings{gabbrielli_no_2019,
	location = {Cham},
	title = {No More, No Less},
	isbn = {978-3-030-22397-7},
	doi = {10.1007/978-3-030-22397-7_9},
	series = {Lecture Notes in Computer Science},
	abstract = {Serverless computing, also known as Functions-as-a-Service, is a recent paradigm aimed at simplifying the programming of cloud applications. The idea is that developers design applications in terms of functions, which are then deployed on a cloud infrastructure. The infrastructure takes care of executing the functions whenever requested by remote clients, dealing automatically with distribution and scaling with respect to inbound traffic.While vendors already support a variety of programming languages for serverless computing (e.g. Go, Java, Javascript, Python), as far as we know there is no reference model yet to formally reason on this paradigm. In this paper, we propose the first core formal programming model for serverless computing, which combines ideas from both the 𝜆λ{\textbackslash}lambda -calculus (for functions) and the 𝜋π{\textbackslash}pi -calculus (for communication). To illustrate our proposal, we model a real-world serverless system. Thanks to our model, we capture limitations of current vendors and formalise possible amendments.},
	pages = {148--157},
	booktitle = {Coordination Models and Languages},
	publisher = {Springer International Publishing},
	author = {Gabbrielli, Maurizio and Giallorenzo, Saverio and Lanese, Ivan and Montesi, Fabrizio and Peressotti, Marco and Zingaro, Stefano Pio},
	editor = {Riis Nielson, Hanne and Tuosto, Emilio},
	date = {2019},
	langid = {english},
	file = {Gabbrielli et al_2019_No More, No Less.pdf:/home/volodia/Zotero/storage/XC8PLVB7/Gabbrielli et al_2019_No More, No Less.pdf:application/pdf},
}

@report{yang_edgebench_2020-1,
	title = {{EdgeBench}: A Workflow-based Benchmark for Edge Computing},
	url = {https://ui.adsabs.harvard.edu/abs/2020arXiv201014027Y},
	shorttitle = {{EdgeBench}},
	abstract = {Edge computing has been developed to utilize multiple tiers of resources for privacy, cost and Quality of Service ({QoS}) reasons. Edge workloads have the characteristics of data-driven and latency-sensitive. Because of this, edge systems have developed to be both heterogeneous and distributed. The unique characteristics of edge workloads and edge systems have motivated {EdgeBench}, a workflow-based benchmark aims to provide the ability to explore the full design space of edge workloads and edge systems. {EdgeBench} is both customizable and representative. It allows users to customize the workflow logic of edge workloads, the data storage backends, and the distribution of the individual workflow stages to different computing tiers. To illustrate the usability of {EdgeBench}, we also implements two representative edge workflows, a video analytics workflow and an {IoT} hub workflow that represents two distinct but common edge workloads. Both workflows are evaluated using the workflow-level and function-level metrics reported by {EdgeBench} to illustrate both the performance bottlenecks of the edge systems and the edge workloads.},
	author = {Yang, Qirui and Jin, Runyu and Gandhi, Nabil and Ge, Xiongzi and Aghaei Khouzani, Hoda and Zhao, Ming},
	urldate = {2022-02-15},
	date = {2020-10-01},
	note = {Publication Title: {arXiv} e-prints
{ADS} Bibcode: 2020arXiv201014027Y
Type: article},
	keywords = {Computer Science - Performance, and Cluster Computing, Computer Science - Distributed, Parallel},
	file = {Yang et al_2020_EdgeBench.pdf:/home/volodia/Zotero/storage/ILKGE4IP/Yang et al_2020_EdgeBench.pdf:application/pdf},
}

@inproceedings{das_edgebench_2018,
	title = {{EdgeBench}: Benchmarking Edge Computing Platforms},
	doi = {10.1109/UCC-Companion.2018.00053},
	shorttitle = {{EdgeBench}},
	pages = {175--180},
	author = {Das, Anirban and Patterson, Stacy and Wittie, Mike},
	date = {2018-12-01},
	file = {Das et al_2018_EdgeBench.pdf:/home/volodia/Zotero/storage/JDVKKNEJ/Das et al_2018_EdgeBench.pdf:application/pdf},
}

@online{noauthor_benchmark_nodate,
	title = {Benchmark of {IoT} Applications for service placement at the Fog-Edge Computing networks — {IoT} applications benchmark},
	url = {https://asfarah.github.io/IoT_Benchmark/README.html},
	urldate = {2022-02-15},
	file = {Benchmark of IoT Applications for service placement at the Fog-Edge Computing networks — IoT applications benchmark:/home/volodia/Zotero/storage/PQSG9WTC/README.html:text/html},
}

@online{noauthor_what_2021,
	title = {What is edge computing and why it matters},
	url = {https://www.ericsson.com/en/edge-computing},
	abstract = {Edge computing is a crucial part of the 5G platform. Explore the winning strategies \& capabilities for service providers to unlock new business opportunities.},
	urldate = {2022-02-15},
	date = {2021-02-04},
	langid = {english},
	note = {Last Modified: 2022-01-29T01:07:35+00:00},
	file = {Snapshot:/home/volodia/Zotero/storage/RTVTQVLP/edge-computing.html:text/html},
}

@online{noauthor_future_2020,
	title = {Future of cloud computing: distributed solutions},
	url = {https://www.ericsson.com/en/reports-and-papers/ericsson-technology-review/articles/the-future-of-cloud-computing},
	shorttitle = {Future of cloud computing},
	abstract = {The future of cloud computing is a combination of more distributed solutions with heterogeneous hardware, which presents an opportunity for network operators.},
	urldate = {2022-02-15},
	date = {2020-05-12},
	langid = {english},
	note = {Last Modified: 2021-02-12T09:14:55+00:00},
	file = {Snapshot:/home/volodia/Zotero/storage/IEUFJS38/the-future-of-cloud-computing.html:text/html},
}

@article{mouradian_comprehensive_2018,
	title = {A Comprehensive Survey on Fog Computing: State-of-the-Art and Research Challenges},
	volume = {20},
	issn = {1553-877X},
	doi = {10.1109/COMST.2017.2771153},
	shorttitle = {A Comprehensive Survey on Fog Computing},
	abstract = {Cloud computing with its three key facets (i.e., Infrastructure-as-a-Service, Platform-as-a-Service, and Software-as-a-Service) and its inherent advantages (e.g., elasticity and scalability) still faces several challenges. The distance between the cloud and the end devices might be an issue for latency-sensitive applications such as disaster management and content delivery applications. Service level agreements ({SLAs}) may also impose processing at locations where the cloud provider does not have data centers. Fog computing is a novel paradigm to address such issues. It enables provisioning resources and services outside the cloud, at the edge of the network, closer to end devices, or eventually, at locations stipulated by {SLAs}. Fog computing is not a substitute for cloud computing but a powerful complement. It enables processing at the edge while still offering the possibility to interact with the cloud. This paper presents a comprehensive survey on fog computing. It critically reviews the state of the art in the light of a concise set of evaluation criteria. We cover both the architectures and the algorithms that make fog systems. Challenges and research directions are also introduced. In addition, the lessons learned are reviewed and the prospects are discussed in terms of the key role fog is likely to play in emerging technologies such as tactile Internet.},
	pages = {416--464},
	number = {1},
	journaltitle = {{IEEE} Communications Surveys Tutorials},
	author = {Mouradian, Carla and Naboulsi, Diala and Yangui, Sami and Glitho, Roch H. and Morrow, Monique J. and Polakos, Paul A.},
	date = {2018},
	note = {Conference Name: {IEEE} Communications Surveys Tutorials},
	keywords = {edge computing, Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Computer architecture, Tutorials, Internet of Things, latency, Classification algorithms, tactile Internet},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/PUKERAJL/8100873.html:text/html;Mouradian et al_2018_A Comprehensive Survey on Fog Computing.pdf:/home/volodia/Zotero/storage/JRIYYWBE/Mouradian et al_2018_A Comprehensive Survey on Fog Computing.pdf:application/pdf},
}

@article{mouradian_iot_2020,
	title = {An {IoT} Platform-as-a-Service for {NFV}-Based Hybrid Cloud/Fog Systems},
	volume = {7},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2020.2968235},
	abstract = {Cloud computing, despite its inherent advantages (e.g., resource efficiency), still faces several challenges. The wide area network used to connect the cloud to end users could cause high latency, which may not be tolerable for some applications, especially Internet-of-Things ({IoT}) applications. Fog computing can reduce this latency by extending the traditional cloud architecture to the edge of the network and by enabling the deployment of some application components on fog nodes. Application providers use Platform-as-a-Service ({PaaS}) to provision (i.e., develop, deploy, manage, and orchestrate) applications in cloud. However, existing {PaaS} solutions (including {IoT} {PaaS}) usually focus on cloud and do not enable provisioning of applications with components spanning cloud and fog. Provisioning such applications requires novel functions, such as application graph generation, that are absent from existing {PaaS}. Furthermore, several functions offered by existing {PaaS} (e.g., publication/discovery) need to be significantly extended in order to fit in a hybrid cloud/fog environment. In this article, we propose a novel architecture for {PaaS} for hybrid cloud/fog system. It is {IoT} use case driven, and its applications' components are implemented as virtual network functions ({VNFs}) with execution sequences modeled as graphs with substructures, such as selection and loops. It automates the provisioning of applications with components spanning cloud and fog. In addition, it enables the discovery of existing cloud and fog nodes and generates application graphs. A proof of concept is built based on Cloudify open source. Feasibility is demonstrated by evaluating its performance when the {PaaS} modules and application components are placed in clouds and fogs in different geographical locations.},
	pages = {6102--6115},
	number = {7},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Mouradian, Carla and Ebrahimnezhad, Fereshteh and Jebbar, Yassine and Ahluwalia, Jasmeen Kaur and Afrasiabi, Seyedeh Negar and Glitho, Roch H. and Moghe, Ashok},
	date = {2020-07},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Accidents, Computer architecture, Internet of Things, Automobiles, Detectors, network functions virtualization ({NFV}), Platform-as-a-Service ({PaaS})},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/6KI39S9W/8964357.html:text/html;Mouradian et al_2020_An IoT Platform-as-a-Service for NFV-Based Hybrid Cloud-Fog Systems.pdf:/home/volodia/Zotero/storage/CFC52AE5/Mouradian et al_2020_An IoT Platform-as-a-Service for NFV-Based Hybrid Cloud-Fog Systems.pdf:application/pdf},
}

@inproceedings{afrasiabi_application_2019,
	title = {Application Components Migration in {NFV}-based Hybrid Cloud/Fog Systems},
	doi = {10.1109/LANMAN.2019.8847126},
	abstract = {Fog computing extends the cloud to the edge of the network, close to the end-users enabling the deployment of some application component in the fog while others in the cloud. Network Functions Virtualization ({NFV}) decouples the network functions from the underlying hardware. In {NFV} settings, application components can be implemented as sets of Virtual Network Functions ({VNFs}) chained in specific order representing {VNF}-Forwarding Graphs ({VNF}-{FG}). Many studies have been carried out to map the {VNF}-{FGs} to cloud systems. However, in hybrid cloud/fog systems, an additional challenge arises. The mobility of fog nodes may cause high latency as the distance between the end-users and the nodes hosting the components increases. This may not be tolerable for some applications. In such cases, a prominent solution is to migrate application components to a closer fog node. This paper focuses on application component migration in {NFV}-based hybrid cloud/fog systems. The objective is to minimize the aggregated makespan of the applications. The problem is modeled mathematically, and a heuristic is proposed to find the sub-optimal solution in an acceptable time. The heuristic aims at finding the optimal fog node in each time-slot considering a pre-knowledge of the mobility models of the fog nodes. The experiment's results show that our proposed solution improves the makespan and the number of migrations compared to random migration and No-migration.},
	eventtitle = {2019 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	pages = {1--6},
	booktitle = {2019 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	author = {Afrasiabi, Seyedeh Negar and Kianpisheh, Somayeh and Mouradian, Carla and Glitho, Roch H. and Moghe, Ashok},
	date = {2019-07},
	note = {{ISSN}: 1944-0375},
	keywords = {Cloud computing, Edge computing, Fog computing, Delays, Task analysis, Drones, Network function virtualization, Network Functions Virtualization ({NFV}), optimization, Heuristic, Migration, Optimization},
	file = {Afrasiabi et al_2019_Application Components Migration in NFV-based Hybrid Cloud-Fog Systems.pdf:/home/volodia/Zotero/storage/Q92EVCUD/Afrasiabi et al_2019_Application Components Migration in NFV-based Hybrid Cloud-Fog Systems.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/B5RSD25T/8847126.html:text/html},
}

@article{mouradian_nfv_2018,
	title = {{NFV} and {SDN}-Based Distributed {IoT} Gateway for Large-Scale Disaster Management},
	volume = {5},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2018.2867255},
	abstract = {Large-scale disaster management applications are among the several realistic applications of the Internet of Things ({IoT}). Fire detection and earthquake early warning applications are just two examples. Several {IoT} devices are used in such applications, e.g., sensors and robots. These sensors and robots are usually heterogeneous. Moreover, in disaster scenarios, the existing communication infrastructure may become completely or partially destroyed, leaving mobile ad-hoc networks the only alternative to provide connectivity. Utilizing these applications raises new challenges such as the need for dynamic, flexible, and distributed gateways which can accommodate new applications and new {IoT} devices. Network functions virtualization ({NFV}) and software defined networking ({SDN}) are emerging paradigms that can help to overcome these challenges. This paper leverages {NFV} and {SDN} to propose an architecture for on-the-fly distributed gateway provisioning in large-scale disaster management. In the proposed architecture, the gateway functions are provisioned as virtual network functions that are chained on-the-fly in the {IoT} domain using {SDN}. A prototype is built and the performance results are presented.},
	pages = {4119--4131},
	number = {5},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Mouradian, Carla and Jahromi, Narjes Tahghigh and Glitho, Roch H.},
	date = {2018-10},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Internet of Things ({IoT}), Logic gates, Internet of Things, Protocols, network functions virtualization ({NFV}), Disaster management, Fires, gateway, Robot sensing systems, software defined networking ({SDN})},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/9KYHKWAY/8447195.html:text/html;Mouradian et al_2018_NFV and SDN-Based Distributed IoT Gateway for Large-Scale Disaster Management.pdf:/home/volodia/Zotero/storage/GPSI8MXY/Mouradian et al_2018_NFV and SDN-Based Distributed IoT Gateway for Large-Scale Disaster Management.pdf:application/pdf},
}

@inproceedings{giang_developing_2015,
	title = {Developing {IoT} applications in the Fog: A Distributed Dataflow approach},
	doi = {10.1109/IOT.2015.7356560},
	shorttitle = {Developing {IoT} applications in the Fog},
	abstract = {In this paper we examine the development of {IoT} applications from the perspective of the Fog Computing paradigm, where computing infrastructure at the network edge in devices and gateways is leverage for efficiency and timeliness. Due to the intrinsic nature of the {IoT}: heterogeneous devices/resources, a tightly coupled perception-action cycle and widely distributed devices and processing, application development in the Fog can be challenging. To address these challenges, we propose a Distributed Dataflow ({DDF}) programming model for the {IoT} that utilises computing infrastructures across the Fog and the Cloud. We evaluate our proposal by implementing a {DDF} framework based on Node-{RED} (Distributed Node-{RED} or D-{NR}), a visual programming tool that uses a flow-based model for building {IoT} applications. Via demonstrations, we show that our approach eases the development process and can be used to build a variety of {IoT} applications that work efficiently in the Fog.},
	eventtitle = {2015 5th International Conference on the Internet of Things ({IOT})},
	pages = {155--162},
	booktitle = {2015 5th International Conference on the Internet of Things ({IOT})},
	author = {Giang, Nam Ky and Blackstock, Michael and Lea, Rodger and Leung, Victor C.M.},
	date = {2015-10},
	keywords = {Cloud computing, Internet of things, Computational modeling, Logic gates, Programming, Buildings, Internet of Things, Distributed dataflow, Node-{RED}, Programming models, Scalability},
	file = {Giang et al_2015_Developing IoT applications in the Fog.pdf:/home/volodia/Zotero/storage/P6D67XU3/Giang et al_2015_Developing IoT applications in the Fog.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DLH6FY55/7356560.html:text/html},
}

@inproceedings{zaheer_multi-provider_2010,
	title = {Multi-provider service negotiation and contracting in network virtualization},
	doi = {10.1109/NOMS.2010.5488487},
	abstract = {Network virtualization environment ({VNE}) affords great business flexibility to the customers and the providers as multiple providers can jointly support a customer's virtual network. Under the current network model, a group of Infrastructure Providers ({InPs}) peer with each other to provide a packaged deal. Such a business arrangement is not customer-driven, does not promote fair market competition and does not ensure cost minimization. Furthermore, the on-demand nature of virtual networks requires efficient and automated service negotiation and contracting. In this paper, we present V-Mart. To the {InPs}, V-Mart offers an environment to participate in a faithful and fair competition over the {VN} resources; and to the {SPs}, it offers a customer-driven virtual resource partitioning and contracting engine. V-Mart uses a two-stage Vickrey auction model that is strategy-proof, flexible to diverse {InP} pricing models, and functions over heterogenous multi-commodity market that characterizes the {NVE}. Through analysis and simulation we show the flexibility and effectiveness of V-Mart.},
	eventtitle = {2010 {IEEE} Network Operations and Management Symposium - {NOMS} 2010},
	pages = {471--478},
	booktitle = {2010 {IEEE} Network Operations and Management Symposium - {NOMS} 2010},
	author = {Zaheer, Fida-E and Xiao, Jin and Boutaba, Raouf},
	date = {2010-04},
	note = {{ISSN}: 2374-9709},
	keywords = {Pricing, Computer science, Costs, Engines, Indium phosphide, Packaging, Peer to peer computing, Resource virtualization, Routing protocols, Service oriented architecture},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DXW9PT6L/5488487.html:text/html;Zaheer et al_2010_Multi-provider service negotiation and contracting in network virtualization.pdf:/home/volodia/Zotero/storage/98YAUWC4/Zaheer et al_2010_Multi-provider service negotiation and contracting in network virtualization.pdf:application/pdf},
}

@article{landa_self-tuning_2016,
	title = {Self-Tuning Service Provisioning for Decentralized Cloud Applications},
	volume = {13},
	issn = {1932-4537},
	doi = {10.1109/TNSM.2016.2549698},
	abstract = {Cloud computing has revolutionized service delivery by providing on-demand invocation and elasticity. To reap these benefits, computation has been displaced from client devices and into data centers. This partial centralization is undesirable for applications that have stringent locality requirements, e.g., low latency. This problem could be addressed with large numbers of smaller cloud resources closer to users. However, as cloud computing diffuses from within data centers and into the network, there will be a need for cloud resource allocation algorithms that operate on resource-constrained computational units that serve localized subsets of customers. In this paper, we present a mechanism for service provisioning in distributed clouds where applications compete for resources. The mechanism operates by enabling execution zones to assign resources based on Vickrey auctions and provides high-quality probabilistic models that applications can use to predict the outcomes of such auctions. This allows applications to use knowledge of the locality distribution of their clients to accurately select the number of bids to be sent to each execution zone and their value. The proposed mechanism is highly scalable, efficient, and validated by extensive simulations.},
	pages = {197--211},
	number = {2},
	journaltitle = {{IEEE} Transactions on Network and Service Management},
	author = {Landa, Raul and Charalambides, Marinos and Clegg, Richard G. and Griffin, David and Rio, Miguel},
	date = {2016-06},
	note = {Conference Name: {IEEE} Transactions on Network and Service Management},
	keywords = {Cloud computing, Quality of service, Computational modeling, Resource management, Measurement, Bandwidth, Cloud Resource Management, Decentralized Cloud Applications, Heuristic algorithms, Quality of Experience, Vickrey Auctions},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/I7DYIWCF/7445875.html:text/html;Landa et al_2016_Self-Tuning Service Provisioning for Decentralized Cloud Applications.pdf:/home/volodia/Zotero/storage/LRTLT3XE/Landa et al_2016_Self-Tuning Service Provisioning for Decentralized Cloud Applications.pdf:application/pdf},
}

@inproceedings{cheng_geelytics_2016,
	title = {Geelytics: Enabling On-Demand Edge Analytics over Scoped Data Sources},
	doi = {10.1109/BigDataCongress.2016.21},
	shorttitle = {Geelytics},
	abstract = {Large-scale Internet of Things ({IoT}) systems typically consist of a large number of sensors and actuators distributed geographically in a physical environment. To react fast on real time situations, it is often required to bridge sensors and actuators via real-time stream processing close to {IoT} devices. Existing stream processing platforms like Apache Storm and S4 are designed for intensive stream processing in a cluster or in the Cloud, but they are unsuitable for large scale {IoT} systems in which processing tasks are expected to be triggered by actuators on-demand and then be allocated and performed in a Cloud-Edge environment. To fill this gap, we designed and implemented a new system called Geelytics, which can enable on-demand edge analytics over scoped data sources via {IoT}-friendly interfaces to sensors and actuators. This paper presents its design, implementation, interfaces, and core algorithms. Three example applications have been built to showcase the potential of Geelytics in enabling advanced {IoT} edge analytics. Our preliminary evaluation results demonstrate that we can reduce the bandwidth cost by 99\% in a face detection example, achieve less than 10 milliseconds reacting latency and about 1.5 seconds startup latency in an outlier detection example, and also save 65\% duplicated computation cost via sharing intermediate results in a data aggregation example.},
	eventtitle = {2016 {IEEE} International Congress on Big Data ({BigData} Congress)},
	pages = {101--108},
	booktitle = {2016 {IEEE} International Congress on Big Data ({BigData} Congress)},
	author = {Cheng, Bin and Papageorgiou, Apostolos and Bauer, Martin},
	date = {2016-06},
	keywords = {edge computing, Cloud computing, Internet of things, Real-time systems, {IoT}, Actuators, edge analytics, Sensor systems, stream processing},
	file = {Cheng et al_2016_Geelytics.pdf:/home/volodia/Zotero/storage/6IVXZ5PR/Cheng et al_2016_Geelytics.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DTJ4K2UB/7584926.html:text/html},
}

@article{tasiopoulos_fogspot_2021-1,
	title = {{FogSpot}: Spot Pricing for Application Provisioning in Edge/Fog Computing},
	volume = {14},
	issn = {1939-1374},
	doi = {10.1109/TSC.2019.2895037},
	shorttitle = {{FogSpot}},
	abstract = {An increasing number of Low Latency Applications ({LLAs}) in the entertainment, {IoT}, and automotive domains require response times that challenge the traditional application provisioning using distant Data Centres. The fog computing paradigm extends cloud computing at the edge and middle-tier locations of the network, providing response times an order of magnitude smaller than those that can be achieved by the current “client-to-cloud” network model. Here, we address the challenges of provisioning heavily stateful {LLA} in the setting where fog infrastructure consists of third-party computing resources, i.e., cloudlets, that come in the form of “data centres in the box”. We introduce {FogSpot}, a charging mechanism for on-path, on-demand, application provisioning. In {FogSpot}, cloudlets offer their resources in the form of Virtual Machines ({VMs}) via markets, collocated with the cloudlets, that interact with forwarded users’ application requests for {VMs} in real time. {FogSpot} associates each cloudlet with a price based on applications’ demand. The proposed mechanism’s design takes into account the characteristics of cloudlets’ resources, such as their limited elasticity, and {LLAs}’ attributes, like their expected {QoS} gain and engagement duration. Lastly, {FogSpot} guarantees the end users’ requests truthfulness while focusing in maximising either each cloudlet’s revenue or resource utilisation.},
	pages = {1781--1795},
	number = {6},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Tasiopoulos, Argyrios G. and Ascigil, Onur and Psaras, Ioannis and Toumpis, Stavros and Pavlou, George},
	date = {2021-11},
	note = {Conference Name: {IEEE} Transactions on Services Computing},
	keywords = {Cloud computing, Edge computing, Quality of service, application provisioning, Data centers, decentralised cloud applications, Economics, Edge/Fog computing, Elasticity, network economics, pricing, Pricing, quality of service, Task analysis},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/QQWHVKNY/8625439.html:text/html;Tasiopoulos et al_2021_FogSpot.pdf:/home/volodia/Zotero/storage/YY4MBXEM/Tasiopoulos et al_2021_FogSpot.pdf:application/pdf},
}

@article{grambow_befaas_2021,
	title = {{BeFaaS}: An Application-Centric Benchmarking Framework for {FaaS} Platforms},
	url = {http://arxiv.org/abs/2102.12770},
	shorttitle = {{BeFaaS}},
	abstract = {Following the increasing interest and adoption of {FaaS} systems, benchmarking frameworks for determining non-functional properties have also emerged. While existing (microbenchmark) frameworks only evaluate single aspects of {FaaS} platforms, a more holistic, application-driven approach is still missing. In this paper, we design and present {BeFaaS}, an extensible application-centric benchmarking framework for {FaaS} environments that focuses on the evaluation of {FaaS} platforms through realistic and typical examples of {FaaS} applications. {BeFaaS} includes a built-in e-commerce benchmark, is extensible for new workload profiles and new platforms, supports federated benchmark runs in which the benchmark application is distributed over multiple providers, and supports a fine-grained result analysis. Our evaluation compares three major {FaaS} providers in single cloud provider setups and shows that {BeFaaS} is capable of running each benchmark automatically with minimal configuration effort and providing detailed insights for each interaction.},
	journaltitle = {{arXiv}:2102.12770 [cs]},
	author = {Grambow, Martin and Pfandzelter, Tobias and Burchard, Luk and Schubert, Carsten and Zhao, Max and Bermbach, David},
	urldate = {2022-02-16},
	date = {2021-11-01},
	eprinttype = {arxiv},
	eprint = {2102.12770},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv.org Snapshot:/home/volodia/Zotero/storage/FKGHBRMP/2102.html:text/html;Grambow et al_2021_BeFaaS.pdf:/home/volodia/Zotero/storage/J63SP9W4/Grambow et al_2021_BeFaaS.pdf:application/pdf},
}

@online{strycek_deploying_nodate,
	title = {Deploying Redis to Kubernetes cluster K3s},
	url = {https://rpi4cluster.com/k3s/k3s-redis/},
	abstract = {Deployment yaml files for simple Redis deployment to Kubernetes K3s cluster on Raspberry Pi 4.},
	author = {Strycek, Vladimir},
	urldate = {2022-02-18},
	langid = {english},
	file = {Snapshot:/home/volodia/Zotero/storage/QSAZMAED/k3s-redis.html:text/html},
}

@inproceedings{ahmed_docker_2020,
	location = {Oxford, {GB}},
	title = {Docker Container Deployment in Distributed Fog Infrastructures with Checkpoint/Restart},
	isbn = {978-1-72811-035-6},
	url = {https://ieeexplore.ieee.org/document/9126743/},
	doi = {10.1109/MobileCloud48802.2020.00016},
	abstract = {In fog computing environments container deployment is a frequent operation which often lies in the critical path of services being delivered to an end user. Although creating a container can be very fast, the container’s application needs to start before the container starts producing useful work. Depending on the application this startup process can be arbitrarily long. To speed up the application startup times we propose to snapshot the state of fully-deployed containers and restart future container instances from a pre-started application state. In our evaluations based on 14 real micro-service containers, this technique effectively reduces the startup phase with speedups between 1x (no speedup) and 60x.},
	eventtitle = {2020 8th {IEEE} International Conference on Mobile Cloud Computing, Services, and Engineering ({MobileCloud})},
	pages = {55--62},
	booktitle = {2020 8th {IEEE} International Conference on Mobile Cloud Computing, Services, and Engineering ({MobileCloud})},
	publisher = {{IEEE}},
	author = {Ahmed, Arif and Mohan, Apoorve and Cooperman, Gene and Pierre, Guillaume},
	urldate = {2022-02-21},
	date = {2020-08},
	langid = {english},
	file = {Ahmed et al. - 2020 - Docker Container Deployment in Distributed Fog Inf.pdf:/home/volodia/Zotero/storage/WGVHSKC6/Ahmed et al. - 2020 - Docker Container Deployment in Distributed Fog Inf.pdf:application/pdf},
}

@inproceedings{siasi_tabu_2019,
	title = {Tabu Search for Efficient Service Function Chain Provisioning in Fog Networks},
	doi = {10.1109/CIC48465.2019.00026},
	abstract = {Fog computing places computation/storage resources at the network edge to overcome delay limitations associated with cloud computing. Namely, fog-based services can provide more responsive relay and caching and alleviate loads at core cloud datacenters. Meanwhile, technologies such as network function virtualization ({NFV}) are virtualizing atomic network functions and allowing provides to build customized service function chains ({SFC}). Hence combining {NFV} with fog computing allows providers to share critical edge resources across clients and achieve much more flexible service designs. However, few efforts have looked at {SFC} provisioning in fog domains. Hence this paper presents one of the first studies in this area, detailing a Tabu search for virtual function placement and heuristic routing schemes with load balancing for efficient resource utilization. Results show reduced processing and propagation times, and lower energy consumption versus cloud-based methods.},
	eventtitle = {2019 {IEEE} 5th International Conference on Collaboration and Internet Computing ({CIC})},
	pages = {145--150},
	booktitle = {2019 {IEEE} 5th International Conference on Collaboration and Internet Computing ({CIC})},
	author = {Siasi, Nazli and Jaesim, Adrian and Ghani, Nasir},
	date = {2019-12},
	keywords = {Cloud computing, Edge computing, Delays, Real-time systems, Network function virtualization, Bandwidth, Cloud computing, fog computing, network function virtualization, service function chaining, Tabu search},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/V8ZTPZ5A/8998512.html:text/html;Siasi et al_2019_Tabu Search for Efficient Service Function Chain Provisioning in Fog Networks.pdf:/home/volodia/Zotero/storage/FZZ47BJ4/Siasi et al_2019_Tabu Search for Efficient Service Function Chain Provisioning in Fog Networks.pdf:application/pdf},
}

@inproceedings{mouradian_application_2018,
	title = {Application Component Placement in {NFV}-based Hybrid Cloud/Fog Systems},
	doi = {10.1109/LANMAN.2018.8475055},
	abstract = {Applications are sets of interacting components that can be executed in sequence, in parallel, or by using more complex constructs such as selections and loops. They can, therefore, be modeled as structured graphs with sub-structures consisting of these constructs. Fog computing can reduce the latency induced by distant clouds by enabling the deployment of some components at the edge of the network (i.e., closer to end-devices) while keeping others in the cloud. Network Functions Virtualization ({NFV}) decouples software from hardware and enables an agile deployment of network services and applications as Virtual Network Functions ({VNFs}). In {NFV} settings, efficient placement algorithms are required to map the structured graphs representing the {VNF} Forwarding Graphs ({VNF}-{FGs}) onto the infrastructure of the hybrid cloud/fog system. Only deterministic graphs with sequence and parallel sub-structures have been considered thus to date. However, several real-life applications do require non-deterministic graphs with sub-structures as selections and loops. This paper focuses on application component placement in {NFV}-based hybrid cloud/fog systems, with the assumption that the graph representing the application is non-deterministic. The objective is to minimize an aggregated weighted function of makespan and cost. The problem is modeled as an Integer Linear Programming ({ILP}) and evaluated over small-scale scenarios using the {CPLEX} optimization tool.},
	eventtitle = {2018 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	pages = {25--30},
	booktitle = {2018 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	author = {Mouradian, Carla and Kianpisheh, Somayeh and Glitho, Roch H.},
	date = {2018-06},
	note = {{ISSN}: 1944-0375},
	keywords = {Cloud computing, Edge computing, Fog computing, Internet of Things ({IoT}), Delays, Network function virtualization, Network Functions Virtualization ({NFV}), Bandwidth, Hardware, Minimization, {VNF} Forwarding Graph Placement},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/J5F6DWY5/8475055.html:text/html;Mouradian et al_2018_Application Component Placement in NFV-based Hybrid Cloud-Fog Systems.pdf:/home/volodia/Zotero/storage/CIZZII3U/Mouradian et al_2018_Application Component Placement in NFV-based Hybrid Cloud-Fog Systems.pdf:application/pdf},
}

@inproceedings{ebrahimzadeh_h-horizon_2021,
	title = {h-Horizon Sequential Look-ahead Greedy Algorithm for {VNF}-{FG} Embedding},
	doi = {10.1109/NFV-SDN53031.2021.9665063},
	abstract = {5G service providers consider Network Function Virtualization ({NFV}) as an enabler to foster new opportunities to scale their business while reducing operational expenses. {NFV} builds on cloud native technologies, automation, and reusability. Central to the success of {NFV} is the ability to design service templates once and to on-demand deploy those template services into specific service contexts, e.g., network slices. Therefore, on-demand homing and assigning of service designs with service level requirements over distributed cloud resources and capabilities is one of the main challenges for the transition to {NFV}. Towards this end, it is important to embed service graphs over the given infrastructure such that the total cost is minimized while satisfying service requirements. To get around the lack of scalability of optimization-based approaches, a viable approach is to rely on efficient Virtual Network Function ({VNF}) embedding heuristics. Despite their low complexity, {VNF} embedding heuristics suffer from the so-called causality issue, which means that embedding decisions must be made before all neighboring dependencies were embedded. This, as a result, may lead to an inferior embedding outcome. In this paper, we propose our novel h-horizon sequential greedy look-ahead embedding algorithm, which allows embedding and re-embedding of {VNFs} based on embedding decisions of other {VNFs} to overcome the causality issue. Our simulation results indicate that our proposed algorithm outperforms the existing greedy benchmark in terms of total embedding cost.},
	eventtitle = {2021 {IEEE} Conference on Network Function Virtualization and Software Defined Networks ({NFV}-{SDN})},
	pages = {41--46},
	booktitle = {2021 {IEEE} Conference on Network Function Virtualization and Software Defined Networks ({NFV}-{SDN})},
	author = {Ebrahimzadeh, Amin and Promwongsa, Nattakorn and Afrasiabi, Seyedeh Negar and Mouradian, Carla and Li, Wubin and Recse, Ákos and Szabó, Róbert and Glitho, Roch. H.},
	date = {2021-11},
	keywords = {Cloud computing, Simulation, Conferences, Scalability, Costs, Greedy algorithms, Software algorithms},
	file = {Ebrahimzadeh et al_2021_h-Horizon Sequential Look-ahead Greedy Algorithm for VNF-FG Embedding.pdf:/home/volodia/Zotero/storage/SPD5UBRJ/Ebrahimzadeh et al_2021_h-Horizon Sequential Look-ahead Greedy Algorithm for VNF-FG Embedding.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/SUS3E9ZA/9665063.html:text/html},
}

@article{mouradian_application_2019-1,
	title = {Application Component Placement in {NFV}-Based Hybrid Cloud/Fog Systems With Mobile Fog Nodes},
	volume = {37},
	issn = {1558-0008},
	doi = {10.1109/JSAC.2019.2906790},
	abstract = {Fog computing reduces the latency induced by distant clouds by enabling the deployment of some application components at the edge of the network, on fog nodes, while keeping others in the cloud. Application components can be implemented as Virtual Network Functions ({VNFs}) and their execution sequences can be modeled by a combination of sub-structures like sequence, parallel, selection, and loops. Efficient placement algorithms are required to map the application components onto the infrastructure nodes. Current solutions do not consider the mobility of fog nodes, a phenomenon which may happen in real systems. In this paper, we use the random waypoint mobility model for fog nodes to calculate the expected makespan and application execution cost. We then model the problem as an Integer Linear Programming ({ILP}) formulation which minimizes an aggregated weighted function of the makespan and cost. We propose a Tabu Search-based Component Placement ({TSCP}) algorithm to find sub-optimal placements. The results show that the proposed algorithm improves the makespan and the application execution cost.},
	pages = {1130--1143},
	number = {5},
	journaltitle = {{IEEE} Journal on Selected Areas in Communications},
	author = {Mouradian, Carla and Kianpisheh, Somayeh and Abu-Lebdeh, Mohammad and Ebrahimnezhad, Fereshteh and Jahromi, Narjes Tahghigh and Glitho, Roch H.},
	date = {2019-05},
	note = {Conference Name: {IEEE} Journal on Selected Areas in Communications},
	keywords = {cloud computing, Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Data centers, Sensors, Component placement, Drones, Earthquakes, Network function virtualization, Network Functions Virtualization ({NFV}), optimization, Tabu Search},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/8II5XQMA/8673549.html:text/html;Mouradian et al_2019_Application Component Placement in NFV-Based Hybrid Cloud-Fog Systems With.pdf:/home/volodia/Zotero/storage/68BCJP4J/Mouradian et al_2019_Application Component Placement in NFV-Based Hybrid Cloud-Fog Systems With.pdf:application/pdf},
}

@inproceedings{pereira_energy_2017,
	location = {Vancouver {BC} Canada},
	title = {Energy efficiency across programming languages: how do energy, time, and memory relate?},
	isbn = {978-1-4503-5525-4},
	url = {https://dl.acm.org/doi/10.1145/3136014.3136031},
	doi = {10.1145/3136014.3136031},
	shorttitle = {Energy efficiency across programming languages},
	abstract = {This paper presents a study of the runtime, memory usage and energy consumption of twenty seven well-known software languages. We monitor the performance of such languages using ten different programming problems, expressed in each of the languages. Our results show interesting findings, such as, slower/faster languages consuming less/more energy, and how memory usage influences energy consumption. We show how to use our results to provide software engineers support to decide which language to use when energy efficiency is a concern.},
	eventtitle = {{SPLASH} '17: Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
	pages = {256--267},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Software Language Engineering},
	publisher = {{ACM}},
	author = {Pereira, Rui and Couto, Marco and Ribeiro, Francisco and Rua, Rui and Cunha, Jácome and Fernandes, João Paulo and Saraiva, João},
	urldate = {2022-02-22},
	date = {2017-10-23},
	langid = {english},
	file = {Pereira et al. - 2017 - Energy efficiency across programming languages ho.pdf:/home/volodia/Zotero/storage/ZXVJYD5I/Pereira et al. - 2017 - Energy efficiency across programming languages ho.pdf:application/pdf},
}

@online{noauthor_getting_nodate,
	title = {Getting Started - Grid5000},
	url = {https://www.grid5000.fr/w/Getting_Started#Connecting_for_the_first_time},
	urldate = {2022-02-22},
	file = {Getting Started - Grid5000:/home/volodia/Zotero/storage/YIABZM73/Getting_Started.html:text/html},
}

@incollection{mittal_mu_2021,
	location = {New York, {NY}, {USA}},
	title = {Mu: An Efficient, Fair and Responsive Serverless Framework for Resource-Constrained Edge Clouds},
	isbn = {978-1-4503-8638-8},
	url = {https://doi.org/10.1145/3472883.3487014},
	shorttitle = {Mu},
	abstract = {Serverless computing platforms simplify development, deployment, and automated management of modular software functions. However, existing serverless platforms typically assume an over-provisioned cloud, making them a poor fit for Edge Computing environments where resources are scarce. In this paper we propose a redesigned serverless platform that comprehensively tackles the key challenges for serverless functions in a resource constrained Edge Cloud. Our Mu platform cleanly integrates the core resource management components of a serverless platform: autoscaling, load balancing, and placement. Each worker node in Mu transparently propagates metrics such as service rate and queue length in response headers, feeding this information to the load balancing system so that it can better route requests, and to our autoscaler to anticipate workload fluctuations and proactively meet {SLOs}. Data from the Autoscaler is then used by the placement engine to account for heterogeneity and fairness across competing functions, ensuring overall resource efficiency, and minimizing resource fragmentation. We implement our design as a set of extensions to the Knative serverless platform and demonstrate its improvements in terms of resource efficiency, fairness, and response time. Evaluating Mu, shows that it improves fairness by more than 2x over the default Kubernetes placement engine, improves 99th percentile response times by 62\% through better load balancing, reduces {SLO} violations and resource consumption by pro-active and precise autoscaling. Mu reduces the average number of pods required by more than {\textasciitilde}15\% for a set of real Azure workloads.},
	pages = {168--181},
	booktitle = {Proceedings of the {ACM} Symposium on Cloud Computing},
	publisher = {Association for Computing Machinery},
	author = {Mittal, Viyom and Qi, Shixiong and Bhattacharya, Ratnadeep and Lyu, Xiaosu and Li, Junfeng and Kulkarni, Sameer G. and Li, Dan and Hwang, Jinho and Ramakrishnan, K. K. and Wood, Timothy},
	urldate = {2022-02-25},
	date = {2021-11-01},
	keywords = {serverless, Edge clouds, resource management},
	file = {Mittal et al_2021_Mu.pdf:/home/volodia/Zotero/storage/6RSWI84C/Mittal et al_2021_Mu.pdf:application/pdf},
}

@online{noauthor_fogbus2_nodate,
	title = {{FogBus}2 {\textbar} Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
	url = {https://dl.acm.org/doi/abs/10.1145/3460866.3461768},
	urldate = {2022-02-25},
	file = {FogBus2 | Proceedings of the International Workshop on Big Data in Emergent Distributed Environments:/home/volodia/Zotero/storage/7UT85HBP/3460866.html:text/html},
}

@incollection{deng_fogbus2_2021,
	location = {New York, {NY}, {USA}},
	title = {{FogBus}2: a lightweight and distributed container-based framework for integration of {IoT}-enabled systems with edge and cloud computing},
	isbn = {978-1-4503-8465-0},
	url = {https://doi.org/10.1145/3460866.3461768},
	shorttitle = {{FogBus}2},
	abstract = {Edge/Fog computing is a novel computing paradigm that provides resource-limited Internet of Things ({IoT}) devices with scalable computing and storage resources. Compared to cloud computing, edge/fog servers have fewer resources, but they can be accessed with higher bandwidth and less communication latency. Thus, integrating edge/fog and cloud infrastructures can support the execution of diverse latency-sensitive and computation-intensive {IoT} applications. Although some frameworks attempt to provide such integration, there are still several challenges to be addressed, such as dynamic scheduling of different {IoT} applications, scalability mechanisms, multi-platform support, and supporting different interaction models. To overcome these challenges, we propose a lightweight and distributed container-based framework, called {FogBus}2. It provides a mechanism for scheduling heterogeneous {IoT} applications and implements several scheduling policies. Also, it proposes an optimized genetic algorithm to obtain fast convergence to well-suited solutions. Besides, it offers a scalability mechanism to ensure efficient responsiveness when either the number of {IoT} devices increases or the resources become overburdened. Also, the dynamic resource discovery mechanism of {FogBus}2 assists new entities to quickly join the system. We have also developed two {IoT} applications, called Conway's Game of Life and Video Optical Character Recognition to demonstrate the effectiveness of {FogBus}2 for handling real-time and non-real-time {IoT} applications. Experimental results show {FogBus}2's scheduling policy improves the response time of {IoT} applications by 53\% compared to other policies. Also, the scalability mechanism can reduce up to 48\% of the queuing waiting time compared to frameworks that do not support scalability.},
	pages = {1--8},
	number = {4},
	booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
	publisher = {Association for Computing Machinery},
	author = {Deng, Qifan and Goudarzi, Mohammad and Buyya, Rajkumar},
	urldate = {2022-02-25},
	date = {2021-06-20},
	keywords = {internet of things, containers scheduling, edge/fog computing, scalability},
	file = {Deng et al_2021_FogBus2.pdf:/home/volodia/Zotero/storage/QWBCTYYX/Deng et al_2021_FogBus2.pdf:application/pdf},
}

@incollection{deng_fogbus2_2021-1,
	location = {New York, {NY}, {USA}},
	title = {{FogBus}2: a lightweight and distributed container-based framework for integration of {IoT}-enabled systems with edge and cloud computing},
	isbn = {978-1-4503-8465-0},
	url = {https://doi.org/10.1145/3460866.3461768},
	shorttitle = {{FogBus}2},
	abstract = {Edge/Fog computing is a novel computing paradigm that provides resource-limited Internet of Things ({IoT}) devices with scalable computing and storage resources. Compared to cloud computing, edge/fog servers have fewer resources, but they can be accessed with higher bandwidth and less communication latency. Thus, integrating edge/fog and cloud infrastructures can support the execution of diverse latency-sensitive and computation-intensive {IoT} applications. Although some frameworks attempt to provide such integration, there are still several challenges to be addressed, such as dynamic scheduling of different {IoT} applications, scalability mechanisms, multi-platform support, and supporting different interaction models. To overcome these challenges, we propose a lightweight and distributed container-based framework, called {FogBus}2. It provides a mechanism for scheduling heterogeneous {IoT} applications and implements several scheduling policies. Also, it proposes an optimized genetic algorithm to obtain fast convergence to well-suited solutions. Besides, it offers a scalability mechanism to ensure efficient responsiveness when either the number of {IoT} devices increases or the resources become overburdened. Also, the dynamic resource discovery mechanism of {FogBus}2 assists new entities to quickly join the system. We have also developed two {IoT} applications, called Conway's Game of Life and Video Optical Character Recognition to demonstrate the effectiveness of {FogBus}2 for handling real-time and non-real-time {IoT} applications. Experimental results show {FogBus}2's scheduling policy improves the response time of {IoT} applications by 53\% compared to other policies. Also, the scalability mechanism can reduce up to 48\% of the queuing waiting time compared to frameworks that do not support scalability.},
	pages = {1--8},
	number = {4},
	booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
	publisher = {Association for Computing Machinery},
	author = {Deng, Qifan and Goudarzi, Mohammad and Buyya, Rajkumar},
	urldate = {2022-02-25},
	date = {2021-06-20},
	keywords = {internet of things, containers scheduling, edge/fog computing, scalability},
	file = {Deng et al_2021_FogBus2.pdf:/home/volodia/Zotero/storage/48L6AYJ3/Deng et al_2021_FogBus2.pdf:application/pdf},
}

@inproceedings{mortazavi_cloudpath_2017,
	location = {San Jose California},
	title = {Cloudpath: a multi-tier cloud computing framework},
	isbn = {978-1-4503-5087-7},
	url = {https://dl.acm.org/doi/10.1145/3132211.3134464},
	doi = {10.1145/3132211.3134464},
	shorttitle = {Cloudpath},
	abstract = {Path computing is a new paradigm that generalizes the edge computing vision into a multi-tier cloud architecture deployed over the geographic span of the network. Path computing supports scalable and localized processing by providing storage and computation along a succession of datacenters of increasing sizes, positioned between the client device and the traditional wide-area cloud datacenter. {CloudPath} is a platform that implements the path computing paradigm. {CloudPath} consists of an execution environment that enables the dynamic installation of light-weight stateless event handlers, and a distributed eventual consistent storage system that replicates application data on-demand. {CloudPath} handlers are small, allowing them to be rapidly instantiated on demand on any server that runs the {CloudPath} execution framework. In turn, {CloudPath} automatically migrates application data across the multiple datacenter tiers to optimize access latency and reduce bandwidth consumption.},
	eventtitle = {{SEC} '17: {IEEE}/{ACM} Symposium on Edge Computing},
	pages = {1--13},
	booktitle = {Proceedings of the Second {ACM}/{IEEE} Symposium on Edge Computing},
	publisher = {{ACM}},
	author = {Mortazavi, Seyed Hossein and Salehe, Mohammad and Gomes, Carolina Simoes and Phillips, Caleb and de Lara, Eyal},
	urldate = {2022-02-25},
	date = {2017-10-12},
	langid = {english},
	file = {Mortazavi et al. - 2017 - Cloudpath a multi-tier cloud computing framework.pdf:/home/volodia/Zotero/storage/VW3SRA2C/Mortazavi et al. - 2017 - Cloudpath a multi-tier cloud computing framework.pdf:application/pdf},
}

@article{milgrom_redesigning_2017,
	title = {Redesigning Spectrum Licenses},
	volume = {40},
	url = {https://heinonline.org/HOL/Page?handle=hein.journals/rcatorbg40&id=156&div=&collection=},
	pages = {22},
	journaltitle = {Regulation},
	shortjournal = {Regulation},
	author = {Milgrom, Paul and Weyl, E. Glen and Zhang, Anthony Lee},
	date = {2017},
	file = {Redesigning Spectrum Licenses Telecommunications & Technology 40 Regulation 2017-2018:/home/volodia/Zotero/storage/JN35652T/LandingPage.html:text/html},
}

@report{milgrom_redesigning_2017-1,
	location = {Rochester, {NY}},
	title = {Redesigning Spectrum Licenses to Encourage Innovation and Investment},
	url = {https://papers.ssrn.com/abstract=3015929},
	abstract = {Commercial radio spectrum use rights in the {US} are traditionally assigned using licenses over large geographic areas with 10- or 15-year terms, to encourage infrastructure investment. However, such long-term licenses are difficult to reassign as more valuable uses for spectrum arise. Licenses with shorter term limits over smaller areas expedite reassignment of spectrum to innovative entrants, but provide lower incentives for long-term investment. Recent economic theory suggests that this trade-off between protecting long-term investments and enabling valuable, innovative entry can be muted by a new, more efficient “depreciating” license. A promising application is to priority access in the 3.5GHz band, where thousands of licenses are about to be auctioned. Alternatively, carefully redesigning auction rules may offer similar benefits.},
	number = {{ID} 3015929},
	institution = {Social Science Research Network},
	type = {{SSRN} Scholarly Paper},
	author = {Milgrom, Paul R. and Weyl, E. Glen and Zhang, Anthony Lee},
	urldate = {2022-03-01},
	date = {2017-08-07},
	langid = {english},
	keywords = {3.5GHz, depreciating license, priority access licenses},
	file = {Milgrom et al_2017_Redesigning Spectrum Licenses to Encourage Innovation and Investment.pdf:/home/volodia/Zotero/storage/QM2CPQKV/Milgrom et al_2017_Redesigning Spectrum Licenses to Encourage Innovation and Investment.pdf:application/pdf;Snapshot:/home/volodia/Zotero/storage/D2M2A6ZQ/papers.html:text/html},
}

@article{weyl_online_2017,
	title = {An Online Appendix to 'Depreciating Licenses'},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3034480},
	doi = {10.2139/ssrn.3034480},
	journaltitle = {{SSRN} Electronic Journal},
	shortjournal = {{SSRN} Journal},
	author = {Weyl, E. Glen and Zhang, Anthony Lee},
	urldate = {2022-03-02},
	date = {2017},
	langid = {english},
	file = {Weyl and Zhang - 2017 - An Online Appendix to 'Depreciating Licenses'.pdf:/home/volodia/Zotero/storage/C9CSDNYZ/Weyl and Zhang - 2017 - An Online Appendix to 'Depreciating Licenses'.pdf:application/pdf},
}

@report{weyl_depreciating_2021,
	location = {Rochester, {NY}},
	title = {Depreciating Licenses},
	url = {https://papers.ssrn.com/abstract=3698941},
	abstract = {Many governments assign use licenses for natural resources, such as radio spectrum, fishing rights, and mineral extraction rights, through auctions or other market-like mechanisms. License design affects resource users' investment incentives, as well as the efficiency of asset allocation. No existing license design achieves first-best outcomes on both dimensions. Long-term licenses have high-investment incentives, but impede reallocation to high-valued entrants. Short-term licenses improve allocative efficiency but discourage investment. We propose a simple new mechanism, the depreciating license, and we argue that it navigates this tradeoff more effectively than existing license designs.},
	number = {{ID} 3698941},
	institution = {Social Science Research Network},
	type = {{SSRN} Scholarly Paper},
	author = {Weyl, E. Glen and Zhang, Anthony Lee},
	urldate = {2022-03-02},
	date = {2021-04-28},
	langid = {english},
	doi = {10.2139/ssrn.3698941},
	keywords = {depreciating license, investment, misallocation, property rights},
	file = {Snapshot:/home/volodia/Zotero/storage/XSYIE2UF/papers.html:text/html;Weyl_Zhang_2021_Depreciating Licenses.pdf:/home/volodia/Zotero/storage/QINBPA5H/Weyl_Zhang_2021_Depreciating Licenses.pdf:application/pdf},
}

@article{baranwal_fair_2015,
	title = {A fair multi-attribute combinatorial double auction model for resource allocation in cloud computing},
	volume = {108},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121215001272},
	doi = {10.1016/j.jss.2015.06.025},
	abstract = {Recently, Cloud computing has emerged as a market where computing related resources are treated as a utility and are priced. There is a big competition among the Cloud service providers and therefore, the providers offer the services strategically. Auction, a market based resource allocation strategy, has received the attention among the Cloud researchers recently. The auction principal of resource allocation is based on demand and supply. This work proposes a multi-attribute combinatorial double auction for the allocation of Cloud resources, which not only considers the price but other quality of service parameters also. Auctioneer extends some of the parameters to the offered bids from the bidders in order to provide fairness and robustness. In case of not meeting the assured quality, a penalty is imposed on the provider and customer is compensated. The reputation of the provider also diminishes in the forthcoming rounds. Performance study of the proposed model is done by simulation which reflects the usefulness of the method.},
	pages = {60--76},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Baranwal, Gaurav and Vidyarthi, Deo Prakash},
	urldate = {2022-03-03},
	date = {2015-10-01},
	langid = {english},
	keywords = {Cloud resources, Double auction, Multi-attribute},
	file = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/TRCWP5QM/S0164121215001272.html:text/html},
}

@article{baranwal_fair_2015-1,
	title = {A fair multi-attribute combinatorial double auction model for resource allocation in cloud computing},
	volume = {108},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121215001272},
	doi = {10.1016/j.jss.2015.06.025},
	abstract = {Recently, Cloud computing has emerged as a market where computing related resources are treated as a utility and are priced. There is a big competition among the Cloud service providers and therefore, the providers offer the services strategically. Auction, a market based resource allocation strategy, has received the attention among the Cloud researchers recently. The auction principal of resource allocation is based on demand and supply. This work proposes a multi-attribute combinatorial double auction for the allocation of Cloud resources, which not only considers the price but other quality of service parameters also. Auctioneer extends some of the parameters to the offered bids from the bidders in order to provide fairness and robustness. In case of not meeting the assured quality, a penalty is imposed on the provider and customer is compensated. The reputation of the provider also diminishes in the forthcoming rounds. Performance study of the proposed model is done by simulation which reflects the usefulness of the method.},
	pages = {60--76},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Baranwal, Gaurav and Vidyarthi, Deo Prakash},
	urldate = {2022-03-03},
	date = {2015-10-01},
	langid = {english},
	keywords = {Cloud resources, Double auction, Multi-attribute},
	file = {Baranwal_Vidyarthi_2015_A fair multi-attribute combinatorial double auction model for resource.pdf:/home/volodia/Zotero/storage/69FVX4DA/Baranwal_Vidyarthi_2015_A fair multi-attribute combinatorial double auction model for resource.pdf:application/pdf;ScienceDirect Snapshot:/home/volodia/Zotero/storage/P75WGW9Y/S0164121215001272.html:text/html},
}

@article{nguyen_market-based_2019,
	title = {A Market-Based Framework for Multi-Resource Allocation in Fog Computing},
	volume = {27},
	issn = {1558-2566},
	doi = {10.1109/TNET.2019.2912077},
	abstract = {Fog computing is transforming the network edge into an intelligent platform by bringing storage, computing, control, and networking functions closer to end users, things, and sensors. How to allocate multiple resource types (e.g., {CPU}, memory, bandwidth) of capacity-limited heterogeneous fog nodes to competing services with diverse requirements and preferences in a fair and efficient manner is a challenging task. To this end, we propose a novel market-based resource allocation framework in which the services act as buyers and fog resources act as divisible goods in the market. The proposed framework aims to compute a market equilibrium ({ME}) solution at which every service obtains its favorite resource bundle under the budget constraint, while the system achieves high resource utilization. This paper extends the general equilibrium literature by considering a practical case of satiated utility functions. In addition, we introduce the notions of non-wastefulness and frugality for equilibrium selection and rigorously demonstrate that all the non-wasteful and frugal {ME} are the optimal solutions to a convex program. Furthermore, the proposed equilibrium is shown to possess salient fairness properties, including envy-freeness, sharing-incentive, and proportionality. Another major contribution of this paper is to develop a privacy-preserving distributed algorithm, which is of independent interest, for computing an {ME} while allowing market participants to obfuscate their private information. Finally, extensive performance evaluation is conducted to verify our theoretical analyses.},
	pages = {1151--1164},
	number = {3},
	journaltitle = {{IEEE}/{ACM} Transactions on Networking},
	author = {Nguyen, Duong Tung and Le, Long Bao and Bhargava, Vijay K.},
	date = {2019-06},
	note = {Conference Name: {IEEE}/{ACM} Transactions on Networking},
	keywords = {Cloud computing, Edge computing, Computational modeling, fog computing, Resource management, Sensors, Companies, General equilibrium, Germanium, multi-resource allocation, privacy-preserving distributed optimization},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/C24ZP4JR/8700615.html:text/html;Nguyen et al_2019_A Market-Based Framework for Multi-Resource Allocation in Fog Computing.pdf:/home/volodia/Zotero/storage/MV3JL6CG/Nguyen et al_2019_A Market-Based Framework for Multi-Resource Allocation in Fog Computing.pdf:application/pdf},
}

@inproceedings{kayal_distributed_2019,
	title = {Distributed Service Placement in Fog Computing: An Iterative Combinatorial Auction Approach},
	doi = {10.1109/ICDCS.2019.00211},
	shorttitle = {Distributed Service Placement in Fog Computing},
	abstract = {A primary concern in fog computing is how to efficiently allocate limited fog resources to applications with diverse resource requirements. In fog computing, applications that consist of a set of interdependent microservices are mapped to computing and communication devices, referred to as fog nodes. While placement of microservices can be done centrally, the essentially decentralized infrastructure of participating end-user devices motivates the search for distributed solutions. In this paper, we present a distributed placement strategy that seeks to optimize energy consumption and communication costs. We devise a game-theoretic approximation method that is inspired by an iterative combinatorial auction. By properly restricting the types of bids that can be made in an auction, we can avoid the need for a centralized auctioneer. We devise a fully distributed service placement algorithm without central coordination or global state information. The algorithm operates in rounds, where the number of rounds is bounded by the number of applications and the total number of microservices. Numerical examples show that our placement algorithm outperforms existing heuristics in terms of efficiency and network utilization while achieving comparable utilization and load balancing.},
	eventtitle = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	pages = {2145--2156},
	booktitle = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	author = {Kayal, Paridhika and Liebeherr, Jörg},
	date = {2019-07},
	note = {{ISSN}: 2575-8411},
	keywords = {Edge computing, Resource management, Internet of Things, Optimization, Approximation algorithms, Energy consumption, Fog computing, resource allocation, iterative combinatorial auction, Indexes},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/SLQSMDN9/8885368.html:text/html;Kayal_Liebeherr_2019_Distributed Service Placement in Fog Computing.pdf:/home/volodia/Zotero/storage/7P5HWUQB/Kayal_Liebeherr_2019_Distributed Service Placement in Fog Computing.pdf:application/pdf},
}

@article{babaioff_era_2017,
	title = {{ERA}: A Framework for Economic Resource Allocation for the Cloud},
	url = {http://arxiv.org/abs/1702.07311},
	doi = {10.1145/3041021.3054186},
	shorttitle = {{ERA}},
	abstract = {Cloud computing has reached significant maturity from a systems perspective, but currently deployed solutions rely on rather basic economics mechanisms that yield suboptimal allocation of the costly hardware resources. In this paper we present Economic Resource Allocation ({ERA}), a complete framework for scheduling and pricing cloud resources, aimed at increasing the efficiency of cloud resources usage by allocating resources according to economic principles. The {ERA} architecture carefully abstracts the underlying cloud infrastructure, enabling the development of scheduling and pricing algorithms independently of the concrete lower-level cloud infrastructure and independently of its concerns. Specifically, {ERA} is designed as a flexible layer that can sit on top of any cloud system and interfaces with both the cloud resource manager and with the users who reserve resources to run their jobs. The jobs are scheduled based on prices that are dynamically calculated according to the predicted demand. Additionally, {ERA} provides a key internal {API} to pluggable algorithmic modules that include scheduling, pricing and demand prediction. We provide a proof-of-concept software and demonstrate the effectiveness of the architecture by testing {ERA} over both public and private cloud systems -- Azure Batch of Microsoft and Hadoop/{YARN}. A broader intent of our work is to foster collaborations between economics and system communities. To that end, we have developed a simulation platform via which economics and system experts can test their algorithmic implementations.},
	pages = {635--642},
	journaltitle = {Proceedings of the 26th International Conference on World Wide Web Companion - {WWW} '17 Companion},
	author = {Babaioff, Moshe and Mansour, Yishay and Nisan, Noam and Noti, Gali and Curino, Carlo and Ganapathy, Nar and Menache, Ishai and Reingold, Omer and Tennenholtz, Moshe and Timnat, Erez},
	urldate = {2022-03-09},
	date = {2017},
	eprinttype = {arxiv},
	eprint = {1702.07311},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Computer Science and Game Theory},
	file = {arXiv.org Snapshot:/home/volodia/Zotero/storage/KMM8WGG5/1702.html:text/html;Babaioff et al_2017_ERA.pdf:/home/volodia/Zotero/storage/H5QL5DWH/Babaioff et al_2017_ERA.pdf:application/pdf},
}

@article{cherrueau_enoslib_2022,
	title = {{EnosLib}: A Library for Experiment-Driven Research in Distributed Computing},
	volume = {33},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2021.3111159},
	shorttitle = {{EnosLib}},
	abstract = {Despite the importance of experiment-driven research in the distributed computing community, there has been little progress in helping researchers conduct their experiments. In most cases, they have to achieve tedious and time-consuming development and instrumentation activities to deal with the specifics of testbeds and the system under study. In order to relieve researchers of the burden of those efforts, we have developed {EnosLib}: a Python library that takes into account best experimentation practices and leverages modern toolkits on automatic deployment and configuration systems. {EnosLib} helps researchers not only in the process of developing their experimental artifacts, but also in running them over different infrastructures. To demonstrate the relevance of our library, we discuss three experimental engines built on top of {EnosLib}, and used to conduct empirical studies on complex software stacks between 2016 and 2019 (database systems, communication buses and {OpenStack}). By introducing {EnosLib}, our goal is to gather academic and industrial actors of our community around a library that aggregates everyday experiment-driven research operations. A library that has been already adopted by open-source projects and members of the scientific community thanks to its ease of use and extension.},
	pages = {1464--1477},
	number = {6},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	author = {Cherrueau, Ronan-Alexandre and Delavergne, Marie and van Kempen, Alexandre and Lebre, Adrien and Pertin, Dimitri and Balderrama, Javier Rojas and Simonet, Anthony and Simonin, Matthieu},
	date = {2022-06},
	note = {Conference Name: {IEEE} Transactions on Parallel and Distributed Systems},
	keywords = {performance evaluation, Task analysis, Protocols, Tools, Benchmark testing, Codes, distributed computing experimentation library, Experiment-driven research, Libraries, Software},
	file = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/PPL2B4Y4/authors.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/3JAH7EDG/Cherrueau et al. - 2022 - EnosLib A Library for Experiment-Driven Research .pdf:application/pdf},
}

@inproceedings{battulga_livingfog_2022,
	location = {Paris, France},
	title = {{LivingFog}: Leveraging fog computing and {LoRaWAN} technologies for smart marina management (experience paper)},
	isbn = {978-1-72818-688-7},
	url = {https://ieeexplore.ieee.org/document/9758124/},
	doi = {10.1109/ICIN53892.2022.9758124},
	shorttitle = {{LivingFog}},
	abstract = {In recent years, fog computing has emerged as a paradigm that brings computing, storage and networking resources closer to end users and devices at the edge of the network. One of the use cases for fog computing is {IoT}, where a large amount of data is generated by sensors that need to be pre-processed in place before the results are sent to the cloud for further processing and long-term storage. However, actual fog deployments are at their infancy. In this paper, we present the smart-marina project at La Marina de Valencia in which the {LivingFog} fog computing platform integrating opensource software and {LoRaWAN} technologies were used to process data collected from several sensors. We show the beneﬁts of the platform in terms of latency reduction and bandwidth saving. Moreover, the platform has been used by particpants of the “Hack the fog” hackathon to deploy applications to test different innovative ideas on using the sensor data.},
	eventtitle = {2022 25th Conference on Innovation in Clouds, Internet and Networks and Workshops ({ICIN})},
	pages = {9--16},
	booktitle = {2022 25th Conference on Innovation in Clouds, Internet and Networks ({ICIN})},
	publisher = {{IEEE}},
	author = {Battulga, Davaadorj and Farhadi, Mozhdeh and Tamiru, Mulugeta Ayalew and Wu, Li and Pierre, Guillaume},
	urldate = {2022-05-30},
	date = {2022-03-07},
	langid = {english},
	file = {Battulga et al. - 2022 - LivingFog Leveraging fog computing and LoRaWAN te.pdf:/home/volodia/Zotero/storage/WU9LIJ54/Battulga et al. - 2022 - LivingFog Leveraging fog computing and LoRaWAN te.pdf:application/pdf},
}

@article{bermbach_auctionwhisk_2022,
	title = {{AuctionWhisk}: Using an auction-inspired approach for function placement in serverless fog platforms},
	volume = {52},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3058},
	doi = {10.1002/spe.3058},
	shorttitle = {{AuctionWhisk}},
	abstract = {The Function-as-a-Service ({FaaS}) paradigm has a lot of potential as a computing model for fog environments comprising both cloud and edge nodes, as compute requests can be scheduled across the entire fog continuum in a fine-grained manner. When the request rate exceeds capacity limits at the resource-constrained edge, some functions need to be offloaded toward the cloud. In this article, we present an auction-inspired approach in which application developers bid on resources while fog nodes decide locally which functions to execute and which to offload in order to maximize revenue. Unlike many current approaches to function placement in the fog, our approach can work in an online and decentralized manner. We also present our proof-of-concept prototype {AuctionWhisk} that illustrates how such an approach can be implemented in a real {FaaS} platform. Through a number of simulation runs and system experiments, we show that revenue for overloaded nodes can be maximized without dropping function requests.},
	pages = {1143--1169},
	number = {5},
	journaltitle = {Software: Practice and Experience},
	author = {Bermbach, David and Bader, Jonathan and Hasenburg, Jonathan and Pfandzelter, Tobias and Thamsen, Lauritz},
	urldate = {2022-05-31},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3058},
	keywords = {function-as-a-service, fog computing, serverless computing, distributed scheduling},
	file = {Full Text PDF:/home/volodia/Zotero/storage/N45PLEJT/Bermbach et al. - 2022 - AuctionWhisk Using an auction-inspired approach f.pdf:application/pdf;Snapshot:/home/volodia/Zotero/storage/DGSRXYRR/spe.html:text/html},
}

@inproceedings{bouizem_active-standby_2020,
	location = {New York, {NY}, {USA}},
	title = {Active-Standby for High-Availability in {FaaS}},
	isbn = {978-1-4503-8204-5},
	url = {https://doi.org/10.1145/3429880.3430097},
	doi = {10.1145/3429880.3430097},
	series = {{WoSC}'20},
	abstract = {Serverless computing is becoming more and more attractive for cloud solution architects and developers. This new computing paradigm relies on Function-as-a-Service ({FaaS}) platforms that enable deploying functions without being concerned with the underlying infrastructure. An important challenge in designing {FaaS} platforms is ensuring the availability of deployed functions. Existing {FaaS} platforms address this challenge principally through retrying function executions. In this paper, we propose and implement an alternative fault-tolerance approach based on active-standby failover. Results from an experimental evaluation show that our approach increases availability and performance compared to the retry-based approach.},
	pages = {31--36},
	booktitle = {Proceedings of the 2020 Sixth International Workshop on Serverless Computing},
	publisher = {Association for Computing Machinery},
	author = {Bouizem, Yasmina and Parlavantzas, Nikos and Dib, Djawida and Morin, Christine},
	urldate = {2022-05-31},
	date = {2020-12-07},
	keywords = {{FaaS}, availability, fault tolerance},
	file = {Full Text PDF:/home/volodia/Zotero/storage/8ZYSATRZ/Bouizem et al. - 2020 - Active-Standby for High-Availability in FaaS.pdf:application/pdf},
}

@inproceedings{costache_economic_2012,
	location = {Berlin, Heidelberg},
	title = {An Economic Approach for Application {QoS} Management in Clouds},
	isbn = {978-3-642-29740-3},
	doi = {10.1007/978-3-642-29740-3_48},
	series = {Lecture Notes in Computer Science},
	abstract = {Virtualization provides increased control and flexibility in how resources are allocated to applications. However, common resource provisioning mechanisms do not fully use these advantages; either they provide limited support for applications demanding quality of service, or the resource allocation complexity is high. To address this problem we propose a novel resource management architecture for virtualized infrastructures based on a virtual economy. By limiting the coupling between the applications and the resource management, this architecture can support diverse types of applications and performance goals while ensuring an efficient resource usage. We validate its use through simple policies that scale the resource allocations of the applications vertically and horizontally to meet application performance goals.},
	pages = {426--435},
	booktitle = {Euro-Par 2011: Parallel Processing Workshops},
	publisher = {Springer},
	author = {Costache, Stefania and Parlavantzas, Nikos and Morin, Christine and Kortas, Samuel},
	editor = {Alexander, Michael and D’Ambra, Pasqua and Belloum, Adam and Bosilca, George and Cannataro, Mario and Danelutto, Marco and Di Martino, Beniamino and Gerndt, Michael and Jeannot, Emmanuel and Namyst, Raymond and Roman, Jean and Scott, Stephen L. and Traff, Jesper Larsson and Vallée, Geoffroy and Weidendorfer, Josef},
	date = {2012},
	langid = {english},
	keywords = {Cloud Infrastructure, Performance Goal, Resource Management System, Schedule Period, Virtual Machine},
	file = {Full Text PDF:/home/volodia/Zotero/storage/6GZ3894M/Costache et al. - 2012 - An Economic Approach for Application QoS Managemen.pdf:application/pdf},
}

@article{costache_resource_2017,
	title = {Resource management in cloud platform as a service systems: Analysis and opportunities},
	volume = {132},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217300845},
	doi = {10.1016/j.jss.2017.05.035},
	shorttitle = {Resource management in cloud platform as a service systems},
	abstract = {Platform-as-a-Service ({PaaS}) clouds offer services to automate the deployment and management of applications, relieving application owners of the complexity of managing the underlying infrastructure resources. However, application owners have an increasingly larger diversity and volume of workloads, which they want to execute at minimum cost while maintaining desired performance guarantees. In this paper we investigate how existing {PaaS} systems cope with this challenge. In particular, we first present a taxonomy of commonly-encountered design decisions regarding how {PaaS} systems manage underlying resources. We then use this taxonomy to analyze an extensive set of {PaaS} systems targeting different application domains. Based on this analysis, we identify several future research opportunities in the {PaaS} design space, which will enable {PaaS} owners to reduce hosting costs while coping with the workload variety.},
	pages = {98--118},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Costache, Stefania and Dib, Djawida and Parlavantzas, Nikos and Morin, Christine},
	urldate = {2022-05-31},
	date = {2017-10-01},
	langid = {english},
	keywords = {Cloud computing, Resource management, Platform-as-a-service},
	file = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/PF2NDB5W/S0164121217300845.html:text/html},
}

@report{longuevergne_terra_2022,
	title = {{TERRA} {FORMA}: Developing the observation platform of the Anthropocene\&nbsp;},
	url = {https://meetingorganizer.copernicus.org/EGU22/EGU22-13559.html},
	shorttitle = {{TERRA} {FORMA}},
	number = {{EGU}22-13559},
	institution = {Copernicus Meetings},
	author = {Longuevergne, Laurent and Elger, Arnaud and Girard, Virginie},
	urldate = {2022-06-03},
	date = {2022-03-25},
	langid = {english},
	doi = {10.5194/egusphere-egu22-13559},
	note = {Conference Name: {EGU}22},
	file = {Snapshot:/home/volodia/Zotero/storage/XY8DYCKQ/EGU22-13559.html:text/html},
}