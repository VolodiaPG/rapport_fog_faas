@article{kim_economics_2020,
	title        = {Economics of Fog Computing: Interplay Among Infrastructure and Service Providers, Users, and Edge Resource Owners},
	shorttitle   = {Economics of Fog Computing},
	author       = {Kim, Daewoo and Lee, Hyojung and Song, Hyungseok and Choi, Nakjung and Yi, Yung},
	volume       = 19,
	number       = 11,
	pages        = {2609--2622},
	doi          = {10.1109/TMC.2019.2925797},
	issn         = {1558-0660},
	note         = {Conference Name: {IEEE} Transactions on Mobile Computing},
	abstract     = {Fog computing is a paradigm which brings computing, storage, and networking closer to end users and end devices for better service provisioning. One of the crucial factors in the success of fog computing is on how to incentivize the individual users' edge resources and provide them to end users such that fog computing is economically beneficial to all involved economic players. In this paper, we model and analyze a market of fog computing, from which we aim at drawing practical implications to uncover how the fog computing market should operate. To this end, we conduct an economic analysis of such user-oriented fog computing by modeling a market consisting of Infrastructure and Service Provider ({ISP}), end Service Users ({SUs}), and Edge Resource Owners ({EROs}) as a non-cooperative game. In this market, {ISP}, which provides a platform for fog computing, behaves as a mediator or a broker which leases {EROs}' edge resources and provides various services to {SUs}. In our model, a two-stage dynamic game is used where in each stage, there exists a dynamic game, one for between {ISP} and {EROs} and another for between {ISP} and {SUs}, to model the market more practically. Despite this complex game structure, we provide a closed-form equilibrium analysis which gives an insight on how much economic benefit is obtained by {ISP}, {SUs}, and {EROs} from user-oriented fog computing under what conditions, and we figure out the economic factors that have a significant impact on the success of fog computing.},
	journaltitle = {{IEEE} Transactions on Mobile Computing},
	date         = {2020-11},
	keywords     = {Edge computing, Business, Computational modeling, Economics, Edge network, fog computing, game theory, Games, {III}-V semiconductor materials, Indium phosphide, network economics},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/729CK3JW/8766848.html:text/html;Economics of Fog Computing\: Interplay Among Infrastructure and Service Providers, Users, and Edge Resource Owners:/home/volodia/Zotero/storage/XXZVIMHM/kim2019.pdf.pdf:application/pdf}
}
@inproceedings{samanta_incentivizing_2019,
	title        = {Incentivizing Microservices for Online Resource Sharing in Edge Clouds},
	author       = {Samanta, Amit and Jiao, Lei and M\"{u}hlh\"{a}user, Max and Wang, Lin},
	booktitle    = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	pages        = {420--430},
	doi          = {10.1109/ICDCS.2019.00049},
	note         = {{ISSN}: 2575-8411},
	abstract     = {The microservice architecture provides high agility, making it a suitable choice for implementing edge cloud services. Provisioning microservices at the network edge requires the dynamic allocation of resources. However, due to the resource limitation in the edge cloud environment, there is no guarantee that enough resources are always available upon a microservice's requests. In this paper, we design an online auction-based mechanism to incentivize microservices to spare their occupied resources so that the edge cloud platform can reclaim them and reallocate them to other microservices that need resources. We firstly design a single-stage auction that determines the winning bids to satisfy the resource demands in polynomial time, while calculating the payments. Then, we design an online framework to tie a series of such single-stage auctions into a multi-stage online mechanism without requiring the knowledge of future bids and demands. Via rigorous analysis, we exhibit that our mechanism design achieves truthful bidding and individual rationality, with a constant competitive ratio regarding the social cost of the system in the long run. Finally, we verify the practical performance of our mechanism through extensive simulations.},
	eventtitle   = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	date         = {2019-07},
	keywords     = {Cloud computing, Edge computing, Resource management, Economics, Estimation, Dynamic scheduling, Microservice, Online algorithm, Pricing, Resource sharing},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/IKG559L9/8885350.html:text/html;Incentivizing Microservices for Online Resource Sharing in Edge Clouds:/home/volodia/Zotero/storage/6FYRKJ7T/samanta2019.pdf.pdf:application/pdf}
}
@article{tasiopoulos_fogspot_2019,
	title        = {{FogSpot}: Spot Pricing for Application Provisioning in Edge/Fog Computing},
	shorttitle   = {{FogSpot}},
	author       = {Tasiopoulos, Argyrios and Ascigil, Onur and Psaras, Ioannis and Toumpis, Stavros and Pavlou, George},
	volume       = 14,
	number       = 6,
	pages        = {1--1},
	doi          = {10.1109/TSC.2019.2895037},
	issn         = {1939-1374},
	note         = {Conference Name: {IEEE} Transactions on Services Computing},
	abstract     = {An increasing number of Low Latency Applications ({LLAs}) in the entertainment, {IoT}, and automotive domains require response times that challenge the traditional application provisioning using distant Data Centres. Fog computing paradigm extends cloud computing at the edge and middle-tier locations of the network, providing response times an order of magnitude smaller than those that can be achieved by the current "client-to-cloud" network model. Here, we address the challenges of provisioning heavily stateful {LLA} in the setting where fog infrastructure consists of third-party computing resources, i.e., cloudlets, that comes in the form of "data centres in the box". We introduce {FogSpot}, a charging mechanism for on-path, on-demand, application provisioning. In {FogSpot}, cloudlets offer their resources in the form of Virtual Machines ({VMs}) via markets, collocated with the cloudlets, that interact with forwarded users' application requests for {VMs} in real time. {FogSpot} associates each cloudlet with a spot price based on current application requests. The proposed mechanism's design takes into account the characteristics of cloudlets' resources, such as their limited elasticity, and {LLAs}' attributes, like the expected {QoS} gain and engagement duration. Lastly, {FogSpot} guarantees end users' requests truthfulness while focusing in maximising either each cloudlet's revenue or resource utilisation.},
	journaltitle = {{IEEE} Transactions on Services Computing},
	date         = 2019,
	keywords     = {Cloud computing, Edge computing, Data centers, Task analysis, Quality of service, Pricing, Elasticity},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/MMNBG3IY/8625439.html:text/html;Submitted Version:/home/volodia/Zotero/storage/HS2875WE/Tasiopoulos et al. - 2019 - FogSpot Spot Pricing for Application Provisioning.pdf:application/pdf;FogSpot\: Spot Pricing for Application Provisioning in Edge/Fog Computing:/home/volodia/Zotero/storage/6DEI24LH/10.1109\@TSC.2019.2895037.pdf.pdf:application/pdf}
}
@inproceedings{fawcett_combinatorial_2016,
	title        = {Combinatorial Auction-Based Resource Allocation in the Fog},
	author       = {Fawcett, Lyndon and Broadbent, Matthew and Race, Nicholas},
	booktitle    = {2016 Fifth European Workshop on Software-Defined Networks ({EWSDN})},
	pages        = {62--67},
	doi          = {10.1109/EWSDN.2016.16},
	note         = {{ISSN}: 2379-0369},
	abstract     = {Network service composition is becoming increasingly flexible, thanks in part to advances in virtualisation and cloud technologies. As these penetrate further into networks, providers are often looking to leverage this infrastructure to improve their service delivery. This desire poses a number of obstacles, including a diversity in device capabilities and the need for a value exchange mechanism. In this demonstration, we present a platform that seeks to address a selection of these challenges.},
	eventtitle   = {2016 Fifth European Workshop on Software-Defined Networks ({EWSDN})},
	date         = {2016-10},
	keywords     = {Cloud computing, Edge computing, Fog Computing, Resource management, Containers, Combinatorial Auctions, Conferences, Europe, Network Virtualisation, Orchestration, Provisioning},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/R7EHW86M/7956056.html:text/html;Accepted Version:/home/volodia/Zotero/storage/2J77S9SI/Fawcett et al. - 2016 - Combinatorial Auction-Based Resource Allocation in.pdf:application/pdf;Combinatorial Auction-Based Resource Allocation in the Fog:/home/volodia/Zotero/storage/YYHMJHT6/fawcett2016.pdf.pdf:application/pdf}
}
@article{bermbach_auctionwhisk_2021,
	title        = {{AuctionWhisk}: Using an Auction-Inspired Approach for Function Placement in Serverless Fog Platforms},
	shorttitle   = {{AuctionWhisk}},
	author       = {Bermbach, David and Bader, Jonathan and Hasenburg, Jonathan and Pfandzelter, Tobias and Thamsen, Lauritz},
	booktitle    = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	volume       = 52,
	number       = 5,
	pages        = {25--31},
	doi          = {10.1109/ICFC49376.2020.00012},
	issn         = {1097-024X},
	url          = {http://arxiv.org/abs/2108.13222},
	urldate      = {2021-11-15},
	note         = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3058},
	abstract     = {The Function-as-a-Service ({FaaS}) paradigm has a lot of potential as a computing model for fog environments comprising both cloud and edge nodes. When the request rate exceeds capacity limits at the edge, some functions need to be offloaded from the edge towards the cloud. In this paper, we present an auction-inspired approach in which application developers bid on resources while fog nodes decide locally which functions to execute and which to offload in order to maximize revenue. We evaluate our approach through a number of simulations, our proof-of-concept prototype {AuctionWhisk}, and a number of experiments with {AuctionWhisk}.},
	journaltitle = {{arXiv}:2108.13222 [cs]},
	date         = {2021-08-30},
	eprinttype   = {arxiv},
	eprint       = {2108.13222},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file         = {arXiv Fulltext PDF:/home/volodia/Zotero/storage/SBG2QP3Q/Bermbach et al. - 2021 - AuctionWhisk Using an Auction-Inspired Approach f.pdf:application/pdf;arXiv.org Snapshot:/home/volodia/Zotero/storage/6Y99HU78/2108.html:text/html},
	eventtitle   = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	langid       = {english}
}
@article{mampage_holistic_2021,
	title        = {A Holistic View on Resource Management in Serverless Computing Environments: Taxonomy and Future Directions},
	shorttitle   = {A Holistic View on Resource Management in Serverless Computing Environments},
	author       = {Mampage, Anupama and Karunasekera, Shanika and Buyya, Rajkumar},
	url          = {http://arxiv.org/abs/2105.11592},
	urldate      = {2021-12-01},
	abstract     = {Serverless computing has emerged as an attractive deployment option for cloud applications in recent times. The unique features of this computing model include, rapid auto-scaling, strong isolation, fine-grained billing options and access to a massive service ecosystem which autonomously handles resource management decisions. This model is increasingly being explored for deployments in geographically distributed edge and fog computing networks as well, due to these characteristics. Effective management of computing resources has always gained a lot of attention among researchers. The need to automate the entire process of resource provisioning, allocation, scheduling, monitoring and scaling, has resulted in the need for specialized focus on resource management under the serverless model. In this article, we identify the major aspects covering the broader concept of resource management in serverless environments and propose a taxonomy of elements which influence these aspects, encompassing characteristics of system design, workload attributes and stakeholder expectations. We take a holistic view on serverless environments deployed across edge, fog and cloud computing networks. We also analyse existing works discussing aspects of serverless resource management using this taxonomy. This article further identifies gaps in literature and highlights future research directions for improving capabilities of this computing model.},
	journaltitle = {{arXiv}:2105.11592 [cs]},
	date         = {2021-05-31},
	eprinttype   = {arxiv},
	eprint       = {2105.11592},
	keywords     = {A.1, C.m, Computer Science - Distributed, Parallel, and Cluster Computing},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/W3P28Q4P/2105.html:text/html;arXiv Fulltext PDF:/home/volodia/Zotero/storage/2FJJPQZN/Mampage et al. - 2021 - A Holistic View on Resource Management in Serverle.pdf:application/pdf}
}
@inproceedings{aslanpour_serverless_2021,
	title        = {Serverless Edge Computing: Vision and Challenges},
	shorttitle   = {Serverless Edge Computing},
	author       = {Aslanpour, Mohammad S. and Toosi, Adel N. and Cicconetti, Claudio and Javadi, Bahman and Sbarski, Peter and Taibi, Davide and Assuncao, Marcos and Gill, Sukhpal Singh and Gaire, Raj and Dustdar, Schahram},
	booktitle    = {2021 Australasian Computer Science Week Multiconference},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{ACSW} '21},
	pages        = {1--10},
	doi          = {10.1145/3437378.3444367},
	isbn         = {978-1-4503-8956-3},
	url          = {https://doi.org/10.1145/3437378.3444367},
	urldate      = {2021-11-15},
	abstract     = {Born from a need for a pure ``pay-per-use'' model and highly scalable platform, the ``Serverless'' paradigm emerged and has the potential to become a dominant way of building cloud applications. Although it was originally designed for cloud environments, Serverless is finding its position in the Edge Computing landscape, aiming to bring computational resources closer to the data source. That is, Serverless is crossing cloud borders to assess its merits in Edge computing, whose principal partner will be the Internet of Things ({IoT}) applications. This move sounds promising as Serverless brings particular benefits such as eliminating always-on services causing high electricity usage, for instance. However, the community is still hesitant to uptake Serverless Edge Computing because of the cloud-driven design of current Serverless platforms, and distinctive characteristics of edge landscape and {IoT} applications. In this paper, we evaluate both sides to shed light on the Serverless new territory. Our in-depth analysis promotes a broad vision for bringing Serverless to the Edge Computing. It also issues major challenges for Serverless to be met before entering Edge computing.},
	date         = {2021-02-01},
	file         = {Serverless Edge Computing\: Vision and Challenges:/home/volodia/Zotero/storage/IPK7XN74/aslanpour2021.pdf.pdf:application/pdf}
}
@article{salaht_overview_2020,
	title        = {An Overview of Service Placement Problem in Fog and Edge Computing},
	author       = {Salaht, Farah A\"{\i}t and Desprez, Fr\'{e}d\'{e}ric and Lebre, Adrien},
	volume       = 53,
	number       = 3,
	pages        = {65:1--65:35},
	doi          = {10.1145/3391196},
	issn         = {0360-0300},
	url          = {https://doi.org/10.1145/3391196},
	urldate      = {2021-11-15},
	abstract     = {To support the large and various applications generated by the Internet of Things ({IoT}), Fog Computing was introduced to complement the Cloud Computing and offer Cloud-like services at the edge of the network with low latency and real-time responses. Large-scale, geographical distribution, and heterogeneity of edge computational nodes make service placement in such infrastructure a challenging issue. Diversity of user expectations and {IoT} devices characteristics also complicate the deployment problem. This article presents a survey of current research conducted on Service Placement Problem ({SPP}) in the Fog/Edge Computing. Based on a new classification scheme, a categorization of current proposals is given and identified issues and challenges are discussed.},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	date         = {2020-06-12},
	keywords     = {edge computing, classification, deployment taxonomy, Fog computing, optimization, service placement},
	file         = {Submitted Version:/home/volodia/Zotero/storage/PW85BMSN/Salaht et al. - 2020 - An Overview of Service Placement Problem in Fog an.pdf:application/pdf;An Overview of Service Placement Problem in Fog and Edge Computing:/home/volodia/Zotero/storage/FH4Y59JP/salaht2020.pdf.pdf:application/pdf}
}
@inproceedings{palade_evaluation_2019,
	title        = {An Evaluation of Open Source Serverless Computing Frameworks Support at the Edge},
	author       = {Palade, Andrei and Kazmi, Aqeel and Clarke, Siobh\'{a}n},
	booktitle    = {2019 {IEEE} World Congress on Services ({SERVICES})},
	volume       = {2642-939X},
	pages        = {206--211},
	doi          = {10.1109/SERVICES.2019.00057},
	note         = {{ISSN}: 2642-939X},
	abstract     = {The proliferation of Internet of Things ({IoT}) and the success of resource-rich cloud services have pushed the data processing horizon towards the edge of the network. This has the potential to address bandwidth costs, and latency, availability and data privacy concerns. Serverless computing, a cloud computing model for stateless and event-driven applications, promises to further improve Quality of Service ({QoS}) by eliminating the burden of always-on infrastructure through ephemeral containers. Open source serverless frameworks have been introduced to avoid the vendor lock-in and computation restrictions of public cloud platforms and to bring the power of serverless computing to on-premises deployments. In an {IoT} environment, these frameworks can leverage the computational capabilities of devices in the local network to further improve {QoS} of applications delivered to the user. However, these frameworks have not been evaluated in a resource-constrained, edge computing environment. In this work we evaluate four open source serverless frameworks, namely, Kubeless, Apache {OpenWhisk}, {OpenFaaS}, Knative. Each framework is installed on a bare-metal, single master, Kubernetes cluster. We use the {JMeter} framework to evaluate the response time, throughput and success rate of functions deployed using these frameworks under different workloads. The evaluation results are presented and open research opportunities are discussed.},
	eventtitle   = {2019 {IEEE} World Congress on Services ({SERVICES})},
	date         = {2019-07},
	keywords     = {Edge computing, {FaaS}, Computational modeling, serverless computing, Task analysis, Runtime, Quality of service, containers, Containers, Apache Openwhisk, Docker, Function as a Service, function composition, {JMeter}, Knative, kubeless, Kubernetes, Measurement, {OpenFaaS}, opensource serverless computing frameworks, {QoS}, quantitative evaluation},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/38C4EDNH/8817155.html:text/html;Submitted Version:/home/volodia/Zotero/storage/LQTWIETZ/Palade et al. - 2019 - An Evaluation of Open Source Serverless Computing .pdf:application/pdf;An Evaluation of Open Source Serverless Computing Frameworks Support at the Edge:/home/volodia/Zotero/storage/5PPLMJSZ/palade2019.pdf.pdf:application/pdf}
}
@thesis{bolton_intersection_2021,
	title        = {The Intersection of Function-as-a-Service and Stream Computing},
	author       = {Bolton, Trevor A.},
	url          = {https://oaktrust.library.tamu.edu/handle/1969.1/194395},
	urldate      = {2021-12-01},
	note         = {Accepted: 2021-07-24T00:30:13Z},
	abstract     = {With recent advancements in the field of computing including the emergence of cloud computing, the consumption and accessibility of computational resources have increased drastically. Although there have been significant movements towards more sustainable computing, there are many more steps to be taken to decrease the amount of energy consumed and greenhouse gases released from the computing sector. Historically, the switch from on-premises computing to cloud computing has led to less energy consumption through the design of efficient data centers. By releasing direct control of the hardware that their software is run on, an organization can also increase efficiency and reduce costs. A new development in cloud computing has been serverless computing. Even though the term "serverless" is a misnomer because all applications are still executed on servers, serverless lets an organization resign another level of control, managing instances of virtual machines, to their cloud provider in order to reduce their cost. The cloud provider then provisions resources on-demand enabling less idle time. This reduction of idle time is a direct reduction of computing resources used, therefore resulting in a decrease in energy consumption. One form of serverless computing, Function-as-a-Service ({FaaS}), may have a promising future replacing some stream computing applications in order to increase efficiency and reduce waste. To explore these possibilities, the development of a stream processing application using traditional methods through Kafka Streams and {FaaS} through {AWS} Lambda was completed in order to demonstrate that {FaaS} can be used for stateless stream processing.},
	type         = {Thesis},
	date         = {2021-07-24},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/ZFT82WXE/194395.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/M729D9UB/Bolton - 2021 - The Intersection of Function-as-a-Service and Stre.pdf:application/pdf}
}
@online{noauthor_journey_nodate,
	title        = {Journey to Event Driven – Part 3: The Affinity Between Events, Streams and Serverless},
	shorttitle   = {Journey to Event Driven – Part 3},
	url          = {https://www.confluent.io/blog/journey-to-event-driven-part-3-affinity-between-events-streams-serverless},
	urldate      = {2021-12-01},
	abstract     = {The synergy of {FaaS} and the event streaming platform is a natural fit when we think about domain modeling and organizational needs as they change over time. Whether it's business processes, data models, technology, cloud or just the organization itself, evolution is inevitable and needs to be embraced.},
	titleaddon   = {Confluent},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/L67ZKBFH/journey-to-event-driven-part-3-affinity-between-events-streams-serverless.html:text/html}
}
@inproceedings{shen_defuse_2021,
	title        = {Defuse: A Dependency-Guided Function Scheduler to Mitigate Cold Starts on {FaaS} Platforms},
	shorttitle   = {Defuse},
	author       = {Shen, Jiacheng and Yang, Tianyi and Su, Yuxin and Zhou, Yangfan and Lyu, Michael R.},
	booktitle    = {2021 {IEEE} 41st International Conference on Distributed Computing Systems ({ICDCS})},
	pages        = {194--204},
	doi          = {10.1109/ICDCS51616.2021.00027},
	note         = {{ISSN}: 2575-8411},
	abstract     = {Function-as-a-Service ({FaaS}) is becoming a prevalent paradigm in developing cloud applications. With {FaaS}, clients can develop applications as serverless functions, leaving the burden of resource management to cloud providers. However, {FaaS} platforms suffer from the performance degradation caused by the cold starts of serverless functions. Cold starts happen when serverless functions are invoked before they have been loaded into the memory. The problem is unavoidable because the memory in datacenters is typically too limited to hold all serverless functions simultaneously. The latency of cold function invocations will greatly degenerate the performance of {FaaS} platforms. Currently, {FaaS} platforms employ various scheduling methods to reduce the occurrences of cold starts. However, they do not consider the ubiquitous dependencies between serverless functions. Observing the potential of using dependencies to mitigate cold starts, we propose Defuse, a Dependency-guided Function Scheduler on {FaaS} platforms. Specifically, Defuse identifies two types of dependencies between serverless functions, i.e., strong dependencies and weak ones. It uses frequent pattern mining and positive point-wise mutual information to mine such dependencies respectively from function invocation histories. In this way, Defuse constructs a function dependency graph. The connected components (i.e., dependent functions) on the graph can be scheduled to diminish the occurrences of cold starts. We evaluate the effectiveness of Defuse by applying it to an industrial serverless dataset. The experimental results show that Defuse can reduce 22\% of memory usage while having a 35\% decrease in function cold-start rates compared with the state-of-the-art method.},
	eventtitle   = {2021 {IEEE} 41st International Conference on Distributed Computing Systems ({ICDCS})},
	date         = {2021-07},
	keywords     = {Cloud Computing, Cold Start, {FAA}, {FaaS}, Job shop scheduling, Memory management, Processor scheduling, Resource management, Schedules, Serverless, Service Dependency, System improvement},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/FDWXEH7Q/9546470.html:text/html}
}
@inproceedings{karhula_checkpointing_2019,
	title        = {Checkpointing and Migration of {IoT} Edge Functions},
	author       = {Karhula, Pekka and Janak, Jan and Schulzrinne, Henning},
	booktitle    = {Proceedings of the 2nd International Workshop on Edge Systems, Analytics and Networking},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{EdgeSys} '19},
	pages        = {60--65},
	doi          = {10.1145/3301418.3313947},
	isbn         = {978-1-4503-6275-7},
	url          = {https://doi.org/10.1145/3301418.3313947},
	urldate      = {2021-11-15},
	abstract     = {The serverless and functions as a service ({FaaS}) paradigms are currently trending among cloud providers and are now increasingly being applied to the network edge, and to the Internet of Things ({IoT}) devices. The benefits include reduced latency for communication, less network traffic and increased privacy for data processing. However, there are challenges as {IoT} devices have limited resources for running multiple simultaneous containerized functions, and also {FaaS} does not typically support long-running functions. Our implementation utilizes Docker and {CRIU} for checkpointing and suspending long-running blocking functions. The results show that checkpointing is slightly slower than regular Docker pause, but it saves memory and allows for more long-running functions to be run on an {IoT} device. Furthermore, the resulting checkpoint files are small, hence they are suitable for live migration and backing up stateful functions, therefore improving availability and reliability of the system.},
	date         = {2019-03-25},
	keywords     = {serverless, Internet of Things, function as a service, checkpointing, light-weight virtualization},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/T2D8BJ6H/Karhula et al. - 2019 - Checkpointing and Migration of IoT Edge Functions.pdf:application/pdf;Checkpointing and Migration of IoT Edge Functions:/home/volodia/Zotero/storage/UQ2FL4PU/karhula2019.pdf.pdf:application/pdf}
}
@inproceedings{pinto_dynamic_2018,
	title        = {Dynamic Allocation of Serverless Functions in {IoT} Environments},
	author       = {Pinto, Duarte and Dias, Jo\~{a}o Pedro and Sereno Ferreira, Hugo},
	booktitle    = {2018 {IEEE} 16th International Conference on Embedded and Ubiquitous Computing ({EUC})},
	pages        = {1--8},
	doi          = {10.1109/EUC.2018.00008},
	abstract     = {The {IoT} area has grown significantly in the last few years and is expected to reach a gigantic amount of 50 billion devices by 2020. The appearance of serverless architectures, specifically highlighting {FaaS}, raises the question of the suitability of using them in {IoT} environments. Combining {IoT} with a serverless architectural design can effective when trying to make use of local processing power that exists in a local network of {IoT} devices and creating a fog layer that leverages computational capabilities that are closer to the end-user. In this approach, which is placed between the device and the serverless function, when a device requests for the execution of a serverless function will decide based on previous metrics of execution if the serverless function should be executed locally, in the fog layer of a local network of {IoT} devices, or if it should be executed remotely, in one of the available cloud servers. Therefore, this approach allows dynamically allocating functions to the most suitable layer.},
	eventtitle   = {2018 {IEEE} 16th International Conference on Embedded and Ubiquitous Computing ({EUC})},
	date         = {2018-10},
	keywords     = {Cloud computing, Edge computing, Fog Computing, Serverless, Internet of Things, Servers, Estimation, Market research, Multi Armed Bandit, Runtime environment, Ubiquitous Computing},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/XSALMCEF/8588841.html:text/html;Dynamic Allocation of Serverless Functions in IoT Environments:/home/volodia/Zotero/storage/RW7YUBWS/pinto2018.pdf.pdf:application/pdf}
}
@inproceedings{cheng_fog_2019,
	title        = {Fog Function: Serverless Fog Computing for Data Intensive {IoT} Services},
	shorttitle   = {Fog Function},
	author       = {Cheng, Bin and Fuerst, Jonathan and Solmaz, Gurkan and Sanada, Takuya},
	booktitle    = {2019 {IEEE} International Conference on Services Computing ({SCC})},
	pages        = {28--35},
	doi          = {10.1109/SCC.2019.00018},
	url          = {http://arxiv.org/abs/1907.08278},
	urldate      = {2022-02-09},
	note         = {{ISSN}: 2474-2473},
	abstract     = {Fog computing can support {IoT} services with fast response time and low bandwidth usage by moving computation from the cloud to edge devices. However, existing fog computing frameworks have limited flexibility to support dynamic service composition with a data-oriented approach. Function-as-a-Service ({FaaS}) is a promising programming model for fog computing to enhance flexibility, but the current event-or topic-based design of function triggering and the separation of data management and function execution result in inefficiency for data-intensive {IoT} services. To achieve both flexibility and efficiency, we propose a data-centric programming model called Fog Function and also introduce its underlying orchestration mechanism that leverages three types of contexts: data context, system context, and usage context. Moreover, we showcase a concrete use case for smart parking where Fog Function allows service developers to easily model their service logic with reduced learning efforts compared to a static service topology. Our performance evaluation results show that the Fog Function can be scaled to hundreds of fog nodes. Fog Function can improve system efficiency by saving 95\% of the internal data traffic over cloud function and it can reduce service latency by 30\% over edge function.},
	eventtitle   = {2019 {IEEE} International Conference on Services Computing ({SCC})},
	date         = {2019-07},
	keywords     = {fog computing, serverless computing, edge computing, context driven, {IoT} services, programming model},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/BBNBUBAH/8814084.html:text/html;Fog Function\: Serverless Fog Computing for Data Intensive IoT Services:/home/volodia/Zotero/storage/34BHDU36/10.1109\@SCC.2019.00018.pdf.pdf:application/pdf},
	journaltitle = {{arXiv}:1907.08278 [cs]},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {1907.08278}
}
@inproceedings{shahrad_architectural_2019,
	title        = {Architectural Implications of Function-as-a-Service Computing},
	author       = {Shahrad, Mohammad and Balkind, Jonathan and Wentzlaff, David},
	booktitle    = {Proceedings of the 52nd Annual {IEEE}/{ACM} International Symposium on Microarchitecture},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{MICRO} '52},
	pages        = {1063--1075},
	doi          = {10.1145/3352460.3358296},
	isbn         = {978-1-4503-6938-1},
	url          = {https://doi.org/10.1145/3352460.3358296},
	urldate      = {2021-12-01},
	abstract     = {Serverless computing is a rapidly growing cloud application model, popularized by Amazon's Lambda platform. Serverless cloud services provide fine-grained provisioning of resources, which scale automatically with user demand. Function-as-a-Service ({FaaS}) applications follow this serverless model, with the developer providing their application as a set of functions which are executed in response to a user- or system-generated event. Functions are designed to be short-lived and execute inside containers or virtual machines, introducing a range of system-level overheads. This paper studies the architectural implications of this emerging paradigm. Using the commercial-grade Apache {OpenWhisk} {FaaS} platform on real servers, this work investigates and identifies the architectural implications of {FaaS} serverless computing. The workloads, along with the way that {FaaS} inherently interleaves short functions from many tenants frustrates many of the locality-preserving architectural structures common in modern processors. In particular, we find that: {FaaS} containerization brings up to 20x slowdown compared to native execution, cold-start can be over 10x a short function's execution time, branch mispredictions per kilo-instruction are 20x higher for short functions, memory bandwidth increases by 6x due to the invocation pattern, and {IPC} decreases by as much as 35\% due to inter-function interference. We open-source {FaaSProfiler}, the {FaaS} testing and profiling platform that we developed for this work.},
	date         = {2019-10-12},
	keywords     = {architecture, cloud, faas, function-as-a-service, {OpenWhisk}, serverless},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/VIRJR23V/Shahrad et al. - 2019 - Architectural Implications of Function-as-a-Servic.pdf:application/pdf;Architectural Implications of Function-as-a-Service Computing:/home/volodia/Zotero/storage/4BXZ83YP/shahrad2019.pdf.pdf:application/pdf}
}
@online{qiu_is_2021,
	title        = {Is Function-as-a-Service a Good Fit for Latency-Critical Services?},
	author       = {Qiu, Haoran},
	url          = {https://haoran-qiu.com/publication/wosc-2021/},
	urldate      = {2021-12-01},
	abstract     = {Function-as-a-Service ({FaaS}) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher server utilization, often at the cost of higher end-toend function request latency. Interestingly, a key aspect of serverless latency management has not been well studied: the trade-off between application developers' latency goals and the {FaaS} providers' utilization goals. This paper presents a multi-faceted, measurement-driven study of latency variation in serverless platforms that elucidates this trade-off space. We obtained production measurements by executing {FaaS} benchmarks on {IBM} Cloud and a private cloud to study the impact of workload consolidation, queuing delay, and cold starts on the end-to-end function request latency. We draw several conclusions. For example, increasing a container's allocated memory limit from 128 {MB} to 256 {MB} reduces the tail latency by 2x but has 1.75x higher power consumption and 59\% lower {CPU} utilization.},
	titleaddon   = {Haoran Qiu \@Illinois {CS}},
	date         = {2021-11-19},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/NHQU52LE/wosc-2021.html:text/html}
}
@inproceedings{kaffes_centralized_2019,
	title        = {Centralized Core-granular Scheduling for Serverless Functions},
	author       = {Kaffes, Kostis and Yadwadkar, Neeraja J. and Kozyrakis, Christos},
	booktitle    = {Proceedings of the {ACM} Symposium on Cloud Computing},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{SoCC} '19},
	pages        = {158--164},
	doi          = {10.1145/3357223.3362709},
	isbn         = {978-1-4503-6973-2},
	url          = {https://doi.org/10.1145/3357223.3362709},
	urldate      = {2021-12-01},
	abstract     = {In recent years, many applications have started using serverless computing platforms primarily due to the ease of deployment and cost efficiency they offer. However, the existing scheduling mechanisms of serverless platforms fall short in catering to the unique characteristics of such applications: burstiness, short and variable execution times, statelessness and use of a single core. Specifically, the existing mechanisms fall short in meeting the requirements generated due to the combined effect of these characteristics: scheduling at a scale of millions of function invocations per second while achieving predictable performance. In this paper, we argue for a cluster-level centralized and core-granular scheduler for serverless functions. By maintaining a global view of the cluster resources, the centralized approach eliminates queue imbalances while the core granularity reduces interference; together these properties enable reduced performance variability. We expect such a scheduler to increase the adoption of serverless computing platforms by various latency and throughput sensitive applications.},
	date         = {2019-11-20},
	keywords     = {cloud computing, resource allocation, scheduling, serverless computing},
	file         = {Centralized Core-granular Scheduling for Serverless Functions:/home/volodia/Zotero/storage/B8RPESQN/kaffes2019.pdf.pdf:application/pdf}
}
@inproceedings{palade_swarm-based_2020,
	title        = {A Swarm-based Approach for Function Placement in Federated Edges},
	author       = {Palade, Andrei and Mukhopadhyay, Atri and Kazmi, Aqeel and Cabrera, Christian and Nomayo, Evelyn and Iosifidis, Georgios and Ruffini, Marco and Clarke, Siobh\'{a}n},
	booktitle    = {2020 {IEEE} International Conference on Services Computing ({SCC})},
	pages        = {48--50},
	doi          = {10.1109/SCC49832.2020.00013},
	note         = {{ISSN}: 2474-2473},
	abstract     = {Multi-access Edge Computing ({MEC}) provides cloud computing capabilities at the edge by offloading users' service requests on {MEC} servers deployed at Base Stations ({BS}). Optimising the resource allocation on such distributed units in a physical area such as a city, especially for compute-intensive and latency-critical services, is a key challenge. We propose a swarm-based approach for placing functions in the edge using a serverless architecture, which does not require services to pre-occupy the required computing resources. The approach uses a probabilistic model to decide where to place the functions while considering the resources available at each {MEC} server and the latency between the physical servers and the application requester. A central controller with a federated view of available {MEC} servers orchestrates functions' deployment and deals changes available resources. We compare our approach against the Best-Fit, Max-Fit, {MultiOpt}, {ILP} and Random baselines. Results show that our approach can reduce the latency of applications with limited effect on the resource utilisation.},
	eventtitle   = {2020 {IEEE} International Conference on Services Computing ({SCC})},
	date         = {2020-11},
	keywords     = {Edge computing, Edge Computing, Resource management, Serverless, Servers, Conferences, Probabilistic logic, Service computing, Service Placement, Urban areas},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/PSZSEFH6/9284644.html:text/html;A Swarm-based Approach for Function Placement in Federated Edges:/home/volodia/Zotero/storage/PXMX7SRX/palade2020.pdf.pdf:application/pdf}
}
@inproceedings{george_nanolambda_2020,
	title        = {{NanoLambda}: Implementing Functions as a Service at All Resource Scales for the Internet of Things.},
	shorttitle   = {{NanoLambda}},
	author       = {George, Gareth and Bakir, Fatih and Wolski, Rich and Krintz, Chandra},
	booktitle    = {2020 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	location     = {San Jose, {CA}, {USA}},
	publisher    = {{IEEE}},
	pages        = {220--231},
	doi          = {10.1109/SEC50012.2020.00035},
	isbn         = {978-1-72815-943-0},
	url          = {https://ieeexplore.ieee.org/document/9355717/},
	urldate      = {2021-11-15},
	abstract     = {Internet of Things ({IoT}) devices are becoming increasingly prevalent in our environment, yet the process of programming these devices and processing the data they produce remains difficult. Typically, data is processed on device, involving arduous work in low level languages, or data is moved to the cloud, where abundant resources are available for Functions as a Service ({FaaS}) or other handlers. {FaaS} is an emerging category of flexible computing services, where developers deploy self-contained functions to be run in portable and secure containerized environments; however, at the moment, these functions are limited to running in the cloud or in some cases at the ``edge'' of the network using resource rich, Linux-based systems.},
	eventtitle   = {2020 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	date         = {2020-11},
	langid       = {english},
	file         = {George et al. - 2020 - NanoLambda Implementing Functions as a Service at.pdf:/home/volodia/Zotero/storage/Q9T7BFNY/George et al. - 2020 - NanoLambda Implementing Functions as a Service at.pdf:application/pdf;NanoLambda\: Implementing Functions as a Service at All Resource Scales for the Internet of Things.:/home/volodia/Zotero/storage/IM7QKEP5/george2020.pdf.pdf:application/pdf}
}
@inproceedings{elgamal_costless_2018,
	title        = {Costless: Optimizing Cost of Serverless Computing through Function Fusion and Placement},
	shorttitle   = {Costless},
	author       = {Elgamal, Tarek},
	booktitle    = {2018 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	pages        = {300--312},
	doi          = {10.1109/SEC.2018.00029},
	abstract     = {Serverless computing has recently experienced significant adoption by several applications, especially Internet of Things ({IoT}) applications. In serverless computing, rather than deploying and managing dedicated virtual machines, users are able to deploy individual functions, and pay only for the time that their code is actually executing. However, since serverless platforms are relatively new, they have a completely different pricing model that depends on the memory, duration, and the number of executions of a sequence/workflow of functions. In this paper we present an algorithm that optimizes the price of serverless applications in {AWS} Lambda. We first describe the factors affecting price of serverless applications which include: (1) fusing a sequence of functions, (2) splitting functions across edge and cloud resources, and (3) allocating the memory for each function. We then present an efficient algorithm to explore different function fusion-placement solutions and find the solution that optimizes the application's price while keeping the latency under a certain threshold. Our results on image processing workflows show that the algorithm can find solutions optimizing the price by more than 35\%-57\% with only 5\%-15\% increase in latency. We also show that our algorithm can find non-trivial memory configurations that reduce both latency and price.},
	eventtitle   = {2018 {IEEE}/{ACM} Symposium on Edge Computing ({SEC})},
	date         = {2018-10},
	keywords     = {Cloud computing, Cloud Computing, Edge computing, Memory management, Serverless, Computational modeling, Internet of Things, Pricing, {AWS} Lambda, Cost Optimization, Face, Fuses},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/GN8FJLJA/8567674.html:text/html;Submitted Version:/home/volodia/Zotero/storage/3HQKGIJJ/Elgamal - 2018 - Costless Optimizing Cost of Serverless Computing .pdf:application/pdf;Costless\: Optimizing Cost of Serverless Computing through Function Fusion and Placement:/home/volodia/Zotero/storage/QWEZ4724/df7ac33bf08b28a3b6cfdd661c3b41c4.pdf.pdf:application/pdf}
}
@article{rausch_optimized_2021,
	title        = {Optimized container scheduling for data-intensive serverless edge computing},
	author       = {Rausch, Thomas and Rashed, Alexander and Dustdar, Schahram},
	volume       = 114,
	pages        = {259--271},
	doi          = {10.1016/j.future.2020.07.017},
	issn         = {0167-739X},
	url          = {https://www.sciencedirect.com/science/article/pii/S0167739X2030399X},
	urldate      = {2021-11-15},
	abstract     = {Operating data-intensive applications on edge systems is challenging, due to the extreme workload and device heterogeneity, as well as the geographic dispersion of compute and storage infrastructure. Serverless computing has emerged as a compelling model to manage the complexity of such systems, by decoupling the underlying infrastructure and scaling mechanisms from applications. Although serverless platforms have reached a high level of maturity, we have found several limiting factors that inhibit their use in an edge setting. This paper presents a container scheduling system that enables such platforms to make efficient use of edge infrastructures. Our scheduler makes heuristic trade-offs between data and computation movement, and considers workload-specific compute requirements such as {GPU} acceleration. Furthermore, we present a method to automatically fine-tune the weights of scheduling constraints to optimize high-level operational objectives such as minimizing task execution time, uplink usage, or cloud execution cost. We implement a prototype that targets the container orchestration system Kubernetes, and deploy it on an edge testbed we have built. We evaluate our system with trace-driven simulations in different infrastructure scenarios, using traces generated from running representative workloads on our testbed. Our results show that (a) our scheduler significantly improves the quality of task placement compared to the state-of-the-art scheduler of Kubernetes, and (b) our method for fine-tuning scheduling parameters helps significantly in meeting operational goals.},
	journaltitle = {Future Generation Computer Systems},
	shortjournal = {Future Generation Computer Systems},
	date         = {2021-01-01},
	langid       = {english},
	keywords     = {Edge computing, Serverless, Container scheduling, Machine learning},
	file         = {Optimized container scheduling for data-intensive serverless edge computing:/home/volodia/Zotero/storage/PUMJ9WFQ/rausch2021.pdf.pdf:application/pdf}
}
@article{das_performance_2020,
	title        = {Performance Optimization for Edge-Cloud Serverless Platforms via Dynamic Task Placement},
	author       = {Das, Anirban and Imai, Shigeru and Wittie, Mike P. and Patterson, Stacy},
	url          = {http://arxiv.org/abs/2003.01310},
	urldate      = {2021-11-15},
	abstract     = {We present a framework for performance optimization in serverless edge-cloud platforms using dynamic task placement. We focus on applications for smart edge devices, for example, smart cameras or speakers, that need to perform processing tasks on input data in real to near-real time. Our framework allows the user to specify cost and latency requirements for each application task, and for each input, it determines whether to execute the task on the edge device or in the cloud. Further, for cloud executions, the framework identifies the container resource configuration needed to satisfy the performance goals. We have evaluated our framework in simulation using measurements collected from serverless applications in {AWS} Lambda and {AWS} Greengrass. In addition, we have implemented a prototype of our framework that runs in these same platforms. In experiments with our prototype, our models can predict average end-to-end latency with less than 6\% error, and we obtain almost three orders of magnitude reduction in end-to-end latency compared to edge-only execution.},
	journaltitle = {{arXiv}:2003.01310 [cs]},
	date         = {2020-05-19},
	eprinttype   = {arxiv},
	eprint       = {2003.01310},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/FHPYSBUN/2003.html:text/html;arXiv Fulltext PDF:/home/volodia/Zotero/storage/WSDVZYVS/Das et al. - 2020 - Performance Optimization for Edge-Cloud Serverless.pdf:application/pdf}
}
@article{ascigil_resource_2021,
	title        = {Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds},
	author       = {Ascigil, Onur and Tasiopoulos, Argyrios and Phan, Truong Khoa and Sourlas, Vasilis and Psaras, Ioannis and Pavlou, George},
	pages        = {1--1},
	doi          = {10.1109/TSC.2021.3052139},
	issn         = {1939-1374},
	note         = {Conference Name: {IEEE} Transactions on Services Computing},
	abstract     = {Edge computing has emerged as a new paradigm to bring cloud applications closer to users for increased performance. Unlike back-end cloud systems which consolidate their resources in a centralized data center location with virtually unlimited capacity, edge-clouds comprise distributed resources at various computation spots, each with very limited capacity. In this paper, we consider Function-as-a-Service ({FaaS}) edge-clouds where application providers deploy their latency-critical functions that process user requests with strict response time deadlines. In this setting, we investigate the problem of resource provisioning and allocation. After formulating the optimal solution, we propose resource allocation and provisioning algorithms across the spectrum of fully-centralized to fully-decentralized. We evaluate the performance of these algorithms in terms of their ability to utilize {CPU} resources and meet request deadlines under various system parameters. Our results indicate that practical decentralized strategies, which require no coordination among computation spots, achieve performance that is close to the optimal fully-centralized strategy with coordination overheads.},
	journaltitle = {{IEEE} Transactions on Services Computing},
	date         = 2021,
	keywords     = {Cloud computing, {FAA}, Resource management, Delays, Containers, Image edge detection, Routing},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/T4AJWKZN/9326369.html:text/html;Full Text:/home/volodia/Zotero/storage/TAGMTENM/Ascigil et al. - 2021 - Resource Provisioning and Allocation in Function-a.pdf:application/pdf;Resource Provisioning and Allocation in Function-as-a-Service Edge-Clouds:/home/volodia/Zotero/storage/TAKJQFRV/ascigil2021.pdf.pdf:application/pdf}
}
@article{wang_lass_2021,
	title        = {{LaSS}: Running Latency Sensitive Serverless Computations at the Edge},
	shorttitle   = {{LaSS}},
	author       = {Wang, Bin and Ali-Eldin, Ahmed and Shenoy, Prashant},
	pages        = {239--251},
	doi          = {10.1145/3431379.3460646},
	url          = {http://arxiv.org/abs/2104.14087},
	urldate      = {2021-11-15},
	abstract     = {Serverless computing has emerged as a new paradigm for running short-lived computations in the cloud. Due to its ability to handle {IoT} workloads, there has been considerable interest in running serverless functions at the edge. However, the constrained nature of the edge and the latency sensitive nature of workloads result in many challenges for serverless platforms. In this paper, we present {LaSS}, a platform that uses model-driven approaches for running latency-sensitive serverless computations on edge resources. {LaSS} uses principled queuing-based methods to determine an appropriate allocation for each hosted function and auto-scales the allocated resources in response to workload dynamics. {LaSS} uses a fair-share allocation approach to guarantee a minimum of allocated resources to each function in the presence of overload. In addition, it utilizes resource reclamation methods based on container deflation and termination to reassign resources from over-provisioned functions to under-provisioned ones. We implement a prototype of our approach on an {OpenWhisk} serverless edge cluster and conduct a detailed experimental evaluation. Our results show that {LaSS} can accurately predict the resources needed for serverless functions in the presence of highly dynamic workloads, and reprovision container capacity within hundreds of milliseconds while maintaining fair share allocation guarantees.},
	journaltitle = {Proceedings of the 30th International Symposium on High-Performance Parallel and Distributed Computing},
	date         = {2021-06-21},
	eprinttype   = {arxiv},
	eprint       = {2104.14087},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/EX2NPTFI/2104.html:text/html;arXiv Fulltext PDF:/home/volodia/Zotero/storage/3F9W2HWB/Wang et al. - 2021 - LaSS Running Latency Sensitive Serverless Computa.pdf:application/pdf;LaSS\: Running Latency Sensitive Serverless Computations at the Edge:/home/volodia/Zotero/storage/2I46FE3Q/wang2020.pdf.pdf:application/pdf}
}
@article{puliafito_stateful_2021,
	title        = {Stateful Function-as-a-Service at the Edge},
	author       = {Puliafito, Carlo and Cicconetti, Claudio and Conti, Marco and Mingozzi, Enzo and Passarella, Andrea},
	url          = {http://arxiv.org/abs/2109.15040},
	urldate      = {2021-12-01},
	abstract     = {In {FaaS}, users invoke remote functions, which encapsulate service(s). These functions typically need to remotely access a persistent state via external services: this makes the paradigm less attractive in edge systems, especially for {IoT} applications, due to the increased delay and outbound traffic. We propose to generalize the {FaaS} paradigm by allowing functions to alternate between remote-state and local-state phases, depending on internal and external conditions, and dedicating a container with persistent memory to functions when in a local-state phase. We present initial results showing that this simple yet powerful pattern allows to better utilize the available resources, which are scarce on edge nodes, while significantly reducing tail latencies, which is key to enable many new applications based on real-time {ML}, e.g., in smart vehicles and smart factory scenarios},
	journaltitle = {{arXiv}:2109.15040 [cs]},
	date         = {2021-09-30},
	eprinttype   = {arxiv},
	eprint       = {2109.15040},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/2JFJXVYC/2109.html:text/html;arXiv Fulltext PDF:/home/volodia/Zotero/storage/MCBLNV7M/Puliafito et al. - 2021 - Stateful Function-as-a-Service at the Edge.pdf:application/pdf},
	langid       = {english}
}
@inproceedings{pfandzelter_tinyfaas_2020,
	title        = {{tinyFaaS}: A Lightweight {FaaS} Platform for Edge Environments},
	shorttitle   = {{tinyFaaS}},
	author       = {Pfandzelter, Tobias and Bermbach, David},
	booktitle    = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	pages        = {17--24},
	doi          = {10.1109/ICFC49376.2020.00011},
	abstract     = {The Function-as-a-Service ({FaaS}) model is a great fit for data and event processing in the Internet of Things ({IoT}). Sending all data to a cloud-based {FaaS} platform, however, may cause performance and privacy issues. While these issues could be mitigated using edge computing, existing {FaaS} approaches, designed for the cloud, are too heavyweight to run on small, constrained edge nodes. In this paper, we propose {tinyFaaS}, a new {FaaS} system that is specifically designed for edge environments and their unique challenges. Our platform is lightweight enough to run on low-performance single machine edge nodes, provides a {CoAP} endpoint to support communication with low-power devices, and uses Docker containers to isolate tenants. We evaluate {tinyFaaS} through a proof-of-concept implementation that we benchmark and compare to state-of-the-art {FaaS} platforms. For {IoT} processing scenarios, we find that {tinyFaaS} outperforms existing systems by at least an order of magnitude.},
	eventtitle   = {2020 {IEEE} International Conference on Fog Computing ({ICFC})},
	date         = {2020-04},
	keywords     = {Cloud computing, Edge computing, Edge Computing, {IoT}, {FAA}, {FaaS}, Serverless, Servers, Runtime, Containers, Protocols},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/FF4IUIKL/9103476.html:text/html;tinyFaaS\: A Lightweight FaaS Platform for Edge Environments:/home/volodia/Zotero/storage/QNQPJXS2/pfandzelter2020.pdf.pdf:application/pdf}
}
@online{breitgand_lean_2018,
	title        = {Lean {OpenWhisk}: Open Source {FaaS} for Edge Computing},
	shorttitle   = {Lean {OpenWhisk}},
	author       = {Breitgand, David},
	url          = {https://medium.com/openwhisk/lean-openwhisk-open-source-faas-for-edge-computing-fb823c6bbb9b},
	urldate      = {2021-11-15},
	abstract     = {This Blog is co-authored with Pavel Kravchenko as part of our work at {IBM} Research -- Haifa\textasteriskcentered.},
	titleaddon   = {Apache {OpenWhisk}},
	date         = {2018-07-25},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/893I5YG7/lean-openwhisk-open-source-faas-for-edge-computing-fb823c6bbb9b.html:text/html}
}
@software{noauthor_previous_2021,
	title        = {Previous Serverless Version 0.5.x},
	publisher    = {Serverless},
	url          = {https://github.com/serverless/serverless},
	urldate      = {2021-11-15},
	note         = {original-date: 2015-04-21T03:48:40Z},
	rights       = {{MIT}},
	abstract     = {⚡ Serverless Framework – Build web, mobile and {IoT} applications with serverless architectures using {AWS} Lambda, Azure Functions, Google {CloudFunctions} \& more! –},
	date         = {2021-11-15},
	keywords     = {serverless, aws, aws-dynamodb, aws-lambda, azure-functions, google-cloud-functions, microservice, serverless-architectures, serverless-framework}
}
@software{noauthor_firecracker-microvmfirecracker_2021,
	title        = {firecracker-microvm/firecracker},
	publisher    = {firecracker-microvm},
	url          = {https://github.com/firecracker-microvm/firecracker},
	urldate      = {2021-11-15},
	note         = {original-date: 2017-10-19T06:18:47Z},
	rights       = {Apache-2.0},
	abstract     = {Secure and fast {microVMs} for serverless computing.},
	date         = {2021-11-15},
	keywords     = {serverless, containers, minimalist, open-source, oversubscription, rust, sandbox, virtual-machine, virtualization}
}
@software{noauthor_slackhqnebula_2021,
	title        = {slackhq/nebula},
	publisher    = {Slack},
	url          = {https://github.com/slackhq/nebula},
	urldate      = {2021-11-15},
	note         = {original-date: 2019-11-16T23:26:23Z},
	rights       = {{MIT}},
	abstract     = {A scalable overlay networking tool with a focus on performance, simplicity and security},
	date         = {2021-11-15}
}
@article{lee_trustful_2020,
	title        = {Trustful Resource Management for Service Allocation in Fog-Enabled Intelligent Transportation Systems},
	author       = {Lee, Yunseong and Jeong, Seohyeon and Masood, Arooj and Park, Laihyuk and Dao, Nhu-Ngoc and Cho, Sungrae},
	volume       = 8,
	pages        = {147313--147322},
	doi          = {10.1109/ACCESS.2020.3015550},
	issn         = {2169-3536},
	note         = {Conference Name: {IEEE} Access},
	abstract     = {A fog-enabled intelligent transportation system is constructed using Vehicle-to-Everything (V2X) communications towards the Internet of Vehicles ({IoV}). In this system, the road side unit ({RSU}) and vehicle correspond to the fog server and fog device, respectively. In practice, the {RSU} offers instant infotainment services (e.g., video streaming and traffic assistance) to vehicles. However, the vehicles are considered untrustworthy and could possibly be exploited to attack the system, thereby compromising the service stability and data integrity. To address this problem, this article proposes truthful service allocation using a Vickrey-Clarke-Groves ({VCG}) auction mechanism. The {RSU} leads the proposed auction as a seller who sells their computing resources, and the vehicles participate as buyers who purchase these computing resources for the offered services. Consequently, the {RSU} generates a transaction whenever a service allocation is assigned. To secure the service transactions, we utilize a distributed blockchain system that implements Hyperledger Fabric framework among {RSUs} for transaction verification. The simulation results demonstrate that the proposed system provides service stability while ensuring service trustfulness.},
	journaltitle = {{IEEE} Access},
	date         = 2020,
	keywords     = {Cloud computing, Computer architecture, Edge computing, Resource management, fog computing, Data centers, Servers, Blockchain, Internet of Vehicles ({IoV}), {VCG}-auction},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/ARYFYZBH/9163371.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/Y3NATAWP/Lee et al. - 2020 - Trustful Resource Management for Service Allocatio.pdf:application/pdf;Trustful Resource Management for Service Allocation in Fog-Enabled Intelligent Transportation Systems:/home/volodia/Zotero/storage/XJZCQBJ2/lee2020.pdf.pdf:application/pdf}
}
@article{kjorveziroski_iot_2021,
	title        = {{IoT} Serverless Computing at the Edge: A Systematic Mapping Review},
	shorttitle   = {{IoT} Serverless Computing at the Edge},
	author       = {Kjorveziroski, Vojdan and Filiposka, Sonja and Trajkovik, Vladimir},
	volume       = 10,
	number       = 10,
	pages        = 130,
	doi          = {10.3390/computers10100130},
	url          = {https://www.mdpi.com/2073-431X/10/10/130},
	urldate      = {2021-11-30},
	note         = {Number: 10 Publisher: Multidisciplinary Digital Publishing Institute},
	rights       = {http://creativecommons.org/licenses/by/3.0/},
	abstract     = {Serverless computing is a new concept allowing developers to focus on the core functionality of their code, while abstracting away the underlying infrastructure. Even though there are existing commercial serverless cloud providers and open-source solutions, dealing with the explosive growth of new Internet of Things ({IoT}) devices requires more efficient bandwidth utilization, reduced latency, and data preprocessing closer to the source, thus reducing the overall data volume and meeting privacy regulations. Moving serverless computing to the edge of the network is a topic that is actively being researched with the aim of solving these issues. This study presents a systematic mapping review of current progress made to this effect, analyzing work published between 1 January 2015 and 1 September 2021. Using a document selection methodology which emphasizes the quality of the papers obtained through querying several popular databases with relevant search terms, we have included 64 entries, which we then further categorized into eight main categories. Results show that there is an increasing interest in this area with rapid progress being made to solve the remaining open issues, which have also been summarized in this paper. Special attention is paid to open-source efforts, as well as open-access contributions.},
	journaltitle = {Computers},
	date         = {2021-10},
	langid       = {english},
	keywords     = {serverless computing, Internet of Things, edge computing, function as a service, systematic review},
	file         = {Snapshot:/home/volodia/Zotero/storage/BPMH6S7U/130.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/HCK9EVGW/Kjorveziroski et al. - 2021 - IoT Serverless Computing at the Edge A Systematic.pdf:application/pdf}
}
@article{hassan_survey_2021,
	title        = {Survey on serverless computing},
	author       = {Hassan, Hassan B. and Barakat, Saman A. and Sarhan, Qusay I.},
	volume       = 10,
	number       = 1,
	pages        = 39,
	doi          = {10.1186/s13677-021-00253-7},
	issn         = {2192-113X},
	url          = {https://doi.org/10.1186/s13677-021-00253-7},
	urldate      = {2021-11-29},
	abstract     = {Serverless computing has gained importance over the last decade as an exciting new field, owing to its large influence in reducing costs, decreasing latency, improving scalability, and eliminating server-side management, to name a few. However, to date there is a lack of in-depth survey that would help developers and researchers better understand the significance of serverless computing in different contexts. Thus, it is essential to present research evidence that has been published in this area. In this systematic survey, 275 research papers that examined serverless computing from well-known literature databases were extensively reviewed to extract useful data. Then, the obtained data were analyzed to answer several research questions regarding state-of-the-art contributions of serverless computing, its concepts, its platforms, its usage, etc. We moreover discuss the challenges that serverless computing faces nowadays and how future research could enable its implementation and usage.},
	journaltitle = {Journal of Cloud Computing},
	shortjournal = {Journal of Cloud Computing},
	date         = {2021-07-12},
	keywords     = {Cloud computing, Serverless benefits, Serverless challenges, Serverless computing, Serverless platforms, Survey},
	file         = {Snapshot:/home/volodia/Zotero/storage/6AD7D2WK/s13677-021-00253-7.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/VDEYH4WR/Hassan et al. - 2021 - Survey on serverless computing.pdf:application/pdf}
}
@online{noauthor_fission_nodate,
	title        = {Fission},
	url          = {https://fission.io/},
	urldate      = {2021-11-16},
	abstract     = {Fast Opensource Kubernetes Serverless Framework},
	titleaddon   = {Fission},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/GKUW3EA5/fission.io.html:text/html}
}
@inproceedings{glikson_deviceless_2017,
	title        = {Deviceless edge computing: extending serverless computing to the edge of the network},
	shorttitle   = {Deviceless edge computing},
	author       = {Glikson, Alex and Nastic, Stefan and Dustdar, Schahram},
	booktitle    = {Proceedings of the 10th {ACM} International Systems and Storage Conference},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{SYSTOR} '17},
	pages        = 1,
	doi          = {10.1145/3078468.3078497},
	isbn         = {978-1-4503-5035-8},
	url          = {https://doi.org/10.1145/3078468.3078497},
	urldate      = {2021-11-16},
	abstract     = {The serverless paradigm has been rapidly adopted by developers of cloud-native applications, mainly because it relieves them from the burden of provisioning, scaling and operating the underlying infrastructure. In this paper, we propose a novel computing paradigm - Deviceless Edge Computing that extends the serverless paradigm to the edge of the network, enabling {IoT} and Edge devices to be seamlessly integrated as application execution infrastructure. We also discuss open challenges to realize Deviceless Edge Computing, based on our experience in prototyping a deviceless platform.},
	date         = {2017-05-22},
	keywords     = {serverless computing, edge computing, function as a service},
	file         = {Deviceless edge computing\: extending serverless computing to the edge of the network:/home/volodia/Zotero/storage/DE3VI26G/5051b39f2a586bb6fd303a6cf790c456.pdf.pdf:application/pdf}
}
@online{noauthor_openzipkin_nodate,
	title        = {{OpenZipkin} \cdot{} A distributed tracing system},
	url          = {https://zipkin.io/},
	urldate      = {2021-11-16},
	file         = {OpenZipkin \cdot{} A distributed tracing system:/home/volodia/Zotero/storage/WNX6SPUS/zipkin.io.html:text/html}
}
@article{cicconetti_decentralized_2021,
	title        = {A Decentralized Framework for Serverless Edge Computing in the Internet of Things},
	author       = {Cicconetti, Claudio and Conti, Marco and Passarella, Andrea},
	volume       = 18,
	number       = 2,
	pages        = {2166--2180},
	doi          = {10.1109/TNSM.2020.3023305},
	issn         = {1932-4537},
	note         = {Conference Name: {IEEE} Transactions on Network and Service Management},
	abstract     = {Serverless computing is becoming widely adopted among cloud providers, thus making increasingly popular the Function-as-a-Service ({FaaS}) programming model, where the developers realize services by packaging sequences of stateless function calls. The current technologies are very well suited to data centers, but cannot provide equally good performance in decentralized environments, such as edge computing systems, which are expected to be typical for Internet of Things ({IoT}) applications. In this article, we fill this gap by proposing a framework for efficient dispatching of stateless tasks to in-network executors so as to minimize the response times while exhibiting short- and long-term fairness, also leveraging information from a virtualized network infrastructure when available. Our solution is shown to be simple enough to be installed on devices with limited computational capabilities, such as {IoT} gateways, especially when using a hierarchical forwarding extension. We evaluate the proposed platform by means of extensive emulation experiments with a prototype implementation in realistic conditions. The results show that it is able to smoothly adapt to the mobility of clients and to the variations of their service request patterns, while coping promptly with network congestion.},
	journaltitle = {{IEEE} Transactions on Network and Service Management},
	date         = {2021-06},
	keywords     = {Computer architecture, Edge computing, Computational modeling, computer simulation experiments, Data centers, Internet of Things, Internet of Things services, overlay networks, Peer-to-peer computing, software-defined networking, Task analysis},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/Z3A6JS3P/9193994.html:text/html;Submitted Version:/home/volodia/Zotero/storage/9GPZR6ND/Cicconetti et al. - 2021 - A Decentralized Framework for Serverless Edge Comp.pdf:application/pdf;A Decentralized Framework for Serverless Edge Computing in the Internet of Things:/home/volodia/Zotero/storage/BYBFK4JS/10.1109\@TNSM.2020.3023305.pdf.pdf:application/pdf}
}
@article{mutichiro_qos-based_2021,
	title        = {{QoS}-Based Service-Time Scheduling in the {IoT}-Edge Cloud},
	author       = {Mutichiro, Briytone and Tran, Minh-Ngoc and Kim, Young-Han},
	volume       = 21,
	number       = 17,
	pages        = 5797,
	doi          = {10.3390/s21175797},
	url          = {https://www.mdpi.com/1424-8220/21/17/5797},
	urldate      = {2021-12-01},
	note         = {Number: 17 Publisher: Multidisciplinary Digital Publishing Institute},
	rights       = {http://creativecommons.org/licenses/by/3.0/},
	abstract     = {In edge computing, scheduling heterogeneous workloads with diverse resource requirements is challenging. Besides limited resources, the servers may be overwhelmed with computational tasks, resulting in lengthy task queues and congestion occasioned by unusual network traffic patterns. Additionally, Internet of Things ({IoT})/Edge applications have different characteristics coupled with performance requirements, which become determinants if most edge applications can both satisfy deadlines and each user's {QoS} requirements. This study aims to address these restrictions by proposing a mechanism that improves the cluster resource utilization and Quality of Service ({QoS}) in an edge cloud cluster in terms of service time. Containerization can provide a way to improve the performance of the {IoT}-Edge cloud by factoring in task dependencies and heterogeneous application resource demands. In this paper, we propose {STaSA}, a service time aware scheduler for the edge environment. The algorithm automatically assigns requests onto different processing nodes and then schedules their execution under real-time constraints, thus minimizing the number of {QoS} violations. The effectiveness of our scheduling model is demonstrated through implementation on {KubeEdge}, a container orchestration platform based on Kubernetes. Experimental results show significantly fewer violations in {QoS} during scheduling and improved performance compared to the state of the art.},
	journaltitle = {Sensors},
	date         = {2021-01},
	langid       = {english},
	keywords     = {ant colony optimization ({ACO}), {IoT}-edge cloud, quality of service ({QoS}), resource scheduling},
	file         = {Snapshot:/home/volodia/Zotero/storage/6RA2U3HV/5797.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/4E8YEA8N/Mutichiro et al. - 2021 - QoS-Based Service-Time Scheduling in the IoT-Edge .pdf:application/pdf}
}
@article{xie_when_2021,
	title        = {When Serverless Computing Meets Edge Computing: Architecture, Challenges, and Open Issues},
	shorttitle   = {When Serverless Computing Meets Edge Computing},
	author       = {Xie, Renchao and Tang, Qinqin and Qiao, Shi and Zhu, Han and Yu, F. Richard and Huang, Tao},
	volume       = 28,
	number       = 5,
	pages        = {126--133},
	doi          = {10.1109/MWC.001.2000466},
	issn         = {1558-0687},
	note         = {Conference Name: {IEEE} Wireless Communications},
	abstract     = {Edge computing enables applications to leverage computing resources near the data source to perform data processing, which can effectively cope with the explosive growth of network data. However, along with the benefits come great challenges: application developers need to explicitly manage their resources and handle the burden of scalability and load balancing; users have to pay based on the allocated resources, not the resources actually consumed; and so forth. Serverless edge computing extends the idea of serverless computing and has emerged as a compelling model for dealing with many of the challenges associated with edge infrastructure. Different from the existing works which mainly focus on the basic architectures, platforms, and optimization models, this article aims to provide a systematic and comprehensive overview of server-less edge computing networks from the perspective of networking. We first propose the network architecture and layered structure of serverless edge computing networks. Then, the communication process, as well as the implementation and deployment, is presented. Next, the promising technical challenges, including service deployment and lifecycle management, resource awareness and service discovery, service scheduling, and so on, are discussed. Finally, some potential areas for future research are highlighted.},
	journaltitle = {{IEEE} Wireless Communications},
	date         = {2021-10},
	keywords     = {Cloud computing, Computer architecture, Edge computing, Processor scheduling, Resource management, Reliability engineering, Servers},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/PZ9JL9W2/9474932.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/NZGGBWSP/Xie et al. - 2021 - When Serverless Computing Meets Edge Computing Ar.pdf:application/pdf}
}
@inproceedings{elgamal_droplet_2018,
	title        = {{DROPLET}: Distributed Operator Placement for {IoT} Applications Spanning Edge and Cloud Resources},
	shorttitle   = {{DROPLET}},
	author       = {Elgamal, Tarek and Sandur, Atul and Nguyen, Phuong and Nahrstedt, Klara and Agha, Gul},
	booktitle    = {2018 {IEEE} 11th International Conference on Cloud Computing ({CLOUD})},
	location     = {San Francisco, {CA}, {USA}},
	publisher    = {{IEEE}},
	pages        = {1--8},
	doi          = {10.1109/CLOUD.2018.00008},
	isbn         = {978-1-5386-7235-8},
	url          = {https://ieeexplore.ieee.org/document/8457776/},
	urldate      = {2021-11-29},
	eventtitle   = {2018 {IEEE} 11th International Conference on Cloud Computing ({CLOUD})},
	date         = {2018-07},
	file         = {DROPLET\: Distributed Operator Placement for IoT Applications Spanning Edge and Cloud Resources:/home/volodia/Zotero/storage/NLT6JI48/1fed32f79e64180a31f4836fca21058c.pdf.pdf:application/pdf}
}
@inproceedings{hall_execution_2019,
	title        = {An execution model for serverless functions at the edge},
	author       = {Hall, Adam and Ramachandran, Umakishore},
	booktitle    = {Proceedings of the International Conference on Internet of Things Design and Implementation},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{IoTDI} '19},
	pages        = {225--236},
	doi          = {10.1145/3302505.3310084},
	isbn         = {978-1-4503-6283-2},
	url          = {https://doi.org/10.1145/3302505.3310084},
	urldate      = {2021-11-15},
	abstract     = {Serverless computing platforms allow developers to host single-purpose applications that automatically scale with demand. In contrast to traditional long-running applications on dedicated, virtualized, or container-based platforms, serverless applications are intended to be instantiated when called, execute a single function, and shut down when finished. State-of-the-art serverless platforms achieve these goals by creating a new container instance to host a function when it is called and destroying the container when it completes. This design allows for cost and resource savings when hosting simple applications, such as those supporting {IoT} devices at the edge of the network. However, the use of containers introduces some overhead which may be unsuitable for applications requiring low-latency response or hardware platforms with limited resources, such as those served by edge computing environments. In this paper, we present a nomenclature for characterizing server-less function access patterns which allows us to derive the basic requirements of a serverless computing runtime. We then propose the use of {WebAssembly} as an alternative method for running serverless applications while meeting these requirements. Finally, we demonstrate how a {WebAssembly}-based serverless platform provides many of the same isolation and performance guarantees of container-based platforms while reducing average application start times and the resources needed to host them.},
	date         = {2019-04-15},
	keywords     = {{FaaS}, fog computing, function-as-a-service, serverless, edge computing, webassembly},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/UHCM86DR/Hall and Ramachandran - 2019 - An execution model for serverless functions at the.pdf:application/pdf;An execution model for serverless functions at the edge:/home/volodia/Zotero/storage/J7ISVEIS/hall2019.pdf.pdf:application/pdf}
}
@article{hellerstein_serverless_2018,
	title        = {Serverless Computing: One Step Forward, Two Steps Back},
	shorttitle   = {Serverless Computing},
	author       = {Hellerstein, Joseph M. and Faleiro, Jose and Gonzalez, Joseph E. and Schleier-Smith, Johann and Sreekanti, Vikram and Tumanov, Alexey and Wu, Chenggang},
	url          = {http://arxiv.org/abs/1812.03651},
	urldate      = {2021-11-15},
	abstract     = {Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.},
	journaltitle = {{arXiv}:1812.03651 [cs]},
	date         = {2018-12-10},
	eprinttype   = {arxiv},
	eprint       = {1812.03651},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Databases},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/RBF7I69Z/1812.html:text/html;arXiv Fulltext PDF:/home/volodia/Zotero/storage/WH8KXSR6/Hellerstein et al. - 2018 - Serverless Computing One Step Forward, Two Steps .pdf:application/pdf}
}
@article{shillaker_provider-friendly_2018,
	title        = {A Provider-Friendly Serverless Framework for Latency-Critical Applications},
	author       = {Shillaker, Simon},
	pages        = 4,
	abstract     = {Serverless is an important step in the evolution of cloud computing. First virtualisation enabled sharing a physical machine, then containers enabled sharing an operating system, now serverless targets sharing a runtime. Serverless platforms allow users to build distributed systems from individual functions, knowing little about the underlying infrastructure. They are free from concerns around configuration, maintenance and scalability. Meanwhile providers guarantee timely execution in a secure, isolated environment with pay-as-you-execute billing.},
	date         = 2018,
	langid       = {english},
	file         = {Shillaker - 2018 - A Provider-Friendly Serverless Framework for Laten.pdf:/home/volodia/Zotero/storage/82T9RYAV/Shillaker - 2018 - A Provider-Friendly Serverless Framework for Laten.pdf:application/pdf}
}
@inproceedings{rausch_towards_2019,
	title        = {Towards a Serverless Platform for Edge \{{AI}\}},
	author       = {Rausch, Thomas and Hummer, Waldemar and Muthusamy, Vinod and Rashed, Alexander and Dustdar, Schahram},
	url          = {https://www.usenix.org/conference/hotedge19/presentation/rausch},
	urldate      = {2021-11-15},
	eventtitle   = {2nd \{{USENIX}\} Workshop on Hot Topics in Edge Computing ({HotEdge} 19)},
	date         = 2019,
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/ME97KH37/rausch.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/7ZBDMWWM/Rausch et al. - 2019 - Towards a Serverless Platform for Edge \{AI\}.pdf:application/pdf}
}
@inproceedings{akkus_sand_2018,
	title        = {\{{SAND}\}: Towards High-Performance Serverless Computing},
	shorttitle   = {\{{SAND}\}},
	author       = {Akkus, Istemi Ekin and Chen, Ruichuan and Rimac, Ivica and Stein, Manuel and Satzke, Klaus and Beck, Andre and Aditya, Paarijaat and Hilt, Volker},
	pages        = {923--935},
	isbn         = {978-1-939133-01-4},
	url          = {https://www.usenix.org/conference/atc18/presentation/akkus},
	urldate      = {2021-11-15},
	eventtitle   = {2018 \{{USENIX}\} Annual Technical Conference (\{{USENIX}\} \{{ATC}\} 18)},
	date         = 2018,
	langid       = {english},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/NEVUPB5Y/Akkus et al. - 2018 - \{SAND\} Towards High-Performance Serverless Comput.pdf:application/pdf}
}
@online{noauthor_sand_nodate,
	title        = {{SAND}: Towards High-Performance Serverless Computing {\textbar} {USENIX}},
	url          = {https://www.usenix.org/conference/atc18/presentation/akkus},
	urldate      = {2021-11-15},
	file         = {SAND\: Towards High-Performance Serverless Computing \vert{} USENIX:/home/volodia/Zotero/storage/B3HPL4ZV/akkus.html:text/html}
}
@online{rocha_adlrocha_2020,
	title        = {\@adlrocha - Can {WASM} become the new Docker?},
	author       = {Rocha, Alfonso de la},
	url          = {https://adlrocha.substack.com/p/adlrocha-can-wasm-become-the-new},
	urldate      = {2021-11-15},
	abstract     = {{WASM} in the cloud with Krustlet},
	titleaddon   = {\@adlrocha Weekly Newsletter},
	type         = {Substack newsletter},
	date         = {2020-05-17},
	file         = {Snapshot:/home/volodia/Zotero/storage/H8NVK435/adlrocha-can-wasm-become-the-new.html:text/html}
}
@online{brown_how_2021,
	title        = {How {WASI} Makes Containerization More Efficient},
	author       = {Brown, Dan},
	url          = {https://training.linuxfoundation.org/blog/how-wasi-makes-containerization-more-efficient/},
	urldate      = {2021-11-15},
	abstract     = {By Marco Fioretti {WebAssembly}, or Wasm for brevity, is a standardized binary format that allows software written in any language to run without customizations on any platform, inside sandboxes or...},
	titleaddon   = {Linux Foundation - Training},
	date         = {2021-05-13},
	langid       = {american},
	file         = {Snapshot:/home/volodia/Zotero/storage/5JHE36E9/how-wasi-makes-containerization-more-efficient.html:text/html}
}
@software{noauthor_kubespherekubesphere_2021,
	title        = {kubesphere/kubesphere},
	publisher    = {{KubeSphere}},
	url          = {https://github.com/kubesphere/kubesphere},
	urldate      = {2021-11-24},
	note         = {original-date: 2018-04-21T02:03:04Z},
	rights       = {Apache-2.0},
	abstract     = {The container platform tailored for Kubernetes multi-cloud, datacenter, and edge management ⎈ 🖥 ☁️},
	date         = {2021-11-24},
	keywords     = {cloud-native, cncf, container-management, devops, hacktoberfest, istio, jenkins, k8s, kubernetes, kubernetes-platform-solution, kubesphere, multi-cluster, observability, servicemesh}
}
@inproceedings{barcelona-pons_faas_2019,
	title        = {On the {FaaS} Track: Building Stateful Distributed Applications with Serverless Architectures},
	shorttitle   = {On the {FaaS} Track},
	author       = {Barcelona-Pons, Daniel and S\'{a}nchez-Artigas, Marc and Par\'{\i}s, Gerard and Sutra, Pierre and L\'{o}pez, Pedro},
	pages        = {41--54},
	doi          = {10.1145/3361525.3361535},
	isbn         = {978-1-4503-7009-7},
	abstract     = {Serverless computing is an emerging paradigm that greatly simplifies the usage of cloud resources and suits well to many tasks. Most notably, Function-as-a-Service ({FaaS}) enables programmers to develop cloud applications as individual functions that can run and scale independently. Yet, due to the disaggregation of storage and compute resources in {FaaS}, applications that require fine-grained support for mutable state and synchronization, such as machine learning and scientific computing, are hard to build. In this work, we present Crucial, a system to program highly-concurrent stateful applications with serverless architectures. Its programming model keeps the simplicity of {FaaS} and allows to port effortlessly multi-threaded algorithms to this new environment. Crucial is built upon the key insight that {FaaS} resembles to concurrent programming at the scale of a data center. As a consequence, a distributed shared memory layer is the right answer to the need for fine-grained state management and coordination in serverless. We validate our system with the help of micro-benchmarks and various applications. In particular, we implement two common machine learning algorithms: k-means clustering and logistic regression. For both cases, Crucial obtains superior or comparable performance to an equivalent Spark cluster.},
	date         = {2019-12-09}
}
@inproceedings{mvondo_ofc_2021,
	title        = {{OFC}: an opportunistic caching system for {FaaS} platforms},
	shorttitle   = {{OFC}},
	author       = {Mvondo, Djob and Bacou, Mathieu and Nguetchouang, Kevin and Ngale, Lucien and Pouget, St\'{e}phane and Kouam, Josiane and Lachaize, Renaud and Hwang, Jinho and Wood, Tim and Hagimont, Daniel and De Palma, No\"{e}l and Batchakui, Bernab\'{e} and Tchana, Alain},
	booktitle    = {Proceedings of the Sixteenth European Conference on Computer Systems},
	location     = {Online Event United Kingdom},
	publisher    = {{ACM}},
	pages        = {228--244},
	doi          = {10.1145/3447786.3456239},
	isbn         = {978-1-4503-8334-9},
	url          = {https://dl.acm.org/doi/10.1145/3447786.3456239},
	urldate      = {2021-11-22},
	abstract     = {Cloud applications based on the ``Functions as a Service'' ({FaaS}) paradigm have become very popular. Yet, due to their stateless nature, they must frequently interact with an external data store, which limits their performance. To mitigate this issue, we introduce {OFC}, a transparent, vertically and horizontally elastic in-memory caching system for {FaaS} platforms, distributed over the worker nodes. {OFC} provides these benefits cost-effectively by exploiting two common sources of resource waste: (i) most cloud tenants overprovision the memory resources reserved for their functions because their footprint is non-trivially input-dependent and (ii) {FaaS} providers keep function sandboxes alive for several minutes to avoid cold starts. Using machine learning models adjusted for typical function input data categories (e.g., multimedia formats), {OFC} estimates the actual memory resources required by each function invocation and hoards the remaining capacity to feed the cache. We build our {OFC} prototype based on enhancements to the {OpenWhisk} {FaaS} platform, the Swift persistent object store, and the {RAMCloud} in-memory store. Using a diverse set of workloads, we show that {OFC} improves by up to 82 \% and 60 \% respectively the execution time of single-stage and pipelined functions.},
	eventtitle   = {{EuroSys} '21: Sixteenth European Conference on Computer Systems},
	date         = {2021-04-21},
	langid       = {english},
	file         = {Mvondo et al. - 2021 - OFC an opportunistic caching system for FaaS plat.pdf:/home/volodia/Zotero/storage/N4TA4XZ4/Mvondo et al. - 2021 - OFC an opportunistic caching system for FaaS plat.pdf:application/pdf}
}
@online{hykes_solomon_2019,
	title        = {Solomon Hykes sur Twitter},
	author       = {Hykes, Solomon},
	url          = {https://twitter.com/solomonstre/status/1111004913222324225},
	urldate      = {2021-12-06},
	abstract     = {If {WASM}+{WASI} existed in 2008, we wouldn't have needed to created Docker. That's how important it is. Webassembly on the server is the future of computing. A standardized system interface was the missing link. Let's hope {WASI} is up to the task!},
	titleaddon   = {Twitter},
	date         = 2019,
	langid       = {french}
}
@article{chaudhry_improved_2020,
	title        = {Improved {QoS} at the Edge Using Serverless Computing to Deploy Virtual Network Functions},
	author       = {Chaudhry, Saqib Rasool and Palade, Andrei and Kazmi, Aqeel and Clarke, Siobh\'{a}n},
	volume       = 7,
	number       = 10,
	pages        = {10673--10683},
	doi          = {10.1109/JIOT.2020.3011057},
	issn         = {2327-4662},
	note         = {Conference Name: {IEEE} Internet of Things Journal},
	abstract     = {Multiaccess edge computing ({MEC}) will strengthen forthcoming 5G networks by improving the Quality of Service ({QoS}), in particular, reducing latency, increasing data processing rates, and providing real-time information to develop high-value Internet-of-Things ({IoT}) services. To enable data-intensive network services and support advanced analytics, many network operators have proposed to integrate {MEC} systems with network function virtualization ({NFV}) consolidating virtual network functions ({VNFs}) and edge capabilities on a shared infrastructure. As of yet, this integration is not fully established, with various architectural issues currently open, even at standardization level. For instance, any update to {VNFs} deployed in a {MEC} system requires a time-consuming manual effort, which affects the overall infrastructure operations. To address these pitfalls, {VNFs} can be decomposed into microservices, which maintain their own states and exhibit different resource consumption requirements. This article presents an approach to integration that leverages serverless computing to merge {MEC} and {NFV} at the system level and to deploy {VNFs} on demand, by combining {MEC} functional blocks with an {NFV} orchestrator using a Kubernetes cluster. We further investigate whether the resource utilization of a {MEC} system can be improved by leveraging networked {FPGA}-enabled {MEC} servers, through an extension of the edge layer that takes advantage of available programmable hardware. We quantitatively evaluate and demonstrate the improvement of 75\% end-to-end latency, 99.96\% {VNF} execution time, 26.9\% resource utilization, and 15.8\% energy consumption in comparison with traditional baselines of cloud, edge, and serverless-edge test cases for a high-definition real-time video streaming application.},
	journaltitle = {{IEEE} Internet of Things Journal},
	date         = {2020-10},
	keywords     = {Edge computing, serverless computing, Internet of Things, Task analysis, Servers, Quality of service, Streaming media, Field programmable gate arrays, Hardware, networked {FPGA}, virtual network functions ({VNFs}) and data security}
}
@article{shi_when_2021,
	title        = {When Blockchain Meets Auction Models: A Survey, Some Applications, and Challenges},
	shorttitle   = {When Blockchain Meets Auction Models},
	author       = {Shi, Zeshun and de Laat, Cees and Grosso, Paola and Zhao, Zhiming},
	url          = {http://arxiv.org/abs/2110.12534},
	urldate      = {2021-12-06},
	abstract     = {In recent years, blockchain has gained widespread attention as an emerging technology for decentralization, transparency, and immutability in advancing online activities over public networks. As an essential market process, auctions have been well studied and applied in many business fields due to their efficiency and contributions to fair trade. Complementary features between blockchain and auction models trigger a great potential for research and innovation. On the one hand, the decentralized nature of blockchain can provide a trustworthy, secure, and cost-effective mechanism to manage the auction process; on the other hand, auction models can be utilized to design incentive and consensus protocols in blockchain architectures. These opportunities have attracted enormous research and innovation activities in both academia and industry; however, there is a lack of an in-depth review of existing solutions and achievements. In this paper, we conduct a comprehensive state-of-the-art survey of these two research topics. We review the existing solutions for integrating blockchain and auction models, with some application-oriented taxonomies generated. Additionally, we highlight some open research challenges and future directions towards integrated blockchain-auction models.},
	journaltitle = {{arXiv}:2110.12534 [cs]},
	date         = {2021-10-24},
	eprinttype   = {arxiv},
	eprint       = {2110.12534},
	keywords     = {Computer Science - Networking and Internet Architecture, Computer Science - Cryptography and Security},
	file         = {arXiv Fulltext PDF:/home/volodia/Zotero/storage/96L7BSSF/Shi et al. - 2021 - When Blockchain Meets Auction Models A Survey, So.pdf:application/pdf}
}
@article{debe_blockchain-based_2020,
	title        = {Blockchain-Based Decentralized Reverse Bidding in Fog Computing},
	author       = {Debe, Mazin and Salah, Khaled and Rehman, Muhammad Habib Ur and Svetinovic, Davor},
	volume       = 8,
	pages        = {81686--81697},
	doi          = {10.1109/ACCESS.2020.2991261},
	issn         = {2169-3536},
	note         = {Conference Name: {IEEE} Access},
	abstract     = {Fog computing systems are designed to provide localized computation, storage, and communication services in close proximity to the endpoint mobile and {IoT} devices. Fog service providers typically monetize their service usage via centralized payment mechanisms in unverifiable and non-transparent manner. Therefore, there exists a need for a trust-enabling payment mechanism whereby fog service providers should be incentivized or penalized based upon the continuous feedback from endpoint devices. We propose a decentralized reverse-bidding scheme developed using the key features of blockchain and smart contracts. We develop a solution that allows the users or devices to initiate the bidding process by making a request for services to be provided by nearby public fog nodes, and these fog nodes to make bid offers in return. The proposed scheme ensures that all fog nodes on the network can equally and fairly make offers to win the bid. The bidding process incorporates the automated payments at the end of the service. Our solution is implemented using Ethereum smart contracts. It also integrates a reputation system for fog nodes and imposes a penalty for misbehaving nodes. Our solution is fully decentralized and provides a high level of trust, transparency, and security. In the paper, we present the system architecture, implementation details, and show the correct functionality of the overall proposed solution. In addition, we provide performance, cost, and security analyses of the smart contract code to demonstrate its effectiveness and robustness against major security concerns. The results show that the cost of running the smart contract remained less than three cents with the current Ethereum price (i.e., 183.22 {USD}/Eth). We have also made our smart contract code publicly available on Github.},
	journaltitle = {{IEEE} Access},
	date         = 2020,
	keywords     = {Cloud computing, Edge computing, {IoT}, fog computing, Servers, Blockchain, Quality of service, auctioning, bidding, Ethereum, Security, smart contracts, Smart contracts},
	file         = {IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/D7RLMX3W/Debe et al. - 2020 - Blockchain-Based Decentralized Reverse Bidding in .pdf:application/pdf}
}
@inproceedings{franco_brain_2019,
	title        = {{BRAIN}: Blockchain-based Reverse Auction for Infrastructure Supply in Virtual Network Functions-as-a -Service},
	shorttitle   = {{BRAIN}},
	author       = {Franco, Muriel Figueredo and Scheid, Eder John and Granville, Lisandro Zambenedetti and Stiller, Burkhard},
	booktitle    = {2019 {IFIP} Networking Conference ({IFIP} Networking)},
	pages        = {1--9},
	doi          = {10.23919/IFIPNetworking.2019.8816843},
	note         = {{ISSN}: 1861-2288},
	abstract     = {Network Functions Virtualization ({NFV}) is transforming the way in which network operators acquire and manage network services. By using virtualization technologies to move packet processing from dedicated hardware to software, {NFV} has introduced a new market focused on the offer and distribution of Virtual Network Functions ({VNF}). Infrastructure Providers ({InP}) can benefit from an {NFV} market by providing their infrastructures to fulfill demands of end-users that, in turn, acquire {VNFs}-as-a-Service ({VNFaaS}). In this context, solutions that promote the competition between {InPs} can lead to lower prices, while increasing {VNF} performance to accommodate specific demands of end-users. In this paper, {BRAIN}, a blockchain-based reverse auction is presented to introduce an auditable solution in which {InPs} can compete to host {VNFs} taking into account the demands of each particular end-user. Such a solution helps reduce costs involved in {VNF}'s commercialization and also monetize {NFV}-enabled infrastructures. {BRAIN} is supported by a case study that provides evidence of the solution's feasibility and effectiveness. A discussion regarding blockchain advantages and drawbacks in this use-case (e.g., additional costs and time) concludes this paper.},
	eventtitle   = {2019 {IFIP} Networking Conference ({IFIP} Networking)},
	date         = {2019-05},
	keywords     = {Blockchain, Infrastructure Supply, Network Functions Virtualization, Smart Contract, Virtual Net-work Functions-as-a-Service},
	file         = {Accepted Version:/home/volodia/Zotero/storage/PGYSHZXX/Franco et al. - 2019 - BRAIN Blockchain-based Reverse Auction for Infras.pdf:application/pdf}
}
@incollection{yu_building_2019,
	title        = {Building Trustful Crowdsensing Service on the Edge},
	author       = {Yu, Biao and Chen, Yingwen and Fu, Shaojing and Yu, Wanrong and Guo, Xiaoli},
	pages        = {445--457},
	doi          = {10.1007/978-3-030-23597-0\_36},
	isbn         = {978-3-030-23596-3},
	abstract     = {Edge computing enables the data to be processed in the edge of networks in order to decrease the latency of crowdsensing services. However, due to the distributed environment and vulnerability of edges, it is difficult for different edges to reach consistency to provide the same service and protect the data from tampering at the same time. To solve these problems, the Blockchain, a credible and natural decentralized technique, is considered as a suitable tool. In this paper, we proposed a Blockchain-based edge crowdsensing service system in which the edge runs a changeable auction algorithm for every task that the users request to find a winner who can provide corresponding sensing data. Specifically, based on {PBFT} algorithm, we proposed a consensus algorithm named Leader Stable Practical Byzantine Fault Tolerance ({LS}-{PBFT}). This algorithm enables all edges to collaboratively maintain an updated, consistent and credible ledger in Blockchain. Furthermore, the data generated in this process are constructed as a multi-transaction, which can be packaged into a block and stored in the block. Simulation results reveal that the proposed system is not only efficient in generating and storing blocks but also feasible in resisting attacks of malicious users and edges. Our experiments also show that {LS}-{PBFT} takes less than 50\% of the time cost by {PBFT} to reach consensus.},
	date         = {2019-06-21}
}
@article{du_collaborative_nodate,
	title        = {Collaborative crowdsensing at the edge},
	author       = {Du, Yifan},
	pages        = 154,
	langid       = {english},
	file         = {Du - Collaborative crowdsensing at the edge.pdf:/home/volodia/Zotero/storage/VAKX98DU/Du - Collaborative crowdsensing at the edge.pdf:application/pdf}
}
@inproceedings{zavodovski_decloud_2019,
	title        = {{DeCloud}: Truthful Decentralized Double Auction for Edge Clouds},
	shorttitle   = {{DeCloud}},
	author       = {Zavodovski, Aleksandr and Bayhan, Suzan and Mohan, Nitinder and Zhou, Pengyuan and Wong, Walter and Kangasharju, Jussi},
	booktitle    = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	pages        = {2157--2167},
	doi          = {10.1109/ICDCS.2019.00212},
	note         = {{ISSN}: 2575-8411},
	abstract     = {The sharing economy has made great inroads with services like Uber or Airbnb enabling people to share their unused resources with those needing them. The computing world, however, despite its abundance of excess computational resources has remained largely unaffected by this trend, save for few examples like {SETI}\@home. We present {DeCloud}, a decentralized market framework bringing the sharing economy to on-demand computing where the offering of pay-as-you-go services will not be limited to large companies, but ad hoc clouds can be spontaneously formed on the edge of the network. We design incentive compatible double auction mechanism targeted specifically for distributed ledger trust model instead of relying on third-party auctioneer. {DeCloud} incorporates innovative matching heuristic capable of coping with the level of heterogeneity inherent for large-scale open systems. Evaluating {DeCloud} on Google cluster-usage data, we demonstrate that the system has a near-optimal performance from an economic point of view, additionally enhanced by the flexibility of matching.},
	eventtitle   = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	date         = {2019-07},
	keywords     = {Cloud computing, Cloud Computing, Edge computing, Edge Computing, Economics, Blockchain, Smart contracts, Crowdsourcing, Distributed ledger, Incentive Compatible Auction, Mechanism design, Smart Contracts, Truthful Auction}
}
@online{noauthor_cloud_nodate,
	title        = {Cloud {IoT} Core},
	url          = {https://cloud.google.com/iot-core},
	urldate      = {2021-12-06},
	abstract     = {Easily and securely connect, manage, and ingest data from globally dispersed devices.},
	titleaddon   = {Google Cloud},
	langid       = {english}
}
@online{noauthor_iot_nodate,
	title        = {{IoT} Edge {\textbar} Cloud Intelligence {\textbar} Microsoft Azure},
	url          = {https://azure.microsoft.com/en-us/services/iot-edge/},
	urldate      = {2021-12-06},
	abstract     = {Connect cloud intelligence to your edge devices with Azure {IoT} Edge, a comprehensive service that deploys artificial intelligence and custom logic to {IoT} devices.},
	langid       = {english}
}
@online{noauthor_aws_nodate,
	title        = {{AWS} {IoT} Greengrass - Amazon Web Services},
	url          = {https://aws.amazon.com/fr/greengrass/},
	urldate      = {2021-12-06},
	titleaddon   = {Amazon Web Services, Inc.},
	langid       = {french}
}
@online{noauthor_apache_nodate,
	title        = {Apache {OpenWhisk} is a serverless, open source cloud platform},
	url          = {https://openwhisk.apache.org/},
	urldate      = {2021-12-06}
}
@online{noauthor_esp8266_nodate,
	title        = {{ESP}8266 Wi-Fi {MCU} I Espressif Systems},
	url          = {https://www.espressif.com/en/products/socs/esp8266},
	urldate      = {2021-12-06}
}
@article{lage-freitas_cloud_2017,
	title        = {Cloud resource management driven by profit augmentation},
	author       = {Lage-Freitas, Andr\'{e} and Parlavantzas, Nikos and Pazat, Jean},
	volume       = 29,
	number       = 4,
	pages        = {e3899},
	doi          = {10.1002/cpe.3899},
	issn         = {1532-0634},
	url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3899},
	urldate      = {2021-12-07},
	note         = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3899},
	abstract     = {Cloud computing has become the infrastructure of choice for building and delivering software services. A key challenge for service providers is effectively managing cloud resources in order to increase profit while maintaining service-level agreements ({SLAs}) with customers. To address this challenge, this paper proposes a combination of automated mechanisms for resource and execution management. The resource management mechanisms, namely, under-provisioning and contract rescission, reduce resource allocation costs and minimize penalties incurred when performance objectives are violated. The execution management mechanisms, namely, crash recovery and delay recovery, minimize penalties incurred when reliability objectives are violated. The mechanisms are integrated in the Qu4DS framework and evaluated in the Grid'5000 testbed. The results show that the under-provisioning mechanism increases profit by 20–50\%, the contract rescission mechanism increases profit up to four times, and the execution management mechanisms increase profit by up to 60\%. Copyright \textcopyright{} 2016 John Wiley \& Sons, Ltd.},
	journaltitle = {Concurrency and Computation: Practice and Experience},
	date         = 2017,
	langid       = {english},
	keywords     = {resource management, profit maximization, service-level objectives ({SLOs}), {SLA} enforcement}
}
@article{ieee_standards_association_ieee_2018,
	title        = {{IEEE} Standard for Adoption of {OpenFog} Reference Architecture for Fog Computing},
	author       = {{IEEE Standards Association}},
	pages        = {1--176},
	doi          = {10.1109/IEEESTD.2018.8423800},
	note         = {Conference Name: {IEEE} Std 1934-2018},
	abstract     = {{OpenFog} Consortium–{OpenFog} Reference Architecture for Fog Computing is adopted by this standard. {OpenFog} Reference Architecture [{OPFRA}001.020817] is a structural and functional prescription of an open, interoperable, horizontal system architecture for distributing computing, storage, control and networking functions closer to the users along a cloud-to-thing continuum of communicating, computing, sensing and actuating entities. It encompasses various approaches to disperse Information Technology ({IT}), Communication Technology ({CT}) and Operational Technology ({OT}) Services through information messaging infrastructure as well as legacy and emerging multi-access networking technologies.},
	journaltitle = {{IEEE} Std 1934-2018},
	date         = {2018-08},
	keywords     = {Edge computing, adoption, communication technology {IEEE} 1934\texttrademark{}, Communications technology, {IEEE} Standards, information technology, Information technology, {OpenFog}, operational technology},
	file         = {IEEE Standard for Adoption of OpenFog Reference Architecture for Fog Computing:/home/volodia/Zotero/storage/8W8P3SSH/ieee-standard-for-adoption-of-openfog-reference-architecture-for.pdf.pdf:application/pdf}
}
@inreference{wikipedia_edge_2021,
	title        = {Edge computing},
	author       = {{Wikipedia}},
	booktitle    = {Wikipedia},
	url          = {https://en.wikipedia.org/w/index.php?title=Edge\%5Fcomputing\&oldid=1057908860},
	urldate      = {2021-12-12},
	note         = {Page Version {ID}: 1057908860},
	rights       = {Creative Commons Attribution-{ShareAlike} License},
	abstract     = {Edge computing is a distributed computing paradigm that brings computation and data storage closer to the sources of data. This is expected to improve response times and save bandwidth. "A common misconception is that edge and {IoT} are synonymous. Edge computing is a topology- and location-sensitive form of distributed computing, while {IoT} is a use case instantiation of edge computing." The term refers to an architecture rather than a specific technology.The origins of edge computing lie in content distributed network that were created in the late 1990s to serve web and video content from edge servers that were deployed close to users. In the early 2000s, these networks evolved to host applications and application components at the edge servers, resulting in the first commercial edge computing services that hosted applications such as dealer locators, shopping carts, real-time data aggregators, and ad insertion engines.},
	date         = {2021-11-30},
	langid       = {english}
}
@inreference{wikipedia_service-level_2021,
	title        = {Service-level agreement},
	author       = {{Wikipedia}},
	booktitle    = {Wikipedia},
	url          = {https://en.wikipedia.org/w/index.php?title=Service-level\%5Fagreement\&oldid=1045280242},
	urldate      = {2021-12-13},
	note         = {Page Version {ID}: 1045280242},
	rights       = {Creative Commons Attribution-{ShareAlike} License},
	abstract     = {A service-level agreement ({SLA}) is a commitment between a service provider and a client. Particular aspects of the service – quality, availability, responsibilities – are agreed between the service provider and the service user. The most common component of an {SLA} is that the services should be provided to the customer as agreed upon in the contract. As an example, Internet service providers and telcos will commonly include service level agreements within the terms of their contracts with customers to define the level(s) of service being sold in plain language terms. In this case the {SLA} will typically have a technical definition in  mean time between failures ({MTBF}), mean time to repair or mean time to recovery ({MTTR}); identifying which party is responsible for reporting faults or paying fees; responsibility for various data rates; throughput; jitter; or similar measurable details.},
	date         = {2021-09-19},
	langid       = {english}
}
@article{hang_sla-based_2019,
	title        = {{SLA}-Based Sharing Economy Service with Smart Contract for Resource Integrity in the Internet of Things},
	author       = {Hang, Lei and Kim, Do-Hyeun},
	volume       = 9,
	number       = 17,
	pages        = 3602,
	doi          = {10.3390/app9173602},
	url          = {https://www.mdpi.com/2076-3417/9/17/3602},
	urldate      = {2021-12-13},
	note         = {Number: 17 Publisher: Multidisciplinary Digital Publishing Institute},
	rights       = {http://creativecommons.org/licenses/by/3.0/},
	abstract     = {Recently, technology startups have leveraged the potential of blockchain-based technologies to govern institutions or interpersonal trust by enforcing signed treaties among different individuals in a decentralized environment. However, it is going to be hard enough convincing that the blockchain technology could completely replace the trust among trading partners in the sharing economy as sharing services always operate in a highly dynamic environment. With the rapid expanding of the rental market, the sharing economy faces more and more severe challenges in the form of regulatory uncertainty and concerns about abuses. This paper proposes an enhanced decentralized sharing economy service using the service level agreement ({SLA}), which documents the services the provider will furnish and defines the service standards the provider is obligated to meet. The {SLA} specifications are defined as the smart contract, which facilitates multi-user collaboration and automates the process with no involvement of the third party. To demonstrate the usability of the proposed solution in the sharing economy, a notebook sharing case study is implemented using the Hyperledger Fabric. The functionalities of the smart contract are tested using the Hyperledger Composer. Moreover, the efficiency of the designed approach is demonstrated through a series of experimental tests using different performance metrics.},
	journaltitle = {Applied Sciences},
	date         = {2019-01},
	langid       = {english},
	keywords     = {blockchain, Hyperledger Fabric, service level agreement, sharing economy, smart contract},
	file         = {SLA-Based Sharing Economy Service with Smart Contract for Resource Integrity in the Internet of Things:/home/volodia/Zotero/storage/I6Q4LQTJ/hang2019.pdf.pdf:application/pdf;Full Text PDF:/home/volodia/Zotero/storage/28D5UCB7/Hang and Kim - 2019 - SLA-Based Sharing Economy Service with Smart Contr.pdf:application/pdf}
}
@article{di_pascale_smart_2017,
	title        = {Smart Contract {SLAs} for Dense Small-Cell-as-a-Service},
	author       = {Di Pascale, Emanuele and {McMenamy}, Jasmina and Macaluso, Irene and Doyle, Linda},
	url          = {http://arxiv.org/abs/1703.04502},
	urldate      = {2021-12-13},
	abstract     = {The disruptive power of blockchain technologies represents a great opportunity to re-imagine standard practices of telecommunication networks and to identify critical areas that can benefit from brand new approaches. As a starting point for this debate, we look at the current limits of infrastructure sharing, and specifically at the Small-Cell-as-a-Service trend, asking ourselves how we could push it to its natural extreme: a scenario in which any individual home or business user can become a service provider for mobile network operators, freed from all the scalability and legal constraints that are inherent to the current modus operandi. We propose the adoption of smart contracts to implement simple but effective Service Level Agreements ({SLAs}) between small cell providers and mobile operators, and present an example contract template based on the Ethereum blockchain.},
	journaltitle = {{arXiv}:1703.04502 [cs]},
	date         = {2017-03-13},
	eprinttype   = {arxiv},
	eprint       = {1703.04502},
	keywords     = {Computer Science - Networking and Internet Architecture},
	file         = {arXiv Fulltext PDF:/home/volodia/Zotero/storage/VXR3GYJ8/Di Pascale et al. - 2017 - Smart Contract SLAs for Dense Small-Cell-as-a-Serv.pdf:application/pdf}
}
@inproceedings{zhou_trustworthy_2018,
	title        = {Trustworthy Cloud Service Level Agreement Enforcement with Blockchain Based Smart Contract},
	author       = {Zhou, Huan and de Laat, Cees and Zhao, Zhiming},
	booktitle    = {2018 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	pages        = {255--260},
	doi          = {10.1109/CloudCom2018.2018.00057},
	note         = {{ISSN}: 2330-2186},
	abstract     = {Cloud Service Level Agreement ({SLA}) is challengeable due to lacking a trustworthy platform. This paper presents a witness model to credibly enforce the cloud service level agreement. Through introducing the witness role and using the blockchain based smart contract, we solve the trust issues about who can detect the service violation, how the violation is confirmed and the compensation is guaranteed. In this model, a verifiable consensus sortition algorithm proposed by us is firstly leveraged to select independent witnesses to form a witness committee. They are responsible for a specific service level agreement and get paid by monitoring and detecting service violation. Through carefully designing the witness' payoff function in the agreement, we further leverage game theory to analyze and prove that it is not the witness itself is trustworthy. Instead, the witness has to tell the truth because of its greedy nature, which is the desire to maximize its own revenue. As long as the service violation is confirmed by the witness committee, the compensation is automatically transferred to the customer by the smart contract. Finally, we implement a proof-of-concept prototype with the smart contract of Ethereum blockchain. It demonstrates the feasibility of our model.},
	eventtitle   = {2018 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	date         = {2018-12},
	keywords     = {Cloud computing, Quality of service, Game theory, Monitoring, service level agreement, cloud computing, smart contract, blockchain, Systems architecture},
	file         = {Trustworthy Cloud Service Level Agreement Enforcement with Blockchain Based Smart Contract:/home/volodia/Zotero/storage/AFST4S2F/10.1109\@CloudCom2018.2018.00057.pdf.pdf:application/pdf;Submitted Version:/home/volodia/Zotero/storage/93R9JKIP/Zhou et al. - 2018 - Trustworthy Cloud Service Level Agreement Enforcem.pdf:application/pdf}
}
@inproceedings{maurice_hello_2017,
	title        = {Hello from the Other Side: {SSH} over Robust Cache Covert Channels in the Cloud},
	shorttitle   = {Hello from the Other Side},
	author       = {Maurice, Clementine and Weber, Manuel and Schwarz, Michael and Giner, Lukas and Gruss, Daniel and Boano, Carlo Alberto and Mangard, Stefan and Roemer, Kay and Mangard, Stefan},
	booktitle    = {Proceedings 2017 Network and Distributed System Security Symposium},
	location     = {San Diego, {CA}},
	publisher    = {Internet Society},
	doi          = {10.14722/ndss.2017.23294},
	isbn         = {978-1-891562-46-4},
	url          = {https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/hello-other-side-ssh-over-robust-cache-covert-channels-cloud/},
	urldate      = {2021-12-13},
	abstract     = {Covert channels evade isolation mechanisms between multiple parties in the cloud. Especially cache covert channels allow the transmission of several hundred kilobits per second between unprivileged user programs in separate virtual machines. However, caches are small and shared and thus cache-based communication is susceptible to noise from any system activity and interrupts. The feasibility of a reliable cache covert channel under a severe noise scenario has not been demonstrated yet. Instead, previous work relies on either of the two contradicting assumptions: the assumption of direct applicability of error-correcting codes, or the assumption that noise effectively prevents covert channels.},
	eventtitle   = {Network and Distributed System Security Symposium},
	date         = 2017,
	langid       = {english},
	file         = {Maurice et al. - 2017 - Hello from the Other Side SSH over Robust Cache C.pdf:/home/volodia/Zotero/storage/FMGKD9W6/Maurice et al. - 2017 - Hello from the Other Side SSH over Robust Cache C.pdf:application/pdf}
}
@article{bocci_secure_2021,
	title        = {Secure {FaaS} orchestration in the fog: how far are we?},
	shorttitle   = {Secure {FaaS} orchestration in the fog},
	author       = {Bocci, Alessandro and Forti, Stefano and Ferrari, Gian-Luigi and Brogi, Antonio},
	volume       = 103,
	number       = 5,
	pages        = {1025--1056},
	doi          = {10.1007/s00607-021-00924-y},
	issn         = {1436-5057},
	url          = {https://doi.org/10.1007/s00607-021-00924-y},
	urldate      = {2021-12-13},
	abstract     = {Function-as-a-Service ({FaaS}) allows developers to define, orchestrate and run modular event-based pieces of code on virtualised resources, without the burden of managing the underlying infrastructure nor the life-cycle of such pieces of code. Indeed, {FaaS} providers offer resource auto-provisioning, auto-scaling and pay-per-use billing at no costs for idle time. This makes it easy to scale running code and it represents an effective and increasingly adopted way to deliver software. This article aims at offering an overview of the existing literature in the field of next-gen {FaaS} from three different perspectives: (i) the definition of {FaaS} orchestrations, (ii) the execution of {FaaS} orchestrations in Fog computing environments, and (iii) the security of {FaaS} orchestrations. Our analysis identify trends and gaps in the literature, paving the way to further research on securing {FaaS} orchestrations in Fog computing landscapes.},
	journaltitle = {Computing},
	shortjournal = {Computing},
	date         = {2021-05-01},
	langid       = {english},
	file         = {Secure FaaS orchestration in the fog\: how far are we?:/home/volodia/Zotero/storage/DWWWJ6C3/bocci2021.pdf.pdf:application/pdf;Springer Full Text PDF:/home/volodia/Zotero/storage/I4ADMKNT/Bocci et al. - 2021 - Secure FaaS orchestration in the fog how far are .pdf:application/pdf}
}
@inproceedings{baresi_towards_2019,
	title        = {Towards a Serverless Platform for Edge Computing},
	author       = {Baresi, Luciano and Filgueira Mendon\c{c}a, Danilo},
	booktitle    = {2019 {IEEE} International Conference on Fog Computing ({ICFC})},
	pages        = {1--10},
	doi          = {10.1109/ICFC.2019.00008},
	abstract     = {The emergence of real-time and data-intensive applications empowered by mobile computing and {IoT} devices is challenging the success of centralized data centers, and fostering the adoption of the paradigm of fog/edge computing. Differently from cloud data centers, fog nodes are geographically distributed in proximity to data prosumers, taking advantage of the emerging wireless communication technologies and mobile networks. The limited resources of densely distributed fog nodes call for their efficient use by hosted applications and services. To address this challenge, and the needs of different application scenarios, this paper proposes a serverless platform for edge computing. It starts motivating the adoption of a serverless architecture. Then, it presents the services and mechanisms that are the building blocks of a Serverless Edge Platform. The paper also proposes a prototype platform and its assessment. Obtained results demonstrate the feasibility of the proposed solution for satisfying different application requirements in diverse deployment configurations of heterogeneous fog nodes.},
	eventtitle   = {2019 {IEEE} International Conference on Fog Computing ({ICFC})},
	date         = {2019-06},
	keywords     = {Cloud computing, Computer architecture, Edge computing, {FAA}, Computational modeling, Data centers, Containers, data-intensive, edge-computing, fog-computing, latency-sensitive, serverless-computing},
	file         = {Towards a Serverless Platform for Edge Computing:/home/volodia/Zotero/storage/4HAWYLYL/10.1109\@ICFC.2019.00008.pdf.pdf:application/pdf}
}
@inproceedings{baresi_paps_2019,
	title        = {{PAPS}: A Framework for Decentralized Self-management at the Edge},
	shorttitle   = {{PAPS}},
	author       = {Baresi, Luciano and Mendon\c{c}a, Danilo Filgueira and Quattrocchi, Giovanni},
	booktitle    = {Service-Oriented Computing},
	location     = {Cham},
	publisher    = {Springer International Publishing},
	series       = {Lecture Notes in Computer Science},
	pages        = {508--522},
	doi          = {10.1007/978-3-030-33702-5\_39},
	isbn         = {978-3-030-33702-5},
	abstract     = {The emergence of latency-sensitive and data-intensive applications requires that computational resources be moved closer to users on computing nodes at the edge of the network (edge computing). Since these nodes have limited resources, the collaboration among them is critical for the robustness, performance, and scalability of the system. One must allocate and provision computational resources to the different components, and these components must be placed on the nodes by considering both network latency and resource availability. Since centralized solutions could be impracticable for large-scale systems, this paper presents {PAPS} (Partitioning, Allocation, Placement, and Scaling), a framework that tackles the complexity of edge infrastructures by means of decentralized self-management and serverless computing. First, the large-scale edge topology is dynamically partitioned into delay-aware communities. Community leaders then provide a reference allocation of resources and tackle the intricate placement of the containers that host serverless functions. Finally, control theory is used at the node level to scale resources timely and effectively. The assessment shows both the feasibility of the approach and its ability to tackle the placement and allocation problem for large-scale edge topologies with up to 100 serverless functions and intense and unpredictable workload variations.},
	editor       = {Yangui, Sami and Bouassida Rodriguez, Ismael and Drira, Khalil and Tari, Zahir},
	date         = 2019,
	langid       = {english},
	keywords     = {Edge computing, Resource management, Serverless computing, Geo-distributed infrastructures, Service placement},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/4QP9F6YF/Baresi et al. - 2019 - PAPS A Framework for Decentralized Self-managemen.pdf:application/pdf}
}
@inproceedings{baresi_empowering_2017,
	title        = {Empowering Low-Latency Applications Through a Serverless Edge Computing Architecture},
	author       = {Baresi, Luciano and Mendon\c{c}a, Danilo Filgueira and Garriga, Martin},
	publisher    = {Springer International Publishing},
	volume       = {{LNCS}-10465},
	pages        = 196,
	doi          = {10.1007/978-3-319-67262-5\_15},
	url          = {https://hal.inria.fr/hal-01677622},
	urldate      = {2021-12-14},
	abstract     = {The exponential increase of the data generated by pervasive and mobile devices requires disrupting approaches for the realization of emerging mobile and {IoT} applications. Although cloud computing provides virtually unlimited computational resources, low-latency applications cannot afford the high latencies introduced by sending and retrieving data from/to the cloud. In this scenario, edge computing appears as a promising solution by bringing computation and data near to users and devices. However, the resource-finite nature of edge servers constrains the possibility of deploying full applications on them. To cope with these problems, we propose a serverless architecture at the edge, bringing a highly scalable, intelligent and cost-effective use of edge infrastructure's resources with minimal configuration and operation efforts. The feasibility of our approach is shown through an augmented reality use case for mobile devices, in which we offload computation and data intensive tasks from the devices to serverless functions at the edge, outperforming the cloud alternative up to 80\% in terms of throughput and latency.},
	eventtitle   = {6th European Conference on Service-Oriented and Cloud Computing ({ESOCC})},
	date         = {2017-09-27},
	langid       = {english},
	file         = {Empowering Low-Latency Applications Through a Serverless Edge Computing Architecture:/home/volodia/Zotero/storage/X69IKTIF/baresi2017.pdf.pdf:application/pdf;Full Text PDF:/home/volodia/Zotero/storage/CCSGDR89/Baresi et al. - 2017 - Empowering Low-Latency Applications Through a Serv.pdf:application/pdf}
}
@article{misra_fogprime_2021,
	title        = {{FogPrime}: Dynamic Pricing-Based Strategic Resource Management in Fog Networks},
	shorttitle   = {{FogPrime}},
	author       = {Misra, Subhas Chandra and Mondal, Ayan},
	volume       = 70,
	number       = 8,
	pages        = {8227--8236},
	doi          = {10.1109/TVT.2021.3096149},
	issn         = {1939-9359},
	note         = {Conference Name: {IEEE} Transactions on Vehicular Technology},
	abstract     = {In this paper, the problem of strategic resource management in fog networks is discussed while considering a pay-per-use model, similar to that used in cloud. Fog networks are distributed in nature, because of which resource management in these networks is an {NP}-hard problem. In the existing literature, the researchers focused on resource management in fog networks, while considering the network delay constraint. However, none of these works considered the effect of pricing policy while deciding on resource allocation. Hence, there is a need for pricing-based resource management in fog networks. In this work, we proposed a dynamic pricing-based resource allocation scheme, named {FogPrime}, for analyzing the trade-off between the service delay and the associated price. In {FogPrime}, we use dynamic coalition-formation game to decide the resource allocation strategy locally within a cluster. On the other hand, we use utility game to choose the fog nodes, strategically, while considering the aforementioned trade-off. Through simulation, we observed that {FogPrime} outperforms the existing schemes in terms of satisfaction of the involved entities - the end-user and the fog nodes. Using {FogPrime}, the satisfaction of the end-users and the fog nodes increases by 24.49-47.82\%, respectively. Additionally, we observe that {FogPrime} ensures an even distribution of profit among the fog nodes and enables the end-users to pay less at most by 15.88-47.27\%.},
	journaltitle = {{IEEE} Transactions on Vehicular Technology},
	date         = {2021-08},
	keywords     = {Cloud computing, Resource management, game theory, Games, Delays, Fog computing, Dynamic scheduling, Pricing, dynamic coalition formation, offloading, pricing, utility game, Vehicle dynamics},
	file         = {FogPrime\: Dynamic Pricing-Based Strategic Resource Management in Fog Networks:/home/volodia/Zotero/storage/U3JMG95R/misra2021.pdf.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/6QEE9G8F/9479709.html:text/html}
}
@inproceedings{junior_stateful_2020,
	title        = {Stateful Container Migration in Geo-Distributed Environments},
	author       = {Junior, Paulo Souza and Miorandi, Daniele and Pierre, Guillaume},
	publisher    = {{IEEE}},
	pages        = 1,
	url          = {https://hal.inria.fr/hal-02963913},
	urldate      = {2021-12-31},
	abstract     = {Container migration is an essential functionality in large-scale geo-distributed platforms such as fog computing infrastructures. Contrary to migration within a single data center, long-distance migration requires that the container's disk state should be migrated together with the container itself. However, this state may be arbitrarily large, so its transfer may create long periods of unavailability for the container. We propose to exploit the layered structure provided by the {OverlayFS} file system to transparently snapshot the volumes' contents and transfer them prior to the actual container migration. We implemented this mechanism within Kubernetes. Our evaluations based on a real fog computing test-bed show that our techniques reduce the container's downtime during migration by a factor 4 compared to a baseline with no volume checkpoint.},
	eventtitle   = {{CloudCom} 2020 - 12th {IEEE} International Conference on Cloud Computing Technology and Science},
	date         = {2020-12-14},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/YZ3YST8A/hal-02963913.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/LY5BI9SB/Junior et al. - 2020 - Stateful Container Migration in Geo-Distributed En.pdf:application/pdf}
}
@inproceedings{tamiru_mck8s_2021,
	title        = {mck8s: An orchestration platform for geo-distributed multi-cluster environments},
	shorttitle   = {mck8s},
	author       = {Tamiru, Mulugeta and Pierre, Guillaume and Tordsson, Johan and Elmroth, Erik},
	pages        = 1,
	url          = {https://hal.inria.fr/hal-03205743},
	urldate      = {2021-12-31},
	abstract     = {Following the adoption of cloud computing, the proliferation of cloud data centers in multiple regions, and the emergence of computing paradigms such as fog computing, there is a need for integrated and efficient management of geodistributed clusters. Geo-distributed deployments suffer from resource fragmentation, as the resources in certain locations are over-allocated while others are under-utilized. Orchestration platforms such as Kubernetes and Kubernetes Federation offer the conceptual models and building blocks that can be used to build integrated solutions that address the resource fragmentation challenge. In this work, we propose mck8s-an orchestration platform for multi-cluster applications on multiple geo-distributed Kubernetes clusters. It offers controllers that automatically place, scale, and burst multi-cluster applications across multiple geo-distributed Kubernetes clusters. mck8s allocates the requested resources to all incoming applications while making efficient use of resources. We designed mck8s to be easy to use by development and operation teams by adopting Kubernetes' design principles and manifest files. We evaluated mck8s in a geo-distributed experimental testbed in Grid'5000. Our results show that mck8s balances the resource allocation across multiple clusters and reduces the fraction of pending pods to 6\% as opposed to 65\% in the case of Kubernetes Federation for the same workload.},
	eventtitle   = {{ICCCN} 2021 - 30th International Conference on Computer Communications and Networks},
	date         = {2021-07-19},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/RYKUC5VH/hal-03205743.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/Z42WYC5G/Tamiru et al. - 2021 - mck8s An orchestration platform for geo-distribut.pdf:application/pdf}
}
@article{arkian_potable_2020,
	title        = {Potable Water Management with integrated Fog computing and {LoRaWAN} technologies},
	author       = {Arkian, Hamidreza and Giouroukis, Dimitrios and Junior, Paulo Souza and Pierre, Guillaume},
	pages        = 1,
	url          = {https://hal.inria.fr/hal-02513467},
	urldate      = {2021-12-31},
	journaltitle = {{IEEE} {IoT} Newsletter},
	date         = {2020-03-11},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/CXCS7B26/hal-02513467.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/6VET8PBG/Arkian et al. - 2020 - Potable Water Management with integrated Fog compu.pdf:application/pdf}
}
@inproceedings{tavonatti_experimental_2021,
	title        = {An experimental evaluation of the scalability of permissioned blockchains},
	author       = {Tavonatti, Stefano and Battulga, Davaadorj and Farhadi, Mozhdeh and Caprini, Carlo and Miorandi, Daniele},
	pages        = 1,
	url          = {https://hal.inria.fr/hal-03263551},
	urldate      = {2021-12-31},
	abstract     = {Permissioned blockchains are decentralized digital systems, which are used to record transactions and which maintain multiple, synchronized copies of the whole list of transactions (i.e., the ledger) on geographically dispersed nodes. Cryptographic operations are used to 'chain' transactions in the ledger, making the system tamper-resistant. In permissioned blockchains, access to the system (in particular in terms of the ability to append new transactions to the ledger) is limited to a specific set of well-identified nodes: this feature puts them apart from the blockchain systems ('permissionless') commonly use to power cryptocurrencies. The ability to control who can operate on the blockchain makes such systems a good choice for implementing use cases like supply chain management, business ecosystems or notarization. Driven by the interest in launching a new digital product for the education market (related to the management of education certificates), we faced some issues related to the scalability of permissioned blockchains. Given the lack of a consistent and comprehensive literature on the subject, we run an extensive experimental testing campaign on a large-scale distributed computing infrastructure (Grid'5000), measuring the performance of a popular permissioned blockchain framework (Hyperledger Fabric) under varying conditions. In this paper, we share the results obtained, which shed light on both scalability bottlenecks and possible approaches for overcoming such limitations in real-world business contexts.},
	eventtitle   = {{FiCloud} 2021 - 8th International Conference on Future Internet of Things and Cloud},
	date         = {2021-08-23},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/Z8ZUCSQV/hal-03263551.html:text/html;Full Text PDF:/home/volodia/Zotero/storage/P9GDSTTQ/Tavonatti et al. - 2021 - An experimental evaluation of the scalability of p.pdf:application/pdf}
}
@article{ahmed_fog_2019,
	title        = {Fog Computing Applications: Taxonomy and Requirements},
	shorttitle   = {Fog Computing Applications},
	author       = {Ahmed, Arif and Arkian, {HamidReza} and Battulga, Davaadorj and Fahs, Ali J. and Farhadi, Mozhdeh and Giouroukis, Dimitrios and Gougeon, Adrien and Gutierrez, Felipe Oliveira and Pierre, Guillaume and Souza Jr, Paulo R. and Tamiru, Mulugeta Ayalew and Wu, Li},
	url          = {http://arxiv.org/abs/1907.11621},
	urldate      = {2021-12-31},
	abstract     = {Fog computing was designed to support the specific needs of latency-critical applications such as augmented reality, and {IoT} applications which produce massive volumes of data that are impractical to send to faraway cloud data centers for analysis. However this also created new opportunities for a wider range of applications which in turn impose their own requirements on future fog computing platforms. This article presents a study of a representative set of 30 fog computing applications and the requirements that a general-purpose fog computing platform should support.},
	journaltitle = {{arXiv}:1907.11621 [cs]},
	date         = {2019-07-26},
	eprinttype   = {arxiv},
	eprint       = {1907.11621},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/72KEHS7D/1907.html:text/html;arXiv Fulltext PDF:/home/volodia/Zotero/storage/HGRTSTRM/Ahmed et al. - 2019 - Fog Computing Applications Taxonomy and Requireme.pdf:application/pdf}
}
@online{noauthor_measurement-driven_nodate,
	title        = {‪Measurement-driven design and runtime optimization in edge computing: Methodology and tools‬},
	shorttitle   = {‪Measurement-driven design and runtime optimization in edge computing},
	url          = {https://scholar.google.com/citations?view\%5Fop=view\%5Fcitation\&hl=fr\&user=sTVmHWUAAAAJ\&sortby=pubdate\&alert\%5Fpreview\%5Ftop\%5Frm=2\&citation\%5Ffor\%5Fview=sTVmHWUAAAAJ:9NZAP19TdFAC},
	urldate      = {2021-12-30},
	abstract     = {‪C Caiazza, C Cicconetti, V Luconi, A Vecchio‬, ‪Computer Networks, 2021‬ - ‪Cit\'{e}(e) 1~fois‬},
	file         = {Snapshot:/home/volodia/Zotero/storage/V5DNIRQU/citations.html:text/html}
}
@article{cicconetti_faas_2021,
	title        = {{FaaS} Execution Models for Edge Applications},
	author       = {Cicconetti, Claudio and Conti, Marco and Passarella, Andrea},
	url          = {http://arxiv.org/abs/2111.06595},
	urldate      = {2021-12-30},
	abstract     = {In this paper, we address the problem of supporting stateful workflows following a Function-as-a-Service ({FaaS}) model in edge networks. In particular we focus on the problem of data transfer, which can be a performance bottleneck due to the limited speed of communication links in some edge scenarios and we propose three different schemes: a pure {FaaS} implementation, {StateProp}, i.e., propagation of the application state throughout the entire chain of functions, and {StateLocal}, i.e., a solution where the state is kept local to the workers that run functions and retrieved only as needed. We then extend the proposed schemes to the more general case of applications modeled as Directed Acyclic Graphs ({DAGs}), which cover a broad range of practical applications, e.g., in the Internet of Things ({IoT}) area. Our contribution is validated via a prototype implementation. Experiments in emulated conditions show that applying the data locality principle reduces significantly the volume of network traffic required and improves the end-to-end delay performance, especially with local caching on edge nodes and low link speeds.},
	journaltitle = {{arXiv}:2111.06595 [cs]},
	date         = {2021-11-12},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2111.06595},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file         = {Cicconetti et al. - 2021 - FaaS Execution Models for Edge Applications.pdf:/home/volodia/Zotero/storage/AAVASTKH/Cicconetti et al. - 2021 - FaaS Execution Models for Edge Applications.pdf:application/pdf}
}
@online{noauthor_faas_nodate,
	title        = {‪{FaaS} Execution Models for Edge Applications‬},
	url          = {https://scholar.google.com/citations?view\%5Fop=view\%5Fcitation\&hl=fr\&user=sTVmHWUAAAAJ\&sortby=pubdate\&alert\%5Fpreview\%5Ftop\%5Frm=2\&citation\%5Ffor\%5Fview=sTVmHWUAAAAJ:TesyEGJKHF4C},
	urldate      = {2021-12-30},
	abstract     = {‪C Cicconetti, M Conti, A Passarella‬, ‪{arXiv} preprint {arXiv}:2111.06595, 2021‬},
	file         = {Snapshot:/home/volodia/Zotero/storage/FUKA58M3/citations.html:text/html}
}
@inreference{wikipedia_hungarian_2021,
	title        = {Hungarian algorithm},
	author       = {{Wikipedia}},
	booktitle    = {Wikipedia},
	url          = {https://en.wikipedia.org/w/index.php?title=Hungarian\%5Falgorithm\&oldid=1055332388},
	urldate      = {2021-12-30},
	note         = {Page Version {ID}: 1055332388},
	rights       = {Creative Commons Attribution-{ShareAlike} License},
	abstract     = {
		The Hungarian method is a combinatorial optimization algorithm that solves the assignment problem in polynomial time and which anticipated later primal–dual methods. It was developed and published in 1955 by Harold Kuhn, who gave the name "Hungarian method" because the algorithm was largely based on the earlier works of two Hungarian mathematicians: D\'{e}nes K\H{o}nig and Jen\H{o} Egerv\'{a}ry.James Munkres reviewed the algorithm in 1957 and observed that it is (strongly) polynomial. Since then the algorithm has been known also as the Kuhn–Munkres algorithm or Munkres assignment algorithm. The time complexity of the original algorithm was

		O (

		n

		4

		)

		\{{\textbackslash}displaystyle O(n{\textasciicircum}\{4\})\} , however Edmonds and Karp, and independently Tomizawa noticed that it can be modified to achieve an

		O (

		n

		3

		)

		\{{\textbackslash}displaystyle O(n{\textasciicircum}\{3\})\} running time. One of the most popular

		O (

		n

		3

		)

		\{{\textbackslash}displaystyle O(n{\textasciicircum}\{3\})\} variants is the Jonker–Volgenant algorithm. Ford and Fulkerson extended the method to general maximum flow problems in form of the Ford–Fulkerson algorithm. In 2006, it was discovered that Carl Gustav Jacobi had solved the assignment problem in the 19th century, and the solution had been published posthumously in 1890 in Latin.
	},
	date         = {2021-11-15},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/IFJGTIZN/index.html:text/html}
}
@article{shi_edge_2016,
	title        = {Edge Computing: Vision and Challenges},
	shorttitle   = {Edge Computing},
	author       = {Shi, Weisong and Cao, Jie and Zhang, Quan and Li, Youhuizi and Xu, Lanyu},
	volume       = 3,
	number       = 5,
	pages        = {637--646},
	doi          = {10.1109/JIOT.2016.2579198},
	issn         = {2327-4662},
	note         = {Conference Name: {IEEE} Internet of Things Journal},
	abstract     = {The proliferation of Internet of Things ({IoT}) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.},
	journaltitle = {{IEEE} Internet of Things Journal},
	date         = {2016-10},
	keywords     = {Cloud computing, Edge computing, Bandwidth, Data privacy, Internet of things, Internet of Things ({IoT}), Mobile handsets, smart home and city, Smart homes, Time factors},
	file         = {Edge Computing\: Vision and Challenges:/home/volodia/Zotero/storage/42CGZKKN/shi2016.pdf.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/MDDBRVUS/7488250.html:text/html}
}
@article{baresi_paps_2021,
	title        = {{PAPS}: A Serverless Platform for Edge Computing Infrastructures},
	shorttitle   = {{PAPS}},
	author       = {Baresi, Luciano and Quattrocchi, Giovanni},
	volume       = 3,
	pages        = 58,
	doi          = {10.3389/frsc.2021.690660},
	issn         = {2624-9634},
	url          = {https://www.frontiersin.org/article/10.3389/frsc.2021.690660},
	urldate      = {2021-12-28},
	abstract     = {Edge computing infrastructures are often employed to run applications with low latency requirements. Users can exploits nodes that are close to their physical positions so that the delay of sending computations and data to the Cloud is mitigated. Since users frequently change their locations, and the resources available in the Edge are limited, the management of these infrastructures poses new, difficult challenges. This paper presents {PAPS} (Partitioning, Allocation, Placement, and Scaling), a framework for the efficient, automated and scalable management of large-scale Edge topologies. {PAPS} acts as a serveless platform for the Edge. Service providers can upload applications as compositions of lightweight and stateless functions along with latency constraints. At runtime, {PAPS} manages these applications by executing them in containers, it changes their placement in the Edge topology according to the geographical distribution of the workload, and efficiently allocates resources according to their needs. This paper also presents the architecture of a {PAPS} prototype built atop Kubernetes and {OpenFaaS}. The assessment shows both the feasibility of the approach and the ability of efficiently managing hundreds of serverless concurrent functions and of dealing with intense and unpredictable workload variations.},
	journaltitle = {Frontiers in Sustainable Cities},
	date         = 2021,
	file         = {Full Text PDF:/home/volodia/Zotero/storage/XLIJASD3/Baresi and Quattrocchi - 2021 - PAPS A Serverless Platform for Edge Computing Inf.pdf:application/pdf}
}
@inproceedings{xu_zenith_2017,
	title        = {Zenith: Utility-Aware Resource Allocation for Edge Computing},
	shorttitle   = {Zenith},
	author       = {Xu, Jinlai and Palanisamy, Balaji and Ludwig, Heiko and Wang, Qingyang},
	booktitle    = {2017 {IEEE} International Conference on Edge Computing ({EDGE})},
	pages        = {47--54},
	doi          = {10.1109/IEEE.EDGE.2017.15},
	abstract     = {In the Internet of Things({IoT}) era, the demands for low-latency computing for time-sensitive applications (e.g., location-based augmented reality games, real-time smart grid management, real-time navigation using wearables) has been growing rapidly. Edge Computing provides an additional layer of infrastructure to fill latency gaps between the {IoT} devices and the back-end computing infrastructure. In the edge computing model, small-scale micro-datacenters that represent ad-hoc and distributed collection of computing infrastructure pose new challenges in terms of management and effective resource sharing to achieve a globally efficient resource allocation. In this paper, we propose Zenith, a novel model for allocating computing resources in an edge computing platform that allows service providers to establish resource sharing contracts with edge infrastructure providers apriori. Based on the established contracts, service providers employ a latency-aware scheduling and resource provisioning algorithm that enables tasks to complete and meet their latency requirements. The proposed techniques are evaluated through extensive experiments that demonstrate the effectiveness, scalability and performance efficiency of the proposed model.},
	eventtitle   = {2017 {IEEE} International Conference on Edge Computing ({EDGE})},
	date         = {2017-06},
	keywords     = {Cloud computing, Edge computing, Resource management, Computational modeling, fog computing, resource allocation, edge computing, Containers, Contracts, Logic gates},
	file         = {Zenith\: Utility-Aware Resource Allocation for Edge Computing:/home/volodia/Zotero/storage/8F42HK3V/xu2017.pdf.pdf:application/pdf}
}
@article{cao_edge_2020,
	title        = {Edge Federation: Towards an Integrated Service Provisioning Model},
	shorttitle   = {Edge Federation},
	author       = {Cao, Xiaofeng and Tang, Guoming and Guo, Deke and Li, Yan and Zhang, Weiming},
	volume       = 28,
	number       = 3,
	pages        = {1116--1129},
	doi          = {10.1109/TNET.2020.2979361},
	issn         = {1063-6692, 1558-2566},
	url          = {http://arxiv.org/abs/1902.09055},
	urldate      = {2022-01-03},
	abstract     = {Edge computing is a promising computing paradigm for pushing the cloud service to the network edge. To this end, edge infrastructure providers ({EIPs}) need to bring computation and storage resources to the network edge and allow edge service providers ({ESPs}) to provision latency-critical services to users. Currently, {EIPs} prefer to establish a series of private edge-computing environments to serve specific requirements of users. This kind of resource provisioning mechanism severely limits the development and spread of edge computing for serving diverse user requirements. To this end, we propose an integrated resource provisioning model, named edge federation, to seamlessly realize the resource cooperation and service provisioning across standalone edge computing providers and clouds. To efficiently schedule and utilize the resources across multiple {EIPs}, we systematically characterize the provisioning process as a large-scale linear programming ({LP}) problem and transform it into an easily solved form. Accordingly, we design a dynamic algorithm to tackle the varying service demands from users. We conduct extensive experiments over the base station networks in Toronto city. Compared with the existing fixed contract model and multihoming model, edge federation can reduce the overall cost of {EIPs} by 23.3\% to 24.5\%, and 15.5\% to 16.3\%, respectively.},
	journaltitle = {{IEEE}/{ACM} Transactions on Networking},
	shortjournal = {{IEEE}/{ACM} Trans. Networking},
	date         = {2020-06},
	eprinttype   = {arxiv},
	eprint       = {1902.09055},
	keywords     = {Computer Science - Networking and Internet Architecture},
	file         = {Edge Federation\: Towards an Integrated Service Provisioning Model:/home/volodia/Zotero/storage/7G5S6KTV/cao2020.pdf.pdf:application/pdf;arXiv Fulltext PDF:/home/volodia/Zotero/storage/A4QXZ3KV/Cao et al. - 2020 - Edge Federation Towards an Integrated Service Pro.pdf:application/pdf}
}
@article{yousefpour_all_2019,
	title        = {All one needs to know about fog computing and related edge computing paradigms: A complete survey},
	shorttitle   = {All one needs to know about fog computing and related edge computing paradigms},
	author       = {Yousefpour, Ashkan and Fung, Caleb and Nguyen, Tam and Kadiyala, Krishna and Jalali, Fatemeh and Niakanlahiji, Amirreza and Kong, Jian and Jue, Jason P.},
	volume       = 98,
	pages        = {289--330},
	doi          = {10.1016/j.sysarc.2019.02.009},
	issn         = {1383-7621},
	url          = {https://www.sciencedirect.com/science/article/pii/S1383762118306349},
	urldate      = {2022-01-07},
	abstract     = {With the Internet of Things ({IoT}) becoming part of our daily life and our environment, we expect rapid growth in the number of connected devices. {IoT} is expected to connect billions of devices and humans to bring promising advantages for us. With this growth, fog computing, along with its related edge computing paradigms, such as multi-access edge computing ({MEC}) and cloudlet, are seen as promising solutions for handling the large volume of security-critical and time-sensitive data that is being produced by the {IoT}. In this paper, we first provide a tutorial on fog computing and its related computing paradigms, including their similarities and differences. Next, we provide a taxonomy of research topics in fog computing, and through a comprehensive survey, we summarize and categorize the efforts on fog computing and its related computing paradigms. Finally, we provide challenges and future directions for research in fog computing.},
	journaltitle = {Journal of Systems Architecture},
	shortjournal = {Journal of Systems Architecture},
	date         = {2019-09-01},
	langid       = {english},
	keywords     = {Cloud computing, Edge computing, Fog computing, Cloudlet, Internet of things ({IoT}), Mist computing, Mobile edge computing, Multi-access edge computing},
	file         = {Yousefpour et al\_2019\_All one needs to know about fog computing and related edge computing paradigms.pdf:/home/volodia/Zotero/storage/8X8IXI3B/Yousefpour et al\_2019\_All one needs to know about fog computing and related edge computing paradigms.pdf:application/pdf}
}
@article{r_sreekanth_mobile_2022,
	title        = {Mobile Fog Computing by Using {SDN}/{NFV} on 5G Edge Nodes},
	author       = {R. Sreekanth, G. and Ahmed Najat Ahmed, S. and Sarac, Marko and Strumberger, Ivana and Bacanin, Nebojsa and Zivkovic, Miodrag},
	volume       = 41,
	number       = 2,
	pages        = {751--765},
	doi          = {10.32604/csse.2022.020534},
	issn         = {0267-6192},
	url          = {https://www.techscience.com/csse/v41n2/45191},
	urldate      = {2022-01-14},
	abstract     = {Fog computing provides quality of service for cloud infrastructure. As the data computation intensifies, edge computing becomes difficult. Therefore, mobile fog computing is used for reducing traffic and the time for data computation in the network. In previous studies, software-defined networking ({SDN}) and network functions virtualization ({NFV}) were used separately in edge computing. Current industrial and academic research is tackling to integrate {SDN} and {NFV} in different environments to address the challenges in performance, reliability, and scalability. {SDN}/{NFV} is still in development. The traditional Internet of things ({IoT}) data analysis system is only based on a linear and time-variant system that needs an {IoT} data system with a high-precision model. This paper proposes a combined architecture of {SDN} and {NFV} on an edge node server for {IoT} devices to reduce the computational complexity in cloud-based fog computing. {SDN} provides a generalization structure of the forwarding plane, which is separated from the control plane. Meanwhile, {NFV} concentrates on virtualization by combining the forwarding model with virtual network functions ({VNFs}) as a single or chain of {VNFs}, which leads to interoperability and consistency. The orchestrator layer in the proposed software-defined {NFV} is responsible for handling real-time tasks by using an edge node server through the {SDN} controller via four actions: task creation, modification, operation, and completion. Our proposed architecture is simulated on the {EstiNet} simulator, and total time delay, reliability, and satisfaction are used as evaluation parameters. The simulation results are compared with the results of existing architectures, such as software-defined unified virtual monitoring function and {ASTP}, to analyze the performance of the proposed architecture. The analysis results indicate that our proposed architecture achieves better performance in terms of total time delay (1800 s for 200 {IoT} devices), reliability (90\%), and satisfaction (90\%).},
	journaltitle = {Computer Systems Science and Engineering},
	date         = 2022,
	langid       = {english},
	file         = {R. Sreekanth et al. - 2022 - Mobile Fog Computing by Using SDNNFV on 5G Edge N.pdf:/home/volodia/Zotero/storage/QYNUNCUI/R. Sreekanth et al. - 2022 - Mobile Fog Computing by Using SDNNFV on 5G Edge N.pdf:application/pdf}
}
@inproceedings{bermbach_towards_2021,
	title        = {Towards grassroots peering at the edge},
	author       = {Bermbach, David and Lucia, Sergio and Handziski, Vlado and Wolisz, Adam},
	booktitle    = {Proceedings of the 8th International Workshop on Middleware and Applications for the Internet of Things},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {M4IoT '21},
	pages        = {14--17},
	doi          = {10.1145/3493369.3493602},
	isbn         = {978-1-4503-9167-2},
	url          = {https://doi.org/10.1145/3493369.3493602},
	urldate      = {2022-01-12},
	abstract     = {Fog Computing allows applications to address their latency and privacy requirements while coping with bandwidth limitations of Internet service providers ({ISPs}). Existing research on fog systems has so far mostly taken a very high-level view on the actual fog infrastructure. In this position paper, we identify and discuss the problem of having multiple {ISPs} in edge-to-edge communication. As a possible solution we propose that edge operators create direct edge-to-edge links in a grassroots fashion and discuss different implementation options. Based on this, we highlight some important open research challenges that result from this.},
	date         = {2021-12-06},
	keywords     = {fog computing, edge computing, network peering}
}
@report{milgrom_redesigning_2017,
	title        = {Redesigning Spectrum Licenses to Encourage Innovation and Investment},
	author       = {Milgrom, Paul R. and Weyl, E. Glen and Zhang, Anthony Lee},
	location     = {Rochester, {NY}},
	volume       = 40,
	number       = {{ID} 3015929},
	pages        = 22,
	url          = {https://papers.ssrn.com/abstract=3015929},
	urldate      = {2022-01-12},
	abstract     = {Commercial radio spectrum use rights in the {US} are traditionally assigned using licenses over large geographic areas with 10- or 15-year terms, to encourage infrastructure investment. However, such long-term licenses are difficult to reassign as more valuable uses for spectrum arise. Licenses with shorter term limits over smaller areas expedite reassignment of spectrum to innovative entrants, but provide lower incentives for long-term investment. Recent economic theory suggests that this trade-off between protecting long-term investments and enabling valuable, innovative entry can be muted by a new, more efficient ``depreciating'' license. A promising application is to priority access in the 3.5GHz band, where thousands of licenses are about to be auctioned. Alternatively, carefully redesigning auction rules may offer similar benefits.},
	institution  = {Social Science Research Network},
	type         = {{SSRN} Scholarly Paper},
	date         = {2017-08-07},
	langid       = {english},
	keywords     = {3.5GHz, depreciating license, priority access licenses},
	file         = {Milgrom et al\_2017\_Redesigning Spectrum Licenses to Encourage Innovation and Investment.pdf:/home/volodia/Zotero/storage/IIW5XEHX/Milgrom et al\_2017\_Redesigning Spectrum Licenses to Encourage Innovation and Investment.pdf:application/pdf;Snapshot:/home/volodia/Zotero/storage/K766UPE5/papers.html:text/html},
	journaltitle = {Regulation},
	shortjournal = {Regulation}
}
@online{rausch_cognitivexr_2020,
	title        = {{CognitiveXR}},
	author       = {Rausch, Thomas and Kr\"{o}sl, Katharina},
	url          = {https://cognitivexr.at/},
	urldate      = {2022-01-11},
	date         = 2020,
	langid       = {english}
}
@online{noauthor_cognitive_nodate,
	title        = {Cognitive {XR}},
	url          = {https://cognitivexr.at/},
	urldate      = {2022-01-11},
	file         = {Cognitive XR:/home/volodia/Zotero/storage/QQ24TVDC/cognitivexr.at.html:text/html}
}
@inproceedings{rausch_towards_2021,
	title        = {Towards a Platform for Smart City-Scale Cognitive Assistance Applications},
	author       = {Rausch, Thomas and Hummer, Waldemar and Stippel, Christian and Vasiljevic, Silvio and Elvezio, Carmine and Dustdar, Schahram and Krosl, Katharina},
	booktitle    = {2021 {IEEE} Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops ({VRW})},
	location     = {Lisbon, Portugal},
	publisher    = {{IEEE}},
	pages        = {330--335},
	doi          = {10.1109/VRW52623.2021.00066},
	isbn         = {978-1-66544-057-8},
	url          = {https://ieeexplore.ieee.org/document/9419192/},
	urldate      = {2022-01-11},
	abstract     = {This position paper describes {CognitiveAR}, a system that seamlessly interfaces {AR} devices with smart city environments. Edge computing nodes distributed throughout the city enable multi-user cognitive assistance applications that require (1) real-time sensor data from the environment, such as approaching cars, and (2) computing resources for low-latency video processing. We discuss three such applications to elicit requirements for a platform to support them, and present our system design.},
	eventtitle   = {2021 {IEEE} Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops ({VRW})},
	date         = {2021-03},
	langid       = {english},
	file         = {Rausch et al\_2021\_Towards a Platform for Smart City-Scale Cognitive Assistance Applications.pdf:/home/volodia/Zotero/storage/F83GRYRK/Rausch et al\_2021\_Towards a Platform for Smart City-Scale Cognitive Assistance Applications.pdf:application/pdf;Rausch et al. - 2021 - Towards a Platform for Smart City-Scale Cognitive .pdf:/home/volodia/Zotero/storage/ND8HF5HK/Rausch et al. - 2021 - Towards a Platform for Smart City-Scale Cognitive .pdf:application/pdf}
}
@inproceedings{deyannis_enabling_2018,
	title        = {Enabling {GPU}-assisted Antivirus Protection on Android Devices through Edge Offloading},
	author       = {Deyannis, Dimitris and Tsirbas, Rafail and Vasiliadis, Giorgos and Montella, Raffaele and Kosta, Sokol and Ioannidis, Sotiris},
	booktitle    = {Proceedings of the 1st International Workshop on Edge Systems, Analytics and Networking},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{EdgeSys}'18},
	pages        = {13--18},
	doi          = {10.1145/3213344.3213347},
	isbn         = {978-1-4503-5837-8},
	url          = {https://doi.org/10.1145/3213344.3213347},
	urldate      = {2022-01-11},
	abstract     = {Antivirus software are the most popular tools for detecting and stopping malicious or unwanted files. However, the performance requirements of traditional host-based antivirus make their wide adoption to mobile, embedded, and hand-held devices questionable. Their computational- and memory-intensive characteristics, which are needed to cope with the evolved and sophisticated malware, makes their deployment to mobile processors a hard task. Moreover, their increasing complexity may result in vulnerabilities that can be exploited by malware. In this paper, we first describe a {GPU}-based antivirus algorithm for Android devices. Then, due to the limited number of {GPU}-enabled Android devices, we present different architecture designs that exploit code offloading for running the antivirus on more powerful machines. This approach enables lower execution and memory overheads, better performance, and improved deployability and management. We evaluate the performance, scalability, and efficacy of the system in several different scenarios and setups. We show that the time to detect a malware is 8.4 times lower than the typical local execution approach.},
	date         = {2018-06-10},
	keywords     = {Edge Computing, Android, {CUDA}, {GPGPU}, Malware Detection, Mobile, Offloading},
	file         = {Deyannis et al\_2018\_Enabling GPU-assisted Antivirus Protection on Android Devices through Edge.pdf:/home/volodia/Zotero/storage/T9GLEE6T/Deyannis et al\_2018\_Enabling GPU-assisted Antivirus Protection on Android Devices through Edge.pdf:application/pdf}
}
@online{noauthor_swamp_nodate,
	title        = {{SWAMP} – Smart Water Management Platform},
	url          = {https://swamp-project.org/},
	urldate      = {2022-01-11},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/NZB28N92/swamp-project.org.html:text/html}
}
@inproceedings{chen_design_2018,
	title        = {Design and implementation of a power consumption management system for smart home over fog-cloud computing},
	author       = {Chen, Yan-Da and Azhari, Muhammad Zulfan and Leu, Jenq-Shiou},
	booktitle    = {2018 3rd International Conference on Intelligent Green Building and Smart Grid ({IGBSG})},
	pages        = {1--5},
	doi          = {10.1109/IGBSG.2018.8393553},
	abstract     = {Smart home becomes a part of the trend in a vast Internet of Things ({IoT}) field. However, according to International Data Corporation, {IDC}, every house generated 2 {TB} amount of data on average by 2014, and this number is estimated to rise up to 10 {TB} by 2020. With a huge amount of data, cloud-only architecture could not keep up with the volume and velocity of this data across the network. Therefore, we provide the reference architecture for smart home which is based on fog computing using Zigbee protocol. We can treat fog computing as the extension of the cloud. It can ease a load of cloud, improve its performance and efficiency, and also provide real-time calculating service. Furthermore, the cloud can provide insight and configuration to fog computing architecture to enhance the home-automated function and optimize system intelligent. Our approach can effectively address the data amount issues and reduce the response latency to secure the safety for the family member in real-time processing needed situation, and monitor the usage of electricity for each member to implement the home energy management system. Each home fog network can communicate with each other and become a bigger architecture for the smart city in the future.},
	eventtitle   = {2018 3rd International Conference on Intelligent Green Building and Smart Grid ({IGBSG})},
	date         = {2018-04},
	keywords     = {Cloud computing, Computer architecture, Edge computing, {IoT}, Peer-to-peer computing, Protocols, Fog computing, Smart homes, Smart city, Smart home, Zigbee, {ZigBee}},
	file         = {Chen et al\_2018\_Design and implementation of a power consumption management system for smart.pdf:/home/volodia/Zotero/storage/GEDFXLSE/Chen et al\_2018\_Design and implementation of a power consumption management system for smart.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/ELM5PCQ4/8393553.html:text/html;Chen et al\_2018\_Design and implementation of a power consumption management system for smart.pdf:/home/volodia/Zotero/storage/ZQVPQFBY/Chen et al\_2018\_Design and implementation of a power consumption management system for smart.pdf:application/pdf}
}
@misc{openfog_consortium_real-time_2018,
	title        = {Real-time subsurface imaging},
	author       = {{OpenFog Consortium}},
	url          = {http://www.fogguru.eu/tmp/OpenFog-Use-Cases.zip},
	date         = 2018
}
@misc{openfog_consortium_process_2018,
	title        = {Process manufacturing for beverage industry},
	author       = {{OpenFog Consortium}},
	url          = {http://www.fogguru.eu/tmp/OpenFog-Use-Cases.zip},
	date         = 2018
}
@misc{openfog_consortium_out_2018,
	title        = {Out of the fog: Use case scenar- ios (high-scale drone package delivery)},
	author       = {{OpenFog Consortium}},
	url          = {http://www.fogguru.eu/tmp/OpenFog-Use-Cases.zip},
	date         = 2018
}
@article{lin_cloudfog_2017,
	title        = {{CloudFog}: Leveraging Fog to Extend Cloud Gaming for Thin-Client {MMOG} with High Quality of Service},
	shorttitle   = {{CloudFog}},
	author       = {Lin, Yuhua and Shen, Haiying},
	volume       = 28,
	number       = 2,
	pages        = {431--445},
	doi          = {10.1109/TPDS.2016.2563428},
	issn         = {1558-2183},
	note         = {Conference Name: {IEEE} Transactions on Parallel and Distributed Systems},
	abstract     = {With the increasing popularity of Massively Multiplayer Online Game ({MMOG}) and fast growth of mobile gaming, cloud gaming exhibits great promises over the conventional {MMOG} gaming model as it frees players from the requirement of hardware and game installation on their local computers. However, as the graphics rendering is offloaded to the cloud, the data transmission between the end-users and the cloud significantly increases the response latency and limits the user coverage, thus preventing cloud gaming to achieve high user Quality of Service ({QoS}). To solve this problem, previous research suggested deploying more datacenters, but it comes at a prohibitive cost. We propose a lightweight system called {CloudFog}, which incorporates ``fog'' consisting of supernodes that are responsible for rendering game videos and streaming them to their nearby players. Fog enables the cloud to be only responsible for the intensive game state computation and sending update information to supernodes, which significantly reduce the traffic hence the latency and bandwidth consumption. To further enhance {QoS}, we propose the reputation based supernode selection strategy to assign each player with a suitable supernode that can provide satisfactory game video streaming service, the receiver-driven encoding rate adaptation strategy to increase the playback continuity, the social network based server assignment strategy to avoid the communication interaction between servers in a datacenter to reduce latency, and the dynamic supernode provisioning strategy to deal with user churns. Experimental results from {PeerSim} and {PlanetLab} show the effectiveness and efficiency of {CloudFog} and our individual strategies in increasing user coverage, reducing response latency and bandwidth consumption.},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	date         = {2017-02},
	keywords     = {Servers, Quality of service, Bandwidth, Cloud gaming, online gaming, P2P network, quality of service, Videos},
	file         = {Lin\_Shen\_2017\_CloudFog.pdf:/home/volodia/Zotero/storage/ST4K4GBF/Lin\_Shen\_2017\_CloudFog.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/XDKFJUEL/7465785.html:text/html;Lin\_Shen\_2017\_CloudFog.pdf:/home/volodia/Zotero/storage/DCH87J3N/Lin\_Shen\_2017\_CloudFog.pdf:application/pdf}
}
@article{ma_understanding_2017,
	title        = {Understanding Performance of Edge Content Caching for Mobile Video Streaming},
	author       = {Ma, Ge and Wang, Zhi and Zhang, Miao and Ye, Jiahui and Chen, Minghua and Zhu, Wenwu},
	volume       = 35,
	number       = 5,
	pages        = {1076--1089},
	doi          = {10.1109/JSAC.2017.2680958},
	issn         = {1558-0008},
	note         = {Conference Name: {IEEE} Journal on Selected Areas in Communications},
	abstract     = {Today's Internet has witnessed an increase in the popularity of mobile video streaming, which is expected to exceed 3/4 of the global mobile data traffic by 2019. To satisfy the considerable amount of mobile video requests, video service providers have been pushing their content delivery infrastructure to edge networks-from regional content delivery network ({CDN}) servers to peer {CDN} servers (e.g., smartrouters in users' homes)-to cache content and serve users with storage and network resources nearby. Among the edge network content caching paradigms, Wi-Fi access point caching and cellular base station caching have become two mainstream solutions. Thus, understanding the effectiveness and performance of these solutions for large-scale mobile video delivery is important. However, the characteristics and request patterns of mobile video streaming are unclear in practical wireless network. In this paper, we use real-world data sets containing 50 million trace items of nearly 2 million users viewing more than 0.3 million unique videos using mobile devices in a metropolis in China over two weeks, not only to understand the request patterns and user behaviors in mobile video streaming, but also to evaluate the effectiveness of Wi-Fi and cellular-based edge content caching solutions. To understand the performance of edge content caching for mobile video streaming, we first present temporal and spatial video request patterns, and we analyze their impacts on caching performance using frequency-domain and entropy analysis approaches. We then study the behaviors of mobile video users, including their mobility and geographical migration behaviors, which determine the request patterns. Using trace-driven experiments, we compare strategies for edge content caching, including least recently used ({LRU}) and least frequently used ({LFU}), in terms of supporting mobile video requests. We reveal that content, location, and mobility factors all affect edge content caching performance. Moreover, we design an efficient caching strategy based on the measurement insights and experimentally evaluate its performance. The results show that our design significantly improves the cache hit rate by up to 30\% compared with {LRU}/{LFU}.},
	journaltitle = {{IEEE} Journal on Selected Areas in Communications},
	date         = {2017-05},
	keywords     = {Edge network, Streaming media, Mobile handsets, Base stations, content delivery, measurement, Mobile communication, Mobile computing, mobile video streaming, user behavior, Wireless fidelity, Wireless networks},
	file         = {Ma et al\_2017\_Understanding Performance of Edge Content Caching for Mobile Video Streaming.pdf:/home/volodia/Zotero/storage/RUEFQSV7/Ma et al\_2017\_Understanding Performance of Edge Content Caching for Mobile Video Streaming.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/BZJ5BV2F/7875170.html:text/html;Ma et al\_2017\_Understanding Performance of Edge Content Caching for Mobile Video Streaming.pdf:/home/volodia/Zotero/storage/GUVR7R29/Ma et al\_2017\_Understanding Performance of Edge Content Caching for Mobile Video Streaming.pdf:application/pdf}
}
@article{hu_survey_2017,
	title        = {Survey on fog computing: architecture, key technologies, applications and open issues},
	shorttitle   = {Survey on fog computing},
	author       = {Hu, Pengfei and Dhelim, Sahraoui and Ning, Huansheng and Qiu, Tie},
	volume       = 98,
	pages        = {27--42},
	doi          = {10.1016/j.jnca.2017.09.002},
	issn         = {1084-8045},
	url          = {https://www.sciencedirect.com/science/article/pii/S1084804517302953},
	urldate      = {2022-01-11},
	abstract     = {The emergence of Internet of Things ({IoT}) has enabled the interconnection and intercommunication among massive ubiquitous things, which caused an unprecedented generation of huge and heterogeneous amount of data, known as data explosions. On the other hand, although that cloud computing has served as an efficient way to process and store these data, however, challenges, such as the increasing demands of real time or latency-sensitive applications and the limitation of network bandwidth, still cannot be solved by using only cloud computing. Therefore, a new computing paradigm, known as fog computing, has been proposed as a complement to the cloud solution. Fog computing extends the cloud services to the edge of network, and makes computation, communication and storage closer to edge devices and end-users, which aims to enhance low-latency, mobility, network bandwidth, security and privacy. In this paper, we will overview and summarize fog computing model architecture, key technologies, applications, challenges and open issues. Firstly, we will present the hierarchical architecture of fog computing and its characteristics, and compare it with cloud computing and edge computing to emphasize the similarities and differences. Then, the key technologies like computing, communication and storage technologies, naming, resource management, security and privacy protection are introduced to present how to support its deployment and application in a detailed manner. Several application cases like health care, augmented reality, brain machine interface and gaming, smart environments and vehicular fog computing are also presented to further explain fog computing application scenarios. Finally, based on the observation, we propose some challenges and open issues which are worth further in-depth study and research in fog computing development.},
	journaltitle = {Journal of Network and Computer Applications},
	shortjournal = {Journal of Network and Computer Applications},
	date         = {2017-11-15},
	langid       = {english},
	keywords     = {Cloud computing, Edge computing, Fog computing, Application, Architecture, Internet of Things({IoT})},
	file         = {Hu et al\_2017\_Survey on fog computing.pdf:/home/volodia/Zotero/storage/2IML4YUL/Hu et al\_2017\_Survey on fog computing.pdf:application/pdf;ScienceDirect Snapshot:/home/volodia/Zotero/storage/NWX94CRR/S1084804517302953.html:text/html}
}
@inproceedings{hu_live_2017,
	title        = {Live Synthesis of Vehicle-Sourced Data Over 4G {LTE}},
	author       = {Hu, Wenlu and Feng, Ziqiang and Chen, Zhuo and Harkes, Jan and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
	booktitle    = {Proceedings of the 20th {ACM} International Conference on Modelling, Analysis and Simulation of Wireless and Mobile Systems},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{MSWiM} '17},
	pages        = {161--170},
	doi          = {10.1145/3127540.3127543},
	isbn         = {978-1-4503-5162-1},
	url          = {https://doi.org/10.1145/3127540.3127543},
	urldate      = {2022-01-11},
	abstract     = {Accurate, up-to-date maps of transient traffic and hazards are invaluable to drivers, city managers, and the emerging class of self-driving vehicles. We present {LiveMap}, a scalable, automated system for acquiring, curating, and disseminating detailed, continually-updated road conditions in a region. {LiveMap} leverages in-vehicle cameras, sensors, and processors to crowd-source hazard detection without human intervention. We build a real-time simulation framework that allows a mix of real and simulated components to be tested together at scale. We demonstrate that {LiveMap} can work well at city scales within the limits of today's cellular network bandwidth. We also show the feasibility of accurate, in-vehicle, computer-vision-based hazard detection.},
	date         = {2017-11-21},
	keywords     = {cloud computing, edge computing, automotive systems, cloudlet, driverless cars, maps, situational awareness, vehicular systems},
	file         = {Hu et al\_2017\_Live Synthesis of Vehicle-Sourced Data Over 4G LTE.pdf:/home/volodia/Zotero/storage/N2MDQJKV/Hu et al\_2017\_Live Synthesis of Vehicle-Sourced Data Over 4G LTE.pdf:application/pdf;Hu et al\_2017\_Live Synthesis of Vehicle-Sourced Data Over 4G LTE.pdf:/home/volodia/Zotero/storage/SRQA5HBD/Hu et al\_2017\_Live Synthesis of Vehicle-Sourced Data Over 4G LTE.pdf:application/pdf}
}
@article{ai_edge_2018,
	title        = {Edge computing technologies for Internet of Things: a primer},
	shorttitle   = {Edge computing technologies for Internet of Things},
	author       = {Ai, Yuan and Peng, Mugen and Zhang, Kecheng},
	volume       = 4,
	number       = 2,
	pages        = {77--86},
	doi          = {10.1016/j.dcan.2017.07.001},
	issn         = {2352-8648},
	url          = {https://www.sciencedirect.com/science/article/pii/S2352864817301335},
	urldate      = {2022-01-10},
	abstract     = {With the rapid development of mobile internet and Internet of Things applications, the conventional centralized cloud computing is encountering severe challenges, such as high latency, low Spectral Efficiency ({SE}), and non-adaptive machine type of communication. Motivated to solve these challenges, a new technology is driving a trend that shifts the function of centralized cloud computing to edge devices of networks. Several edge computing technologies originating from different backgrounds to decrease latency, improve {SE}, and support the massive machine type of communication have been emerging. This paper comprehensively presents a tutorial on three typical edge computing technologies, namely mobile edge computing, cloudlets, and fog computing. In particular, the standardization efforts, principles, architectures, and applications of these three technologies are summarized and compared. From the viewpoint of radio access network, the differences between mobile edge computing and fog computing are highlighted, and the characteristics of fog computing-based radio access network are discussed. Finally, open issues and future research directions are identified as well.},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	date         = {2018-04-01},
	langid       = {english},
	keywords     = {Fog computing, Internet of Things ({IoT}), Mobile edge computing, Cloudlets},
	file         = {Ai et al\_2018\_Edge computing technologies for Internet of Things.pdf:/home/volodia/Zotero/storage/TJHE65CD/Ai et al\_2018\_Edge computing technologies for Internet of Things.pdf:application/pdf;Full Text PDF:/home/volodia/Zotero/storage/KBV968TK/Edge computing technologies for Internet of Things.pdf:application/pdf;ScienceDirect Snapshot:/home/volodia/Zotero/storage/A6YDB3IL/S2352864817301335.html:text/html;Ai et al\_2018\_Edge computing technologies for Internet of Things.pdf:/home/volodia/Zotero/storage/YL2J84QY/Ai et al\_2018\_Edge computing technologies for Internet of Things.pdf:application/pdf}
}
@online{redhat_what_2019,
	title        = {What is {NFV}?},
	author       = {{Redhat}},
	url          = {https://www.redhat.com/en/topics/virtualization/what-is-nfv},
	urldate      = {2022-01-08},
	abstract     = {Network functions virtualization ({NFV}) is a way to virtualize network services that have traditionally been run on proprietary hardware.},
	date         = {2019-08},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/E7G7YYC5/what-is-nfv.html:text/html}
}
@online{dahmen-lhuissier_etsi_nodate,
	title        = {{ETSI} - Our group on Multi-access Edge Computing ({MEC})},
	author       = {Dahmen-Lhuissier, Sabine},
	url          = {https://www.etsi.org/committee/1425-mec},
	urldate      = {2022-01-08},
	abstract     = {Multi-access Edge Computing ({MEC}) {ISG}},
	titleaddon   = {{ETSI}},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/8VRA2M3B/1425-mec.html:text/html}
}
@online{dahmen-lhuissier_etsi_nodate-1,
	title        = {{ETSI} - Multi-access Edge Computing - Standards for {MEC}},
	author       = {Dahmen-Lhuissier, Sabine},
	url          = {https://www.etsi.org/technologies/multi-access-edge-computing},
	urldate      = {2022-01-08},
	abstract     = {The Multi-access Edge Computing ({MEC}) initiative is an Industry Specification Group ({ISG}) within {ETSI}. The purpose of the {ISG} is to create a standardized, open environment which will allow the efficient and seamless integration of applications from vendors, service providers, and third-parties across multi-vendor Multi-access Edge Computing platforms.},
	titleaddon   = {{ETSI}},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/P3ILTTWS/multi-access-edge-computing.html:text/html}
}
@article{satyanarayanan_case_2009,
	title        = {The Case for {VM}-Based Cloudlets in Mobile Computing},
	author       = {Satyanarayanan, Mahadev and Bahl, Paramvir and Caceres, Ramon and Davies, Nigel},
	volume       = 8,
	number       = 4,
	pages        = {14--23},
	doi          = {10.1109/MPRV.2009.82},
	issn         = {1558-2590},
	note         = {Conference Name: {IEEE} Pervasive Computing},
	abstract     = {Mobile computing continuously evolve through the sustained effort of many researchers. It seamlessly augments users' cognitive abilities via compute-intensive capabilities such as speech recognition, natural language processing, etc. By thus empowering mobile users, we could transform many areas of human activity. This article discusses the technical obstacles to these transformations and proposes a new architecture for overcoming them. In this architecture, a mobile user exploits virtual machine ({VM}) technology to rapidly instantiate customized service software on a nearby cloudlet and then uses that service over a wireless {LAN}; the mobile device typically functions as a thin client with respect to the service. A cloudlet is a trusted, resource-rich computer or cluster of computers that's well-connected to the Internet and available for use by nearby mobile devices. Our strategy of leveraging transiently customized proximate infrastructure as a mobile device moves with its user through the physical world is called cloudlet-based, resource-rich, mobile computing. Crisp interactive response, which is essential for seamless augmentation of human cognition, is easily achieved in this architecture because of the cloudlet's physical proximity and one-hop network latency. Using a cloudlet also simplifies the challenge of meeting the peak bandwidth demand of multiple users interactively generating and receiving media such as high-definition video and high-resolution images. Rapid customization of infrastructure for diverse applications emerges as a critical requirement, and our results from a proof-of-concept prototype suggest that {VM} technology can indeed help meet this requirement.},
	journaltitle = {{IEEE} Pervasive Computing},
	date         = {2009-10},
	keywords     = {Cloud computing, Computer architecture, Mobile computing, augmented reality, cognitive augmentation, cyber foraging, dynamic {VM} synthesis, Humans, Internet, Natural language processing, resource constraints, Speech recognition, virtual machines, Virtual machining, Virtual manufacturing, Wireless {LAN}},
	file         = {Satyanarayanan et al\_2009\_The Case for VM-Based Cloudlets in Mobile Computing.pdf:/home/volodia/Zotero/storage/S9JVKIHP/Satyanarayanan et al\_2009\_The Case for VM-Based Cloudlets in Mobile Computing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/LTJYKAPY/5280678.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/W9J5G99V/Satyanarayanan et al. - 2009 - The Case for VM-Based Cloudlets in Mobile Computin.pdf:application/pdf}
}
@inproceedings{bonomi_fog_2012,
	title        = {Fog computing and its role in the internet of things},
	author       = {Bonomi, Flavio and Milito, Rodolfo and Zhu, Jiang and Addepalli, Sateesh},
	booktitle    = {Proceedings of the first edition of the {MCC} workshop on Mobile cloud computing},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{MCC} '12},
	pages        = {13--16},
	doi          = {10.1145/2342509.2342513},
	isbn         = {978-1-4503-1519-7},
	url          = {https://doi.org/10.1145/2342509.2342513},
	urldate      = {2022-01-08},
	abstract     = {Fog Computing extends the Cloud Computing paradigm to the edge of the network, thus enabling a new breed of applications and services. Defining characteristics of the Fog are: a) Low latency and location awareness; b) Wide-spread geographical distribution; c) Mobility; d) Very large number of nodes, e) Predominant role of wireless access, f) Strong presence of streaming and real time applications, g) Heterogeneity. In this paper we argue that the above characteristics make the Fog the appropriate platform for a number of critical Internet of Things ({IoT}) services and applications, namely, Connected Vehicle, Smart Grid, Smart Cities, and, in general, Wireless Sensors and Actuators Networks ({WSANs}).},
	date         = {2012-08-17},
	keywords     = {analytics, iot, fog computing, cloud computing, real time systems, software defined networks, wsan},
	file         = {Bonomi et al\_2012\_Fog computing and its role in the internet of things.pdf:/home/volodia/Zotero/storage/KN2TIAB3/Bonomi et al\_2012\_Fog computing and its role in the internet of things.pdf:application/pdf;Full Text PDF:/home/volodia/Zotero/storage/NB88DGX6/Bonomi et al. - 2012 - Fog computing and its role in the internet of thin.pdf:application/pdf}
}
@article{chiang_fog_2016,
	title        = {Fog and {IoT}: An Overview of Research Opportunities},
	shorttitle   = {Fog and {IoT}},
	author       = {Chiang, Mung and Zhang, Tao},
	volume       = 3,
	number       = 6,
	pages        = {854--864},
	doi          = {10.1109/JIOT.2016.2584538},
	issn         = {2327-4662},
	note         = {Conference Name: {IEEE} Internet of Things Journal},
	abstract     = {Fog is an emergent architecture for computing, storage, control, and networking that distributes these services closer to end users along the cloud-to-things continuum. It covers both mobile and wireline scenarios, traverses across hardware and software, resides on network edge but also over access networks and among end users, and includes both data plane and control plane. As an architecture, it supports a growing variety of applications, including those in the Internet of Things ({IoT}), fifth-generation (5G) wireless systems, and embedded artificial intelligence ({AI}). This survey paper summarizes the opportunities and challenges of fog, focusing primarily in the networking context of {IoT}.},
	journaltitle = {{IEEE} Internet of Things Journal},
	date         = {2016-12},
	keywords     = {fog, Cloud computing, Computer architecture, Edge computing, fog computing, Hardware, Security, Internet of things, Internet of Things ({IoT}), edge networking, edge storage, fog control, fog networking, fog storage},
	file         = {Chiang\_Zhang\_2016\_Fog and IoT.pdf:/home/volodia/Zotero/storage/37PA7PUC/Chiang\_Zhang\_2016\_Fog and IoT.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/LD7WGAKM/7498684.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/KY7BQD4Y/Chiang and Zhang - 2016 - Fog and IoT An Overview of Research Opportunities.pdf:application/pdf}
}
@software{noauthor_api_2022,
	title        = {The {API} Traffic Viewer for Kubernetes},
	publisher    = {{UP}9},
	url          = {https://github.com/up9inc/mizu},
	urldate      = {2022-01-08},
	note         = {original-date: 2021-04-19T10:29:56Z},
	rights       = {Apache-2.0},
	abstract     = {{API} traffic viewer for Kubernetes enabling you to view all {API} communication between microservices. Think {TCPDump} and Wireshark re-invented for Kubernetes},
	date         = {2022-01-08},
	keywords     = {devops, kubernetes, microservice, containers, amqp, cloudnative-services, devops-tools, go, golang, grpc, kafka, microservices, microservices-application, mizu, redis, rest, traffic-viewer, visibility}
}
@article{frost_smart_2017,
	title        = {Smart Cities Deserve an Easier Task! Standards Will Help.},
	author       = {Frost, Lindsay},
	pages        = 20,
	journaltitle = {News from {ETSI}},
	date         = 2017,
	langid       = {english},
	file         = {Frost - Smart Cities Deserve an Easier Task! Standards Wil.pdf:/home/volodia/Zotero/storage/RPUZ96NX/Frost - Smart Cities Deserve an Easier Task! Standards Wil.pdf:application/pdf}
}
@inproceedings{dolui_comparison_2017,
	title        = {Comparison of edge computing implementations: Fog computing, cloudlet and mobile edge computing},
	shorttitle   = {Comparison of edge computing implementations},
	author       = {Dolui, Koustabh and Datta, Soumya Kanti},
	booktitle    = {2017 Global Internet of Things Summit ({GIoTS})},
	pages        = {1--6},
	doi          = {10.1109/GIOTS.2017.8016213},
	abstract     = {When it comes to storage and computation of large scales of data, Cloud Computing has acted as the de-facto solution over the past decade. However, with the massive growth in intelligent and mobile devices coupled with technologies like Internet of Things ({IoT}), V2X Communications, Augmented Reality ({AR}), the focus has shifted towards gaining real-time responses along with support for context-awareness and mobility. Due to the delays induced on the Wide Area Network ({WAN}) and location agnostic provisioning of resources on the cloud, there is a need to bring the features of the cloud closer to the consumer devices. This led to the birth of the Edge Computing paradigm which aims to provide context aware storage and distributed Computing at the edge of the networks. In this paper, we discuss the three different implementations of Edge Computing namely Fog Computing, Cloudlet and Mobile Edge Computing in detail and compare their features. We define a set of parameters based on which one of these implementations can be chosen optimally given a particular use-case or application and present a decision tree for the selection of the optimal implementation.},
	eventtitle   = {2017 Global Internet of Things Summit ({GIoTS})},
	date         = {2017-06},
	keywords     = {Cloud computing, Cloud Computing, Computer architecture, Edge computing, Edge Computing, Fog Computing, {IoT}, Real-time systems, Cloudlet, Mobile Edge Computing, Mobile radio mobility management, Performance evaluation},
	file         = {Dolui\_Datta\_2017\_Comparison of edge computing implementations.pdf:/home/volodia/Zotero/storage/H63N6KFS/Dolui\_Datta\_2017\_Comparison of edge computing implementations.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/8MGKC58Z/8016213.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/TL5DTHST/Dolui and Datta - 2017 - Comparison of edge computing implementations Fog .pdf:application/pdf}
}
@article{ren_survey_2019,
	title        = {A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms: Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet},
	shorttitle   = {A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms},
	author       = {Ren, Ju and Zhang, Deyu and He, Shiwen and Zhang, Yaoxue and Li, Tao},
	volume       = 52,
	number       = 6,
	pages        = {125:1--125:36},
	doi          = {10.1145/3362031},
	issn         = {0360-0300},
	url          = {https://doi.org/10.1145/3362031},
	urldate      = {2022-01-07},
	abstract     = {Sending data to the cloud for analysis was a prominent trend during the past decades, driving cloud computing as a dominant computing paradigm. However, the dramatically increasing number of devices and data traffic in the Internet-of-Things ({IoT}) era are posing significant burdens on the capacity-limited Internet and uncontrollable service delay. It becomes difficult to meet the delay-sensitive and context-aware service requirements of {IoT} applications by using cloud computing alone. Facing these challenges, computing paradigms are shifting from the centralized cloud computing to distributed edge computing. Several new computing paradigms, including Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet, have emerged to leverage the distributed resources at network edge to provide timely and context-aware services. By integrating end devices, edge servers, and cloud, they form a hierarchical {IoT} architecture, i.e., End-Edge-Cloud orchestrated architecture to improve the performance of {IoT} systems. This article presents a comprehensive survey of these emerging computing paradigms from the perspective of end-edge-cloud orchestration. Specifically, we first introduce and compare the architectures and characteristics of different computing paradigms. Then, a comprehensive survey is presented to discuss state-of-the-art research in terms of computation offloading, caching, security, and privacy. Finally, some potential research directions are envisioned for fostering continuous research efforts.},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	date         = {2019-10-16},
	keywords     = {fog computing, cloudlet, End-edge-cloud orchestration, mobile edge computing, network computing, transparent computing},
	file         = {Ren et al\_2019\_A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms.pdf:/home/volodia/Zotero/storage/9BE3JEWW/Ren et al\_2019\_A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms.pdf:application/pdf}
}
@incollection{baldini_serverless_2017,
	title        = {Serverless Computing: Current Trends and Open Problems},
	shorttitle   = {Serverless Computing},
	author       = {Baldini, Ioana and Castro, Paul and Chang, Kerry and Cheng, Perry and Fink, Stephen and Ishakian, Vatche and Mitchell, Nick and Muthusamy, Vinod and Rabbah, Rodric and Slominski, Aleksander and Suter, Philippe},
	booktitle    = {Research Advances in Cloud Computing},
	location     = {Singapore},
	publisher    = {Springer},
	pages        = {1--20},
	doi          = {10.1007/978-981-10-5026-8\_1},
	isbn         = {978-981-10-5026-8},
	url          = {https://doi.org/10.1007/978-981-10-5026-8\%5F1},
	urldate      = {2022-01-18},
	abstract     = {Serverless computing has emerged as a new compelling paradigm for the deployment of applications and services. It represents an evolution of cloud programming models, abstractions, and platforms, and is a testament to the maturity and wide adoption of cloud technologies. In this chapter, we survey existing serverless platforms from industry, academia, and open-source projects, identify key characteristics and use cases, and describe technical challenges and open problems.},
	editor       = {Chaudhary, Sanjay and Somani, Gaurav and Buyya, Rajkumar},
	date         = 2017,
	langid       = {english},
	file         = {Baldini et al\_2017\_Serverless Computing.pdf:/home/volodia/Zotero/storage/6L4RJ5XR/Baldini et al\_2017\_Serverless Computing.pdf:application/pdf}
}
@online{redhat_what_2020,
	title        = {What is {FaaS}?},
	author       = {{RedHat}},
	url          = {https://www.redhat.com/en/topics/cloud-native-apps/what-is-faas},
	urldate      = {2022-01-18},
	abstract     = {{FaaS} is a kind of cloud computing service that allows developers to build, run, and manage application packages as functions without maintaining the infrastructure.},
	date         = {2020-01-03},
	langid       = {english}
}
@online{ibm_faas_2019,
	title        = {faas},
	author       = {{IBM}},
	url          = {https://www.ibm.com/cloud/learn/faas},
	urldate      = {2022-01-18},
	abstract     = {An introduction to {FaaS}--a cloud computing service that makes it easier for cloud application developers to run and manage microservices applications.},
	date         = {2019-07-30},
	langid       = {english}
}
@article{bocci_placing_nodate,
	title        = {Placing {FaaS} in the Fog, Securely},
	author       = {Bocci, Alessandro and Forti, Stefano and Ferrari, Gian-Luigi and Brogi, Antonio},
	pages        = 14,
	abstract     = {Placing {FaaS} applications onto Fog infrastructures is an open problem presenting various challenges. It requires considering hardware and software requirements of single functions as well as Quality of Service requirements of the overall application. In this article, we propose a declarative methodology to address the placement of {FaaS} applications onto Fog infrastructures, supported by a running prototype. Our methodology considers hardware and software requirements, and latency constraints on functionfunction and function-service interactions. Particular attention is given to information flow security constraints and trust relations among the involved stakeholders, to rank eligible output placements. A lifelike motivating example from augmented reality is used to showcase the prototype.},
	langid       = {english},
	file         = {Bocci et al. - Placing FaaS in the Fog, Securely.pdf:/home/volodia/Zotero/storage/ZUJBPD36/Bocci et al. - Placing FaaS in the Fog, Securely.pdf:application/pdf}
}
@software{smartfog_fogflow_2022,
	title        = {{FogFlow}},
	author       = {smartfog},
	url          = {https://github.com/smartfog/fogflow},
	urldate      = {2022-02-09},
	note         = {original-date: 2017-11-14T22:30:18Z},
	rights       = {{BSD}-3-Clause},
	abstract     = {{FogFlow} is a standard-based {IoT} fog computing framework that supports serverless computing and edge computing with advanced programming models},
	date         = {2022-01-24},
	keywords     = {edge-computing, fiware, fog-computing, function-as-a-service, intent-based, iot, ngsi, ngsi-ld, programming-model, serverless-computing, serverless-functions}
}
@software{noauthor_healthfog_2022,
	title        = {{HealthFog}},
	publisher    = {The Cloud Computing and Distributed Systems ({CLOUDS}) Laboratory},
	url          = {https://github.com/Cloudslab/HealthFog},
	urldate      = {2022-02-09},
	note         = {original-date: 2019-06-07T04:38:25Z},
	rights       = {{GPL}-3.0},
	abstract     = {[{FGCS}'20] An ensemble deep learning based smart healthcare system for automatic diagnosis of heart diseases in integrated {IoT} and Fog computing environments},
	date         = {2022-01-17},
	keywords     = {fog-computing, deep-learning, fogbus, healthcare}
}
@online{noauthor_ewall_nodate,
	title        = {{eWALL} Project {EU}},
	url          = {https://github.com/ewallprojecteu},
	urldate      = {2022-02-09},
	abstract     = {{eWALL} is the outcome of a {EC}-funded project that contributes to the prolongation of independent living of various patients types and senior citizens. - {eWALL} Project {EU}},
	titleaddon   = {{GitHub}},
	langid       = {english},
	keywords     = {bancale},
	file         = {Snapshot:/home/volodia/Zotero/storage/F8V6ZR4H/ewallprojecteu.html:text/html}
}
@software{woods_sisyphus_2018,
	title        = {Sisyphus :  A Fog of Serverless Functions},
	shorttitle   = {Sisyphus},
	author       = {Woods, Chris},
	url          = {https://github.com/woodsmc/sisyphus},
	urldate      = {2022-02-09},
	note         = {original-date: 2018-03-22T00:57:03Z},
	rights       = {Apache-2.0},
	abstract     = {Research framework for a Fog of {FaaS}},
	date         = {2018-05-09},
	keywords     = {idea}
}
@software{cicconetti_ccicconettiserverlessonedge_2022,
	title        = {ccicconetti/serverlessonedge},
	author       = {Cicconetti, Claudio},
	url          = {https://github.com/ccicconetti/serverlessonedge},
	urldate      = {2022-02-09},
	note         = {original-date: 2020-02-26T10:13:42Z},
	rights       = {{MIT}},
	abstract     = {Decentralized framework for the distribution of lambda functions to multiple serverless platforms},
	date         = {2022-01-30},
	keywords     = {edge-computing, distributed-computing, serverless-framework}
}
@online{noauthor_how_nodate,
	title        = {How the Actor Model Meets the Needs of Modern, Distributed Systems \textbullet{} Akka Documentation},
	url          = {https://doc.akka.io/docs/akka/current/typed/guide/actors-intro.html?language=scala},
	urldate      = {2022-02-09}
}
@online{noauthor_does_nodate,
	title        = {Does it make sense to use actor/agent oriented programming in Function as a Service environment?},
	url          = {https://stackoverflow.com/questions/46878548/does-it-make-sense-to-use-actor-agent-oriented-programming-in-function-as-a-serv},
	urldate      = {2022-02-09},
	titleaddon   = {Stack Overflow},
	file         = {Snapshot:/home/volodia/Zotero/storage/U6EU2RBD/does-it-make-sense-to-use-actor-agent-oriented-programming-in-function-as-a-serv.html:text/html}
}
@software{bermbach_faas4fogsim_2021,
	title        = {{FaaS}4FogSim},
	author       = {Bermbach, David},
	url          = {https://github.com/dbermbach/faas4fogsim},
	urldate      = {2022-02-09},
	note         = {original-date: 2019-07-30T10:21:29Z},
	rights       = {{GPL}-3.0},
	date         = {2021-05-12}
}
@online{noauthor_developers_2018,
	title        = {Developers Catalogue - {FIWARE}},
	url          = {https://www.fiware.org/developers/catalogue/},
	urldate      = {2022-02-09},
	abstract     = {{FIWARE} brings a curated framework of open source software platform components which can be assembled together and with other third-party components to build},
	date         = {2018-05-07},
	langid       = {american},
	file         = {Snapshot:/home/volodia/Zotero/storage/647W8XBD/catalogue.html:text/html}
}
@article{araujo_performance_2019,
	title        = {Performance evaluation of {FIWARE}: A cloud-based {IoT} platform for smart cities},
	shorttitle   = {Performance evaluation of {FIWARE}},
	author       = {Araujo, Victor and Mitra, Karan and Saguna, Saguna and \AA{}hlund, Christer},
	volume       = 132,
	pages        = {250--261},
	doi          = {10.1016/j.jpdc.2018.12.010},
	issn         = {0743-7315},
	url          = {https://www.sciencedirect.com/science/article/pii/S0743731519300164},
	urldate      = {2022-02-09},
	abstract     = {As the Internet of Things ({IoT}) becomes a reality, millions of devices will be connected to {IoT} platforms in smart cities. These devices will cater to several areas within a smart city such as healthcare, logistics, and transportation. These devices are expected to generate significant amounts of data requests at high data rates, therefore, necessitating the performance benchmarking of {IoT} platforms to ascertain whether they can efficiently handle such devices. In this article, we present our results gathered from extensive performance evaluation of the cloud-based {IoT} platform, {FIWARE}. In particular, to study {FIWARE}'s performance, we developed a testbed and generated {CoAP} and {MQTT} data to emulate large-scale {IoT} deployments, crucial for future smart cities. We performed extensive tests and studied {FIWARE}'s performance regarding vertical and horizontal scalability. We present bottlenecks and limitations regarding {FIWARE} components and their cloud deployment. Finally, we discuss cost-efficient {FIWARE} deployment strategies that can be extremely beneficial to stakeholders aiming to deploy {FIWARE} as an {IoT} platform for smart cities.},
	journaltitle = {Journal of Parallel and Distributed Computing},
	shortjournal = {Journal of Parallel and Distributed Computing},
	date         = {2019-10-01},
	langid       = {english},
	keywords     = {Cloud computing, Benchmarking, Internet of things, Middleware, Quality of service, Smart cities},
	file         = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/LJEI5WI3/S0743731519300164.html:text/html}
}
@online{noauthor_new_nodate,
	title        = {A New Era for Cities with Fog Computing},
	url          = {https://ieeexplore.ieee.org/abstract/document/7867722/},
	urldate      = {2022-02-09},
	abstract     = {In this article, the authors dissect the technical challenges that cities face when implementing smart city plans and outlines the design principles and lessons learned after they carried out a flagship initiative on fog computing in Barcelona. In particular, they analyze what they call the Quadruple Silo ({QS}) problem -- that is, four categories of silos that cities confront after deploying commercially available solutions. Those silo categories are: physical (hardware) silos, data silos, and service management silos, and the implications of the three silos in administrative silos. The authors show how their converged cloud/fog paradigm not only helps solve the {QS} problem, but also meets the requirements of a growing number of decentralized services -- an area in which traditional cloud models fall short. The article exposes cases in which fog computing is a must, and shows that the reasons for deploying fog are centered much more on operational requirements than on performance issues related to the cloud.},
	langid       = {american},
	file         = {Snapshot:/home/volodia/Zotero/storage/3CWXGHKP/7867722.html:text/html}
}
@online{noauthor_smartfog_nodate,
	title        = {smartfog - Overview},
	url          = {https://github.com/smartfog},
	urldate      = {2022-02-09},
	abstract     = {smartfog has 7 repositories available. Follow their code on {GitHub}.},
	titleaddon   = {{GitHub}},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/CYXKE5AG/smartfog.html:text/html}
}
@article{cheng_fogflow_2018,
	title        = {{FogFlow}: Easy Programming of {IoT} Services Over Cloud and Edges for Smart Cities},
	shorttitle   = {{FogFlow}},
	author       = {Cheng, Bin and Solmaz, G\"{u}rkan and Cirillo, Flavio and Kovacs, Ern\"{o} and Terasawa, Kazuyuki and Kitazawa, Atsushi},
	volume       = 5,
	number       = 2,
	pages        = {696--707},
	doi          = {10.1109/JIOT.2017.2747214},
	issn         = {2327-4662},
	note         = {Conference Name: {IEEE} Internet of Things Journal},
	abstract     = {Smart city infrastructure is forming a large scale Internet of Things ({IoT}) system with widely deployed {IoT} devices, such as sensors and actuators that generate a huge volume of data. Given this large scale and geo-distributed nature of such {IoT} systems, fog computing has been considered as an affordable and sustainable computing paradigm to enable smart city {IoT} services. However, it is still a major challenge for developers to program their services to leverage benefits of fog computing. Developers have to figure out many details, such as how to dynamically configure and manage data processing tasks over cloud and edges and how to optimize task allocation for minimal latency and bandwidth consumption. In addition, most of the existing fog computing frameworks either lack service programming models or define a programming model only based on their own private data model and interfaces; therefore, as a smart city platform, they are quite limited in terms of openness and interoperability. To tackle these problems, we propose a standard-based approach to design and implement a new fog computing-based framework, namely {FogFlow}, for {IoT} smart city platforms. {FogFlow}'s programming model allows {IoT} service developers to program elastic {IoT} services easily over cloud and edges. Moreover, it supports standard interfaces to share and reuse contextual data across services. To showcase how smart city use cases can be realized with {FogFlow}, we describe three use cases and implement an example application for anomaly detection of energy consumption in smart cities. We also analyze {FogFlow}'s performance based on microbenchmarking results for message propagation latency, throughput, and scalability.},
	journaltitle = {{IEEE} Internet of Things Journal},
	date         = {2018-04},
	keywords     = {Cloud computing, Edge computing, Smart cities, Computational modeling, Data models, Internet of Things ({IoT}), Logic gates, parallel programming, Programming},
	file         = {Cheng et al\_2018\_FogFlow.pdf:/home/volodia/Zotero/storage/XWK3PRQ6/Cheng et al\_2018\_FogFlow.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/S2VFG65M/8022859.html:text/html}
}
@software{noauthor_yomo_2022,
	title        = {{YoMo}},
	publisher    = {{YoMo}},
	url          = {https://github.com/yomorun/yomo},
	urldate      = {2022-02-09},
	note         = {original-date: 2020-07-01T05:48:28Z},
	rights       = {Apache-2.0},
	abstract     = {🦖 Serverless Streaming Framework for Low-latency Edge Computing applications, running atop {QUIC} protocol, as Metaverse infrastructure, engaging 5G technology.},
	date         = {2022-02-08},
	keywords     = {edge-computing, iot, 5g, distributed-cloud, edge-ai, edge-mesh, functional-reactive-programming, geodistributedsystems, low-latency, metaverse, metaverse-infrastructure, networking, quic, realtime, serverless, stream-processing}
}
@software{noauthor_baetyl_2022,
	title        = {{BAETYL} v2},
	publisher    = {baetyl},
	url          = {https://github.com/baetyl/baetyl},
	urldate      = {2022-02-09},
	note         = {original-date: 2018-09-11T09:31:22Z},
	rights       = {Apache-2.0},
	abstract     = {Extend cloud computing, data and service seamlessly to edge devices.},
	date         = {2022-02-07},
	keywords     = {edge-computing, iot, container, docker, edge, faas, functions-as-a-service, golang, micro-service, ml-in-production, mqtt}
}
@online{noauthor_k3s_nodate,
	title        = {K3s: Lightweight Kubernetes},
	url          = {https://k3s.io/},
	urldate      = {2022-02-09},
	file         = {K3s\: Lightweight Kubernetes:/home/volodia/Zotero/storage/WEWA8DQM/k3s.io.html:text/html}
}
@software{noauthor_kubeedge_2022,
	title        = {{KubeEdge}},
	publisher    = {{KubeEdge}},
	url          = {https://github.com/kubeedge/kubeedge},
	urldate      = {2022-02-09},
	note         = {original-date: 2018-09-28T08:57:49Z},
	rights       = {Apache-2.0},
	abstract     = {Kubernetes Native Edge Computing Framework (project under {CNCF})},
	date         = {2022-02-09},
	keywords     = {edge-computing, iot, container, docker, golang, mqtt, cloud-native, cncf, device-management, kubernetes, mosquitto}
}
@article{brzoza-woch_holistic_2015,
	title        = {Holistic Approach to Urgent Computing for Flood Decision Support},
	author       = {Brzoza-Woch, Robert and Konieczny, Marek and Kwolek, Bartosz and Nawrocki, Piotr and Szyd\l{}o, Tomasz and Zieli\'{n}ski, Krzysztof},
	series       = {International Conference On Computational Science, {ICCS} 2015},
	volume       = 51,
	pages        = {2387--2396},
	doi          = {10.1016/j.procs.2015.05.414},
	issn         = {1877-0509},
	url          = {https://www.sciencedirect.com/science/article/pii/S1877050915012223},
	urldate      = {2022-02-09},
	abstract     = {This paper presents the concept of holistic approach to urgent computing which extends resources management in situation of emergency from computational resources to Data Acquisition and Preprocessing System. The layered structure of this system is presented in detail and its rearrangement in case of emergency is proposed. This process is harmonized with large scale computation using Urgent Service Profile. The proposed approach was validated by practical work performed under {ISMOP} project. Concrete examples of Urgent Service Profile definition have been discussed. Results of preliminary experiments related to energy management and data transmission optimization in case of emergency have been presented.},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	date         = {2015-01-01},
	langid       = {english},
	keywords     = {flood decision support, fog computing, software reconfiguration, telemetry networks, Urgent computing, wireless sensor networks},
	file         = {Brzoza-Woch et al\_2015\_Holistic Approach to Urgent Computing for Flood Decision Support.pdf:/home/volodia/Zotero/storage/FL7B7XB2/Brzoza-Woch et al\_2015\_Holistic Approach to Urgent Computing for Flood Decision Support.pdf:application/pdf;ScienceDirect Snapshot:/home/volodia/Zotero/storage/C29EHR5X/S1877050915012223.html:text/html}
}
@inproceedings{aazam_e-hamc_2015,
	title        = {E-{HAMC}: Leveraging Fog computing for emergency alert service},
	shorttitle   = {E-{HAMC}},
	author       = {Aazam, Mohammad and Huh, Eui-Nam},
	booktitle    = {2015 {IEEE} International Conference on Pervasive Computing and Communication Workshops ({PerCom} Workshops)},
	pages        = {518--523},
	doi          = {10.1109/PERCOMW.2015.7134091},
	abstract     = {Timeliness is one the most important factors in emergency management. Emergency notification mechanism has to be hassle free and quick, in order to have efficient response for any disaster, health-fix, act of terrorism, etc. In this paper, we present service architecture for emergency alert, using Fog computing. Fog computing brings cloud resources close to the underlying devices and {IoTs}, which makes it ideal for latency sensitive services. Furthermore, Fog is used for offloading resource constrained devices. Our smart phone based service, known as Emergency Help Alert Mobile Cloud (E-{HAMC}) provides a quick way of notifying the relevant emergency dealing department, utilizing the services of Fog for offloading as well as pre-processing purposes. The service sends the location of incident and contacts the appropriate emergency dealing department automatically through already stored contact numbers. The emergency related information is then synchronized automatically from Fog to the Cloud, allowing further analysis and improvement in safety of the people and creates extended portfolio of services for the concerned authorities as well as the users. Performance in most certain scenarios is also evaluated and presented in this study, which shows the applicability of our system and its future prospects.},
	eventtitle   = {2015 {IEEE} International Conference on Pervasive Computing and Communication Workshops ({PerCom} Workshops)},
	date         = {2015-03},
	keywords     = {Cloud computing, Fog computing, Accidents, Delays, Edge Computing, emergency alert, Emergency services, M2M, Micro Data Center ({MDC}), mobile cloud computing, Mobile communication, Synchronization, Vehicles},
	file         = {Aazam\_Huh\_2015\_E-HAMC.pdf:/home/volodia/Zotero/storage/RKXLSADS/Aazam\_Huh\_2015\_E-HAMC.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/ZI2AFNRR/7134091.html:text/html}
}
@inproceedings{hossain_efficient_2021,
	title        = {Efficient Task Offloading for {MEC}-Enabled Vehicular Networks: A Non-Cooperative Game Theoretic Approach},
	shorttitle   = {Efficient Task Offloading for {MEC}-Enabled Vehicular Networks},
	author       = {Hossain, Md Delowar and Khanal, Subina and Huh, Eui-Nam},
	booktitle    = {2021 Twelfth International Conference on Ubiquitous and Future Networks ({ICUFN})},
	pages        = {11--16},
	doi          = {10.1109/ICUFN49451.2021.9528673},
	note         = {{ISSN}: 2165-8536},
	abstract     = {Vehicular Edge Computing ({VEC}) is a new leading technology to enhance the vehicular performance through task offloading where resource-confined vehicles offload their computing task to the vehicular multi-access edge computing ({MEC}) networks in proximity. However, the environment of vehicular task offloading is extremely dynamic and faces some challenges to determine the location of processing the offloaded task. As a result, to achieve optimal performance by using traditional {VEC} system is difficult because in advance we don't know the demand of vehicles. Therefore, a non-cooperative game theory-based efficient task offloading ({NGTO}) scheme is proposed in this study where the offloading decisions are taken either the {MEC} server or remote cloud server through the game-theoretic approach. To reduce the processing latency of the vehicles' computation tasks and assure the maximum utility of each vehicle, we used a distributed best response offloading strategy. Our proposed strategy accommodates its offloading probability to achieve a unique equilibrium under certain conditions. Detailed performance evaluation affirms that our proposed {NGTO} scheme can outperform in all scenarios. It can minimize the response time at almost 41.2 \% and average task failure rate at approximately 56.3\% when compared with a local roadside unit computing ({LRC}) scheme. The reduced response time and task failure rates are approximately 25.2\% and 20.4\%, respectively, when compared with a collaborative ({LRC} with cloud via roadside unit) offloading scheme.},
	eventtitle   = {2021 Twelfth International Conference on Ubiquitous and Future Networks ({ICUFN})},
	date         = {2021-08},
	keywords     = {Collaboration, game theory, Games, Performance evaluation, Real-time systems, Servers, Simulation, task of-floading, Time factors, vehicular edge computing, vehicular networks},
	file         = {Hossain et al\_2021\_Efficient Task Offloading for MEC-Enabled Vehicular Networks.pdf:/home/volodia/Zotero/storage/AT67FZHP/Hossain et al\_2021\_Efficient Task Offloading for MEC-Enabled Vehicular Networks.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/UMLHST8A/9528673.html:text/html}
}
@inproceedings{li_ehopes_2015,
	title        = {{EHOPES}: Data-centered Fog platform for smart living},
	shorttitle   = {{EHOPES}},
	author       = {Li, Jianhua and Jin, Jiong and Yuan, Dong and Palaniswami, Marimuthu and Moessner, Klaus},
	booktitle    = {2015 International Telecommunication Networks and Applications Conference ({ITNAC})},
	pages        = {308--313},
	doi          = {10.1109/ATNAC.2015.7366831},
	abstract     = {Nowadays, smart environments (e.g., smart home, smart city) are built heavily relying on Cloud computing for the coordination and collaboration among smart objects. Cloud is typically centralized but smart objects are ubiquitously distributed, thus, data transmission latency (i.e., end-to-end delay or response time) between Cloud and smart objects is a critical issue especially to the applications that have strict delay requirements. To address the concern, a new Fog computing paradigm is recently proposed by the industry, while the detailed Fog platform is yet to be developed. The key idea is to bring the computing power from the remote Cloud closer to the users, which further enables real-time interaction and location-based services. In particular, the local processing capability of Fog computing significantly scales down the data volume towards the Cloud, and it in turn has great impacts on the entire Internet. In this paper, a data-centered Fog platform is developed to support smart living together with dataflow analysis. Case studies are also conducted to validate and evaluate the proposed platform.},
	eventtitle   = {2015 International Telecommunication Networks and Applications Conference ({ITNAC})},
	date         = {2015-11},
	keywords     = {Cloud computing, Real-time systems, Servers, Cloud Computing, Fog Computing, Medical services, Robots, Smart Living},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/99P95UVP/7366831.html:text/html;Li et al\_2015\_EHOPES.pdf:/home/volodia/Zotero/storage/2LZ5TWYR/Li et al\_2015\_EHOPES.pdf:application/pdf}
}
@inproceedings{chakraborty_fog_2016,
	title        = {Fog Networks in Healthcare Application},
	author       = {Chakraborty, Suryadip and Bhowmick, Satyajit and Talaga, Paul and Agrawal, Dharma P.},
	booktitle    = {2016 {IEEE} 13th International Conference on Mobile Ad Hoc and Sensor Systems ({MASS})},
	pages        = {386--387},
	doi          = {10.1109/MASS.2016.065},
	note         = {{ISSN}: 2155-6814},
	abstract     = {Fog computing is a recently proposed computing paradigm that extends Cloud computing and services to the edge of the network. The new features offered by fog computing (e.g., distributed analytics and edge intelligence), if successfully applied for time-sensitive healthcare applications, has great potential to accelerate the discovery of early notification of emergency situations to support smart decision making. While promising, how to design and develop real-world fog computing-based data monitoring system is still an open question. As a first step to answer this question, in this research, we employ a fog-based cloud paradigm for time-sensitive medical applications and also propose to show the practical applicability and significance of such a novel system. The ubiquitous deployment of mobile and sensor devices is creating a new environment, namely the Internet of Things ({IoT}) that enables a wide range of future Internet applications. In this work, we present dynamic Fog, a high level programming model for time-sensitive applications that are geospatially distributed, large-scale, and latency-sensitive. We also analyze our fog model with healthcare data, more specifically with Heartrate data that is one of the most time-sensitive medical data which deals with life and death situations. Our experiments show that our proposed system achieves minimum delay while it also achieves the data accuracy and data consistency which are very important in many applications like medical data.},
	eventtitle   = {2016 {IEEE} 13th International Conference on Mobile Ad Hoc and Sensor Systems ({MASS})},
	date         = {2016-10},
	keywords     = {Cloud computing, Edge computing, Logic gates, Delays, Mobile communication, Medical services, Delay, Fog networks, Healthcare data, {IoT}, Monitoring},
	file         = {Chakraborty et al\_2016\_Fog Networks in Healthcare Application.pdf:/home/volodia/Zotero/storage/WKSLDCVH/Chakraborty et al\_2016\_Fog Networks in Healthcare Application.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/I7Y989BR/7815059.html:text/html}
}
@unpublished{biren_gandhi_fog_nodate,
	title        = {Fog Computing Reality Check: Real World Applications and Architectures},
	shorttitle   = {Fog Computing Reality Check},
	author       = {Biren Gandhi},
	url          = {https://www.slideshare.net/biren\%5Fgandhi/fog-computing-reality-check-real-world-applications-and-architectures},
	urldate      = {2022-02-09}
}
@online{noauthor_clouds_nodate,
	title        = {The {CLOUDS} Lab: Flagship Projects - Gridbus and Cloudbus},
	url          = {http://www.cloudbus.org/cloudsim/},
	urldate      = {2022-02-09},
	file         = {The CLOUDS Lab\: Flagship Projects - Gridbus and Cloudbus:/home/volodia/Zotero/storage/S5BYJGLY/cloudsim.html:text/html}
}
@inproceedings{etemad_using_2017,
	title        = {Using {DEVS} for modeling and simulating a Fog Computing environment},
	author       = {Etemad, Mohammad and Aazam, Mohammad and St-Hilaire, Marc},
	booktitle    = {2017 International Conference on Computing, Networking and Communications ({ICNC})},
	pages        = {849--854},
	doi          = {10.1109/ICCNC.2017.7876242},
	abstract     = {With the increase in popularity of Internet of Things ({IoT}), pervasive computing, healthcare services, sensor networks, and mobile devices, a lot of data is being generated at the perception layer. Cloud is the most viable solution for data storage, processing, and management. Cloud also helps in the creation of further services, refined according to the context and requirement. However, being reachable through the Internet, cloud is not efficient enough for latency sensitive multimedia services and other time-sensitive services, like emergency and healthcare. Fog, an extended cloud lying within the proximity of underlying nodes, can mitigate the issues traditional cloud cannot solve being standalone. Fog can provide quick response to the requiring applications. Moreover, it can preprocess and filter data according to the requirements. Trimmed data is then sent to the cloud for further analysis and enhanced service provisioning. However, how much better is it to have a fog in any particular scenario instead of a standalone cloud working without fog is a question right now. In this paper, we provide an answer by analyzing both cloud-only and cloud-fog scenarios in the context of processing delay and power consumption according to increasing number of users, on the basis of varying server load. The simulation is done through Discrete Event System Specification ({DEVS}). Simulation results demonstrate that by the use of fog networks, users experienced lower waiting times and increased data rates.},
	eventtitle   = {2017 International Conference on Computing, Networking and Communications ({ICNC})},
	date         = {2017-01},
	keywords     = {cloud computing, Fog computing, Simulation, {DEVS}, performance evaluation},
	file         = {Etemad et al\_2017\_Using DEVS for modeling and simulating a Fog Computing environment.pdf:/home/volodia/Zotero/storage/YI52LUAM/Etemad et al\_2017\_Using DEVS for modeling and simulating a Fog Computing environment.pdf:application/pdf}
}
@article{tuli_fogbus_2019,
	title        = {{FogBus}: A Blockchain-based Lightweight Framework for Edge and Fog Computing},
	shorttitle   = {{FogBus}},
	author       = {Tuli, Shreshth and Mahmud, Redowan and Tuli, Shikhar and Buyya, Rajkumar},
	volume       = 154,
	pages        = {22--36},
	doi          = {10.1016/j.jss.2019.04.050},
	issn         = {01641212},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0164121219300822},
	urldate      = {2022-02-09},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	date         = {2019-08},
	langid       = {english},
	keywords     = {paas},
	file         = {Tuli et al. - 2019 - FogBus A Blockchain-based Lightweight Framework f.pdf:/home/volodia/Zotero/storage/D2MSANHJ/Tuli et al. - 2019 - FogBus A Blockchain-based Lightweight Framework f.pdf:application/pdf}
}
@software{noauthor_fogbus_2021,
	title        = {{FogBus}},
	publisher    = {The Cloud Computing and Distributed Systems ({CLOUDS}) Laboratory},
	url          = {https://github.com/Cloudslab/FogBus},
	urldate      = {2022-02-09},
	note         = {original-date: 2018-09-02T13:58:59Z},
	rights       = {{GPL}-2.0},
	abstract     = {[{JSS}'19] A Blockchain-based Lightweight Framework for Edge and Fog Computing},
	date         = {2021-12-26},
	keywords     = {edge-computing, fog-computing, blockchain, cloud-computing, iot-application}
}
@software{noauthor_fogbus2_2021,
	title        = {{FogBus}2 Framework},
	publisher    = {The Cloud Computing and Distributed Systems ({CLOUDS}) Laboratory},
	url          = {https://github.com/Cloudslab/FogBus2},
	urldate      = {2022-02-09},
	note         = {original-date: 2021-07-31T14:28:33Z},
	abstract     = {{FogBus}2: A Lightweight and Distributed Container-based Framework for Integration of {IoT}-enabled Systems with Edge and Cloud Computing},
	date         = {2021-12-07},
	keywords     = {paas}
}
@online{noauthor_how_nodate-1,
	title        = {How to set public {SSH} key for root user on server?},
	url          = {https://serverfault.com/questions/140421/how-to-set-public-ssh-key-for-root-user-on-server},
	urldate      = {2022-02-09},
	titleaddon   = {Server Fault},
	file         = {Snapshot:/home/volodia/Zotero/storage/P4WZ3J7W/how-to-set-public-ssh-key-for-root-user-on-server.html:text/html}
}
@online{ltd_learn_2021,
	title        = {Learn how to build functions faster using Rancher's kim and K3s},
	author       = {Ltd, {OpenFaaS}},
	url          = {https://www.openfaas.com/blog/kim/},
	urldate      = {2022-02-09},
	abstract     = {Learn how the kim tool from Rancher can be used to build functions directly into a K3s cluster},
	titleaddon   = {{OpenFaaS} - Serverless Functions Made Simple},
	date         = {2021-05-12},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/EEPJRG5F/kim.html:text/html}
}
@article{fernandez-carames_fog_2018,
	title        = {A Fog Computing and Cloudlet Based Augmented Reality System for the Industry 4.0 Shipyard},
	author       = {Fern\'{a}ndez-Caram\'{e}s, Tiago M. and Fraga-Lamas, Paula and Su\'{a}rez-Albela, Manuel and Vilar-Montesinos, Miguel},
	volume       = 18,
	number       = 6,
	pages        = 1798,
	doi          = {10.3390/s18061798},
	issn         = {1424-8220},
	url          = {https://www.mdpi.com/1424-8220/18/6/1798},
	urldate      = {2022-02-10},
	note         = {Number: 6 Publisher: Multidisciplinary Digital Publishing Institute},
	rights       = {http://creativecommons.org/licenses/by/3.0/},
	abstract     = {Augmented Reality ({AR}) is one of the key technologies pointed out by Industry 4.0 as a tool for enhancing the next generation of automated and computerized factories. {AR} can also help shipbuilding operators, since they usually need to interact with information (e.g., product datasheets, instructions, maintenance procedures, quality control forms) that could be handled easily and more efficiently through {AR} devices. This is the reason why Navantia, one of the 10 largest shipbuilders in the world, is studying the application of {AR} (among other technologies) in different shipyard environments in a project called ``Shipyard 4.0''. This article presents Navantia's industrial {AR} ({IAR}) architecture, which is based on cloudlets and on the fog computing paradigm. Both technologies are ideal for supporting physically-distributed, low-latency and {QoS}-aware applications that decrease the network traffic and the computational load of traditional cloud computing systems. The proposed {IAR} communications architecture is evaluated in real-world scenarios with payload sizes according to demanding Microsoft {HoloLens} applications and when using a cloud, a cloudlet and a fog computing system. The results show that, in terms of response delay, the fog computing system is the fastest when transferring small payloads (less than 128 {KB}), while for larger file sizes, the cloudlet solution is faster than the others. Moreover, under high loads (with many concurrent {IAR} clients), the cloudlet in some cases is more than four times faster than the fog computing system in terms of response delay.},
	journaltitle = {Sensors},
	date         = {2018-06},
	langid       = {english},
	keywords     = {cloudlet, fog computing, augmented reality, {IIoT}, industrial augmented reality, industrial operator support, Industry 4.0, Microsoft {HoloLens}, shipyard},
	file         = {Fern\'{a}ndez-Caram\'{e}s et al\_2018\_A Fog Computing and Cloudlet Based Augmented Reality System for the Industry 4.pdf:/home/volodia/Zotero/storage/IKDAAMKI/Fern\'{a}ndez-Caram\'{e}s et al\_2018\_A Fog Computing and Cloudlet Based Augmented Reality System for the Industry 4.pdf:application/pdf;Snapshot:/home/volodia/Zotero/storage/XNR2ZNYJ/htm.html:text/html}
}
@online{noauthor_dhcp_nodate,
	title        = {{DHCP} not working on Fedora rawhide \cdot{} Issue \#1448 \cdot{} canonical/multipass},
	url          = {https://github.com/canonical/multipass/issues/1448},
	urldate      = {2022-02-10},
	abstract     = {Describe the bug Trying to package a snap using snapcraft on Fedora rawhide. Initially this failed with a permission error on /var/snap/multipass/common/multipass\_socket \$ ls -lh /var/snap/multipas...},
	titleaddon   = {{GitHub}},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/2Y95MUAB/1448.html:text/html}
}
@online{262588213843476_setup_nodate,
	title        = {Setup a k3s kubernetes cluster using Multipass {VMs}},
	author       = 262588213843476,
	url          = {https://gist.github.com/lucj/5a0e2286b40130d02388a264e6924ed4},
	urldate      = {2022-02-10},
	abstract     = {Setup a k3s kubernetes cluster using Multipass {VMs} - k3s-multipass.sh},
	titleaddon   = {Gist},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/2SJ594ZF/5a0e2286b40130d02388a264e6924ed4.html:text/html}
}
@online{juggery_local_2019,
	title        = {Local K3s Cluster Made Easy With Multipass},
	author       = {Juggery, Luc},
	url          = {https://betterprogramming.pub/local-k3s-cluster-made-easy-with-multipass-108bf6ce577c},
	urldate      = {2022-02-10},
	abstract     = {Its integration with low-level hypervisors makes it a good choice to deploy multiple {VMs} locally},
	titleaddon   = {Medium},
	date         = {2019-12-17},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/NQKALFL7/local-k3s-cluster-made-easy-with-multipass-108bf6ce577c.html:text/html}
}
@software{noauthor_faasd_2022,
	title        = {faasd - a lightweight \& portable faas engine},
	publisher    = {{OpenFaaS}},
	url          = {https://github.com/openfaas/faasd/blob/95c41ea758e31154327b89124e4a678b8d633cbb/docs/MULTIPASS.md},
	urldate      = {2022-02-10},
	note         = {original-date: 2019-12-20T12:55:07Z},
	rights       = {{MIT}},
	abstract     = {A lightweight \& portable faas engine},
	date         = {2022-02-10}
}
@online{noauthor_create_nodate,
	title        = {Create functions - {OpenFaaS}},
	url          = {https://docs.openfaas.com/cli/templates/},
	urldate      = {2022-02-10},
	file         = {Create functions - OpenFaaS:/home/volodia/Zotero/storage/8I7VBIV7/templates.html:text/html}
}
@article{eismann_state_2021,
	title        = {The State of Serverless Applications: Collection, Characterization, and Community Consensus},
	shorttitle   = {The State of Serverless Applications},
	author       = {Eismann, Simon and Scheuner, Joel and Van Eyk, Erwin and Schwinger, Maximilian and Grohmann, Johannes and Herbst, Nikolas and Abad, Cristina and Iosup, Alexandru},
	pages        = {1--1},
	doi          = {10.1109/TSE.2021.3113940},
	issn         = {1939-3520},
	note         = {Conference Name: {IEEE} Transactions on Software Engineering},
	abstract     = {Over the last five years, all major cloud platform providers have increased their serverless offerings. Many early adopters report significant benefits for serverless-based over traditional applications, and many companies are considering moving to serverless themselves. However, currently there exist only few, scattered, and sometimes even conflicting reports on when serverless applications are well suited and what the best practices for their implementation are. We address this problem in the present study about the state of serverless applications. We collect descriptions of 89 serverless applications from open-source projects, academic literature, industrial literature, and domain-specific feedback. We analyze 16 characteristics that describe why and when successful adopters are using serverless applications, and how they are building them. We further compare the results of our characterization study to 10 existing, mostly industrial, studies and datasets; this allows us to identify points of consensus across multiple studies, investigate points of disagreement, and overall confirm the validity of our results. The results of this study can help managers to decide if they should adopt serverless technology, engineers to learn about current practices of building serverless applications, and researchers and platform providers to better understand the current landscape of serverless applications.},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	date         = 2021,
	keywords     = {Logic gates, Buildings, Computer architecture, Open source software, Production, Software engineering, Systematics},
	file         = {Eismann et al\_2021\_The State of Serverless Applications.pdf:/home/volodia/Zotero/storage/3K8SAQ3P/Eismann et al\_2021\_The State of Serverless Applications.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/6W2VTXC6/9543531.html:text/html}
}
@online{noauthor_tinyfaas_nodate,
	title        = {{tinyFaaS}: A Lightweight {FaaS} Platform for Edge Environments {\textbar} {IEEE} Conference Publication {\textbar} {IEEE} Xplore},
	url          = {https://ieeexplore.ieee.org/abstract/document/9103476},
	urldate      = {2022-02-10},
	file         = {tinyFaaS\: A Lightweight FaaS Platform for Edge Environments \vert{} IEEE Conference Publication \vert{} IEEE Xplore:/home/volodia/Zotero/storage/6JCYTRZQ/9103476.html:text/html}
}
@inproceedings{xu_towards_2016,
	title        = {Towards {SDN}-based fog computing: {MQTT} broker virtualization for effective and reliable delivery},
	shorttitle   = {Towards {SDN}-based fog computing},
	author       = {Xu, Yiming and Mahendran, V. and Radhakrishnan, Sridhar},
	booktitle    = {2016 8th International Conference on Communication Systems and Networks ({COMSNETS})},
	pages        = {1--6},
	doi          = {10.1109/COMSNETS.2016.7439974},
	note         = {{ISSN}: 2155-2509},
	abstract     = {Performance of data analytics in Internet of Things ({IoTs}) depends on effective transport services offered by the underlying network. Fog computing enables independent data-plane computational features at the edge-switches, which serves as a platform for performing certain critical analytics required at the {IoT} source. To this end, in this paper, we implement a working prototype of Fog computing node based on Software-Defined Networking ({SDN}). Message Queuing Telemetry Transport ({MQTT}) is chosen as the candidate {IoT} protocol that transports data generated from {IoT} devices (a:k:a: {MQTT} publishers) to a remote host (called {MQTT} broker). We implement the {MQTT} broker functionalities integrated at the edge-switches, that serves as a platform to perform simple message-based analytics at the switches, and also deliver messages in a reliable manner to the end-host for post-delivery analytics. We mathematically validate the improved delivery performance as offered by the proposed switch-embedded brokers.},
	eventtitle   = {2016 8th International Conference on Communication Systems and Networks ({COMSNETS})},
	date         = {2016-01},
	keywords     = {Performance evaluation, Computer architecture, Big data, Conferences, Control systems, Ports (Computers), Throughput},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/I6YQRB5H/7439974.html:text/html;Xu et al\_2016\_Towards SDN-based fog computing.pdf:/home/volodia/Zotero/storage/5UZVADE2/Xu et al\_2016\_Towards SDN-based fog computing.pdf:application/pdf}
}
@article{salman_iot_2018,
	title        = {{IoT} survey: An {SDN} and fog computing perspective},
	shorttitle   = {{IoT} survey},
	author       = {Salman, Ola and Elhajj, Imad and Chehab, Ali and Kayssi, Ayman},
	volume       = 143,
	pages        = {221--246},
	doi          = {10.1016/j.comnet.2018.07.020},
	issn         = {1389-1286},
	url          = {https://www.sciencedirect.com/science/article/pii/S1389128618305395},
	urldate      = {2022-02-10},
	abstract     = {Recently, there has been an increasing interest in the Internet of Things ({IoT}). While some analysts disvalue the {IoT} hype, several technology leaders, governments, and researchers are putting serious efforts to develop solutions enabling wide {IoT} deployment. Thus, the huge amount of generated data, the high network scale, the security and privacy concerns, the new requirements in terms of {QoS}, and the heterogeneity in this ubiquitous network of networks make its implementation a very challenging task. {SDN}, a new networking paradigm, has revealed its usefulness in reducing the management complexities in today's networks. Additionally, {SDN}, having a global view of the network, has presented effective security solutions. On the other hand, fog computing, a new data service platform, consists of pushing the data to the network edge reducing the cost (in terms of bandwidth consumption and high latency) of ``big data'' transportation through the core network. In this paper, we critically review the {SDN} and fog computing-based solutions to overcome the {IoT} main challenges, highlighting their advantages, and exposing their weaknesses. Thus, we make recommendations at the end of this paper for the upcoming research work.},
	journaltitle = {Computer Networks},
	shortjournal = {Computer Networks},
	date         = {2018-10-09},
	langid       = {english},
	keywords     = {{IoT}, 5G, Cloud, Fog, {SDN}, Survey},
	file         = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/3375APN4/S1389128618305395.html:text/html}
}
@inreference{noauthor_software-defined_2022,
	title        = {Software-defined networking},
	booktitle    = {Wikipedia},
	url          = {https://en.wikipedia.org/w/index.php?title=Software-defined\%5Fnetworking\&oldid=1070889880},
	urldate      = {2022-02-10},
	note         = {Page Version {ID}: 1070889880},
	rights       = {Creative Commons Attribution-{ShareAlike} License},
	abstract     = {Software-defined networking ({SDN}) technology is an approach to network management that enables dynamic, programmatically efficient network configuration in order to improve network performance and monitoring, making it more like cloud computing than traditional network management. {SDN} is meant to address the static architecture of traditional networks. {SDN} attempts to centralize network intelligence in one network component by disassociating the forwarding process of network packets (data plane) from the routing process (control plane). The control plane consists of one or more controllers, which are considered the brain of the {SDN} network where the whole intelligence is incorporated. However, centralization has its own drawbacks when it comes to security, scalability and elasticity and this is the main issue of {SDN}.{SDN} was commonly associated with the {OpenFlow} protocol (for remote communication with network plane elements for the purpose of determining the path of network packets across network switches) since the latter's emergence in 2011. However, since 2012, proprietary  systems also used the term. These include Cisco Systems' Open Network Environment and Nicira's network virtualization platform. {SD}-{WAN} applies similar technology to a wide area network ({WAN}).},
	date         = {2022-02-09},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/R47RGRS7/Software-defined\_networking.html:text/html}
}
@online{networks_lets_nodate,
	title        = {Let's build our own Software Defined Network!},
	author       = {Networks, Northbound},
	url          = {https://northboundnetworks.com/blogs/sdn/lets-build-our-own-software-defined-network},
	urldate      = {2022-02-10},
	abstract     = {In Part 3 of this series we are going to build an actual Software Defined Network.},
	titleaddon   = {Northbound Networks},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/KQPWJF4X/lets-build-our-own-software-defined-network.html:text/html}
}
@article{espinel_sarmiento_decentralized_2021,
	title        = {Decentralized {SDN} Control Plane for a Distributed Cloud-Edge Infrastructure: A Survey},
	shorttitle   = {Decentralized {SDN} Control Plane for a Distributed Cloud-Edge Infrastructure},
	author       = {Espinel Sarmiento, David and Lebre, Adrien and Nussbaum, Lucas and Chari, Abdelhadi},
	volume       = 23,
	number       = 1,
	pages        = {256--281},
	doi          = {10.1109/COMST.2021.3050297},
	issn         = {1553-877X},
	note         = {Conference Name: {IEEE} Communications Surveys Tutorials},
	abstract     = {Today's emerging needs (Internet of Things applications, Network Function Virtualization services, Mobile Edge computing, etc.) are challenging the classic approach of deploying a few large data centers to provide cloud services. A massively distributed Cloud-Edge architecture could better fit these new trends' requirements and constraints by deploying on-demand infrastructure services in Point-of-Presences within backbone networks. In this context, a key feature is establishing connectivity among several resource managers in charge of operating, each one a subset of the infrastructure. After explaining the networking management challenges related to distributed Cloud-Edge infrastructures, this article surveys and analyzes the characteristics and limitations of existing technologies in the Software Defined Network field that could be used to provide the inter-site connectivity feature. We also introduce Kubernetes, the new de facto container orchestrator platform, and analyze its use in the proposed context. This survey is concluded by providing a discussion about some research directions in the field of {SDN} applied to distributed Cloud-Edge infrastructures' management.},
	journaltitle = {{IEEE} Communications Surveys Tutorials},
	date         = 2021,
	keywords     = {Cloud computing, Quality of service, networking, Routing, Computer architecture, {SDN}, automation, {IaaS}, Neutrons, Tutorials, virtualization, Wide area networks},
	file         = {Espinel Sarmiento et al\_2021\_Decentralized SDN Control Plane for a Distributed Cloud-Edge Infrastructure.pdf:/home/volodia/Zotero/storage/7QYZ8JYM/Espinel Sarmiento et al\_2021\_Decentralized SDN Control Plane for a Distributed Cloud-Edge Infrastructure.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/IJ5KGGXD/9319748.html:text/html}
}
@incollection{jin_lessons_2021,
	title        = {Lessons learned from migrating complex stateful applications onto serverless platforms},
	author       = {Jin, Zewen and Zhu, Yiming and Zhu, Jiaan and Yu, Dongbo and Li, Cheng and Chen, Ruichuan and Akkus, Istemi Ekin and Xu, Yinlong},
	booktitle    = {Proceedings of the 12th {ACM} {SIGOPS} Asia-Pacific Workshop on Systems},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	pages        = {89--96},
	isbn         = {978-1-4503-8698-2},
	url          = {https://doi.org/10.1145/3476886.3477510},
	urldate      = {2022-02-11},
	abstract     = {Serverless computing is increasingly seen as a pivot cloud computing paradigm that has great potential to simplify application development while removing the burden of operational tasks from developers. Despite these advantages, the use of serverless computing has been limited to few application scenarios exhibiting stateless and parallel executions. In addition, the significant effort and cost associated with rearchitecting existing codebase limits the range of these applications and hinder efforts to enhance serverless computing platforms to better suit the needs of current applications. In this paper, we report our experience and observations from migrating four complex and stateful microservice applications (involving 8 programming languages, 5 application frameworks, and 40 application logic services) to {ApacheOpenWhisk}, a widely used serverless computing platform. We highlight a number of patterns and guidelines that facilitate this migration with minimal code changes and practical performance considerations, and imply a path towards further automating this process. We hope our guidelines will help increase the applicability of serverless computing and improve serverless platforms to be more application friendly.},
	date         = {2021-08-24},
	file         = {Jin et al\_2021\_Lessons learned from migrating complex stateful applications onto serverless.pdf:/home/volodia/Zotero/storage/TEYNBVCS/Jin et al\_2021\_Lessons learned from migrating complex stateful applications onto serverless.pdf:application/pdf}
}
@inproceedings{eskandani_wonderless_2021,
	title        = {The Wonderless Dataset for Serverless Computing},
	author       = {Eskandani, Nafise and Salvaneschi, Guido},
	booktitle    = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
	pages        = {565--569},
	doi          = {10.1109/MSR52588.2021.00075},
	note         = {{ISSN}: 2574-3864},
	abstract     = {Function as a Service ({FaaS}) has grown in popularity in recent years, with an increasing number of applications following the Serverless computing model. Serverless computing supports out of the box autoscaling in a pay-as-you-go manner, letting developers focus on the application logic rather than worrying about resource management. With the increasing adoption of the this model, researchers have started studying a wide variety of aspects of Serverless computing, including communication, security, performance, and cost optimization. Yet, we still know very little of how Serverless computing is used in practice.In this paper, we introduce Wonderless, a novel dataset of open-source Serverless applications. Wonderless consists of 1,877 real-world Serverless applications extracted from {GitHub}, and it can be used as a data source for further research in the Serverless ecosystem, such as performance evaluation and software mining. To the best of our knowledge, Wonderless is currently the most diverse and largest dataset for research on Serverless computing.},
	eventtitle   = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
	date         = {2021-05},
	keywords     = {Computational modeling, Performance evaluation, Cloud Computing, {FAA}, Resource management, Data mining, Ecosystems, {FaaS}, Function as a Service, Security, Serverless},
	file         = {Eskandani\_Salvaneschi\_2021\_The Wonderless Dataset for Serverless Computing.pdf:/home/volodia/Zotero/storage/QDZHVUPF/Eskandani\_Salvaneschi\_2021\_The Wonderless Dataset for Serverless Computing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/UWXXRL7P/9463099.html:text/html}
}
@software{noauthor_befaas_2021,
	title        = {{BeFaaS}},
	publisher    = {{BeFaaS}},
	url          = {https://github.com/Be-FaaS/BeFaaS-framework},
	urldate      = {2022-02-11},
	note         = {original-date: 2020-11-11T12:44:57Z},
	rights       = {Apache-2.0},
	abstract     = {Main repository of the {BeFaaS} project},
	date         = {2021-03-20}
}
@software{noauthor_kmu-bigdataserverless-faas-workbench_2022,
	title        = {kmu-bigdata/serverless-faas-workbench},
	publisher    = {{BigData} Lab. in {KMU}},
	url          = {https://github.com/kmu-bigdata/serverless-faas-workbench},
	urldate      = {2022-02-11},
	note         = {original-date: 2019-01-28T05:19:01Z},
	rights       = {Apache-2.0},
	abstract     = {{FunctionBench}},
	date         = {2022-02-11},
	keywords     = {serverless, faas, benchmark, function-bench, serverless-faas, workbench}
}
@software{copik_sebs_2021,
	title        = {{SeBS}: serverless benchmarks suite},
	shorttitle   = {{SeBS}},
	author       = {Copik, Marcin},
	url          = {https://github.com/spcl/serverless-benchmarks},
	urldate      = {2022-02-11},
	note         = {original-date: 2019-12-13T11:04:54Z},
	rights       = {{BSD}-3-Clause},
	abstract     = {{SeBS}: serverless benchmarking suite for automatic performance analysis of {FaaS} platforms.},
	version      = {1.0},
	date         = {2021-07}
}
@online{noauthor_faasprofiler_nodate,
	title        = {{FaaSProfiler}},
	url          = {http://parallel.princeton.edu/FaaSProfiler.html},
	urldate      = {2022-02-11}
}
@software{noauthor_serverlessbench_2022,
	title        = {{ServerlessBench}},
	publisher    = {{IPADS}},
	url          = {https://github.com/SJTU-IPADS/ServerlessBench},
	urldate      = {2022-02-11},
	note         = {original-date: 2020-08-09T11:53:43Z},
	abstract     = {A benchmark suite for serverless computing},
	date         = {2022-02-06}
}
@software{wlloyduw_saaf_2022,
	title        = {{SAAF} - Serverless Application Analytics Framework},
	author       = {wlloyduw},
	url          = {https://github.com/wlloyduw/SAAF},
	urldate      = {2022-02-11},
	note         = {original-date: 2018-10-19T00:36:28Z},
	abstract     = {Serverless Application Analytics Framework},
	date         = {2022-01-14}
}
@software{bschitter_benchmark-suite-serverless-computing_2021,
	title        = {benchmark-suite-serverless-computing},
	author       = {Bschitter},
	url          = {https://github.com/Bschitter/benchmark-suite-serverless-computing},
	urldate      = {2022-02-11},
	note         = {original-date: 2019-02-27T12:27:11Z},
	abstract     = {Repository used for the master thesis "A Benchmark Suite for Serverless Computing".},
	date         = {2021-10-06}
}
@software{noauthor_overview_2022,
	title        = {Overview},
	publisher    = {Microsoft Azure},
	url          = {https://github.com/Azure/AzurePublicDataset},
	urldate      = {2022-02-11},
	note         = {original-date: 2017-08-18T17:37:45Z},
	abstract     = {Microsoft Azure Traces},
	date         = {2022-02-10}
}
@software{noauthor_create_2018,
	title        = {Create a Serverless Pipeline for Video Frame Analysis and Alerting},
	publisher    = {serverless projects},
	url          = {https://github.com/serverless-projects/serverless-rekognition-video-analyzer},
	urldate      = {2022-02-11},
	note         = {original-date: 2018-04-11T11:49:45Z},
	abstract     = {A working prototype for capturing frames off of a live {MJPEG} video stream, identifying objects in near real-time using deep learning, and triggering actions based on an objects watch list.},
	date         = {2018-04-11},
	keywords     = {serverless, rekognition}
}
@software{noauthor_lambci_2022,
	title        = {{LambCI}},
	publisher    = {{LambCI}},
	url          = {https://github.com/lambci/lambci},
	urldate      = {2022-02-11},
	note         = {original-date: 2016-06-12T21:53:34Z},
	rights       = {{MIT}},
	abstract     = {A continuous integration system built on {AWS} Lambda},
	date         = {2022-02-02}
}
@software{noauthor_streamalert_2022,
	title        = {{StreamAlert} - Serverless, Realtime Data Analysis Framework},
	publisher    = {Airbnb},
	url          = {https://github.com/airbnb/streamalert},
	urldate      = {2022-02-11},
	note         = {original-date: 2017-01-22T01:10:56Z},
	rights       = {Apache-2.0},
	abstract     = {{StreamAlert} is a serverless, realtime data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using datasources and alerting logic you define.},
	date         = {2022-02-07},
	keywords     = {serverless, analysis, aws, kinesis, lambda, rules, security, terraform}
}
@software{noauthor_goad_2022,
	title        = {Goad},
	publisher    = {Goad},
	url          = {https://github.com/goadapp/goad},
	urldate      = {2022-02-11},
	note         = {original-date: 2016-01-22T19:21:26Z},
	rights       = {{MIT}},
	abstract     = {Goad is an {AWS} Lambda powered, highly distributed, load testing tool},
	date         = {2022-02-07}
}
@software{noauthor_async-coap_2022,
	title        = {async-coap: An experimental, asynchronous {CoAP} library},
	shorttitle   = {async-coap},
	publisher    = {Google},
	url          = {https://github.com/google/rust-async-coap},
	urldate      = {2022-02-11},
	note         = {original-date: 2019-08-21T20:23:02Z},
	rights       = {Apache-2.0},
	abstract     = {A flexible, asynchronous library for using and serving {CoAP} resources in Rust.},
	date         = {2022-02-01}
}
@article{silva_performance_2021,
	title        = {A Performance Analysis of Internet of Things Networking Protocols: Evaluating {MQTT}, {CoAP}, {OPC} {UA}},
	shorttitle   = {A Performance Analysis of Internet of Things Networking Protocols},
	author       = {Silva, Daniel and Carvalho, Liliana I. and Soares, Jos\'{e} and Sofia, Rute C.},
	volume       = 11,
	number       = 11,
	pages        = 4879,
	doi          = {10.3390/app11114879},
	issn         = {2076-3417},
	url          = {https://www.mdpi.com/2076-3417/11/11/4879},
	urldate      = {2022-02-11},
	note         = {Number: 11 Publisher: Multidisciplinary Digital Publishing Institute},
	rights       = {http://creativecommons.org/licenses/by/3.0/},
	abstract     = {{IoT} data exchange is supported today by different communication protocols and different protocolar frameworks, each of which with its own advantages and disadvantages, and often co-existing in a way that is mandated by vendor policies. Although different protocols are relevant in different domains, there is not a protocol that provides better performance (jitter, latency, energy consumption) across different scenarios. The focus of this work is two-fold. First, to provide a comparison of the different available solutions in terms of protocolar features such as type of transport, type of communication pattern support, security aspects, including Named-data networking as relevant example of an Information-centric networking architecture. Secondly, the work focuses on evaluating three of the most popular protocols used both in Consumer as well as in Industrial {IoT} environments: {MQTT}, {CoAP}, and {OPC} {UA}. The experimentation has been carried out first on a local testbed for {MQTT}, {COAP} and {OPC} {UA}. Then, larger experiments have been carried out for {MQTT} and {CoAP}, based on the large-scale {FIT}-{IoT} testbed. Results show that {CoAP} is the protocol that achieves across all scenarios lowest time-to-completion, while {OPC} {UA}, albeit exhibiting less variability, resulted in higher time-to-completion in comparison to {CoAP} or {MQTT}.},
	journaltitle = {Applied Sciences},
	date         = {2021-01},
	langid       = {english},
	keywords     = {performance evaluation, Internet of Things, networking architectures, networking protocols},
	file         = {Silva et al\_2021\_A Performance Analysis of Internet of Things Networking Protocols.pdf:/home/volodia/Zotero/storage/XVNJPECM/Silva et al\_2021\_A Performance Analysis of Internet of Things Networking Protocols.pdf:application/pdf}
}
@software{noauthor_seastar_2022,
	title        = {Seastar},
	publisher    = {{ScyllaDB}},
	url          = {https://github.com/scylladb/seastar},
	urldate      = {2022-02-11},
	note         = {original-date: 2014-08-18T07:01:07Z},
	rights       = {Apache-2.0},
	abstract     = {High performance server-side application framework},
	date         = {2022-02-11},
	keywords     = {aio, async, c-plus-plus, dpdk, seastar}
}
@software{noauthor_wonderless_2021,
	title        = {Wonderless},
	publisher    = {prg-grp},
	url          = {https://github.com/prg-grp/wonderless},
	urldate      = {2022-02-11},
	note         = {original-date: 2021-03-19T13:15:57Z},
	abstract     = {A dataset to shed light upon Serverless computing.},
	date         = {2021-11-27}
}
@inproceedings{tadakamalla_characterization_2019,
	title        = {Characterization of {IoT} Workloads},
	author       = {Tadakamalla, Uma and Menasc\'{e}, Daniel A.},
	booktitle    = {Edge Computing – {EDGE} 2019},
	location     = {Cham},
	publisher    = {Springer International Publishing},
	series       = {Lecture Notes in Computer Science},
	volume       = 11520,
	pages        = {1--15},
	doi          = {10.1007/978-3-030-23374-7\_1},
	isbn         = {978-3-030-23374-7},
	url          = {http://link.springer.com/10.1007/978-3-030-23374-7\%5F1},
	urldate      = {2022-02-11},
	note         = {Series Title: Lecture Notes in Computer Science},
	abstract     = {Workload characterization is a fundamental step in carrying out performance and Quality of Service engineering studies. The workload of a system is defined as the set of all inputs received by the system from its environment during one or more time windows. The characterization of the workload entails determining the nature of its basic components as well as a quantitative and probabilistic description of the workload components in terms of both the arrival process, event counts, and service demands. Several workload characterization studies were presented for a variety of domains, except for {IoT} workloads. This is precisely the main contribution of this paper, which also presents a capacity planning study based on one of the workload characterizations presented here.},
	editor       = {Zhang, Tao and Wei, Jinpeng and Zhang, Liang-Jie},
	date         = 2019,
	langid       = {english},
	keywords     = {Internet of Things, Capacity planning, G/G/n queue, Quality of Service in edge computing, Workload characterization},
	file         = {Tadakamalla\_Menasc\'{e}\_2019\_Characterization of IoT Workloads.pdf:/home/volodia/Zotero/storage/L9X9FRLY/Tadakamalla\_Menasc\'{e}\_2019\_Characterization of IoT Workloads.pdf:application/pdf}
}
@article{van_lingen_unavoidable_2017,
	title        = {The Unavoidable Convergence of {NFV}, 5G, and Fog: A Model-Driven Approach to Bridge Cloud and Edge},
	shorttitle   = {The Unavoidable Convergence of {NFV}, 5G, and Fog},
	author       = {van Lingen, Frank and Yannuzzi, Marcelo and Jain, Anuj and Irons-Mclean, Rik and Lluch, Oriol and Carrera, David and Perez, Juan Luis and Gutierrez, Alberto and Montero, Diego and Marti, Josep and Maso, Ricard and Rodriguez and Pedro, Juan},
	volume       = 55,
	number       = 8,
	pages        = {28--35},
	doi          = {10.1109/MCOM.2017.1600907},
	issn         = {1558-1896},
	note         = {Conference Name: {IEEE} Communications Magazine},
	abstract     = {The interplay between cloud and fog computing is crucial for the evolution of {IoT}, but the reach and specification of such interplay is an open problem. Meanwhile, the advances made in managing hyper-distributed infrastructures involving the cloud and the network edge are leading to the convergence of {NFV} and 5G, supported mainly by {ETSI}'s {MANO} architecture. This article argues that fog computing will become part of that convergence, and introduces an open and converged architecture based on {MANO} that offers uniform management of {IoT} services spanning the continuum from the cloud to the edge. More specifically, we created the first {YANG} models for fog nodes, for {IoT} services involving cloud, network, and/or fog, and expanded the concept of "orchestrated assurance" to provision carrier-grade service assurance in {IoT}. The article also discusses the application of our model in a flagship pilot in the city of Barcelona.},
	journaltitle = {{IEEE} Communications Magazine},
	date         = {2017-08},
	keywords     = {Cloud computing, Edge computing, Data models, Computer architecture, 5G mobile communication, Analytical models, Convergence},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/32ZIRUGT/8004150.html:text/html;van Lingen et al\_2017\_The Unavoidable Convergence of NFV, 5G, and Fog.pdf:/home/volodia/Zotero/storage/GSEX2HB2/van Lingen et al\_2017\_The Unavoidable Convergence of NFV, 5G, and Fog.pdf:application/pdf}
}
@inproceedings{vilalta_control_2018,
	title        = {Control and Management of a Connected Car Using {SDN}/{NFV}, Fog Computing and {YANG} data models},
	author       = {Vilalta, Ricard and V\'{\i}a, Selva and Mira, Ferm\'{\i}n and Casellas, Ramon and Mu\~{n}oz, Raul and Alonso-Zarate, Jesus and Kousaridas, Apostolos and Dillinger, Markus},
	booktitle    = {2018 4th {IEEE} Conference on Network Softwarization and Workshops ({NetSoft})},
	pages        = {378--383},
	doi          = {10.1109/NETSOFT.2018.8460131},
	abstract     = {There are several use cases that claim the need for a connected car. Among them there is the need for connectivity between vehicles and information sources, or V2V and V2X exchanges for accident prevention. In order to cope with the need for novel applications running on top of an interconnected network, the concept of fog computing appears as a realistic solution for both intra-car and inter-car data processing and decision making. This paper describes the proposed architecture and experimental evaluation of an innovative proof-of-concept ({PoC}) for a connected car, modeled with {YANG}, which can be remotely controlled using {SDN}/{NFV} and fog computing technologies. As an example, the remote control of the car might be based on a service application running on a fog node, which can be located close to a road side unit ({RSU}). We also propose a fog architecture in order to enable cooperative perception between connected cars. Finally, the performance evaluation uses a {RESTCONF} server installed in a Raspberry Pi aboard of a small car. This server is responsible for the sensors and actuators of the car and allows for its remote control from a user terminal (e.g., a smartphone, tablet, or laptop) and through the fog node, running a control application as a service.},
	eventtitle   = {2018 4th {IEEE} Conference on Network Softwarization and Workshops ({NetSoft})},
	date         = {2018-06},
	keywords     = {Cloud computing, Edge computing, Data models, Computer architecture, 5G, {SDN}, Protocols, Automobiles, Connected Car, {NFV}, Sensors, {YANG}},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/U7EYV6TK/8460131.html:text/html;Vilalta et al\_2018\_Control and Management of a Connected Car Using SDN-NFV, Fog Computing and YANG.pdf:/home/volodia/Zotero/storage/E92DZC7F/Vilalta et al\_2018\_Control and Management of a Connected Car Using SDN-NFV, Fog Computing and YANG.pdf:application/pdf}
}
@article{mouradian_application_2019,
	title        = {Application Component Placement in {NFV}-Based Hybrid Cloud/Fog Systems With Mobile Fog Nodes},
	author       = {Mouradian, Carla and Kianpisheh, Somayeh and Abu-Lebdeh, Mohammad and Ebrahimnezhad, Fereshteh and Jahromi, Narjes Tahghigh and Glitho, Roch H.},
	volume       = 37,
	number       = 5,
	pages        = {1130--1143},
	doi          = {10.1109/JSAC.2019.2906790},
	issn         = {1558-0008},
	note         = {Conference Name: {IEEE} Journal on Selected Areas in Communications},
	abstract     = {Fog computing reduces the latency induced by distant clouds by enabling the deployment of some application components at the edge of the network, on fog nodes, while keeping others in the cloud. Application components can be implemented as Virtual Network Functions ({VNFs}) and their execution sequences can be modeled by a combination of sub-structures like sequence, parallel, selection, and loops. Efficient placement algorithms are required to map the application components onto the infrastructure nodes. Current solutions do not consider the mobility of fog nodes, a phenomenon which may happen in real systems. In this paper, we use the random waypoint mobility model for fog nodes to calculate the expected makespan and application execution cost. We then model the problem as an Integer Linear Programming ({ILP}) formulation which minimizes an aggregated weighted function of the makespan and cost. We propose a Tabu Search-based Component Placement ({TSCP}) algorithm to find sub-optimal placements. The results show that the proposed algorithm improves the makespan and the application execution cost.},
	journaltitle = {{IEEE} Journal on Selected Areas in Communications},
	date         = {2019-05},
	keywords     = {cloud computing, Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Data centers, Sensors, Component placement, Drones, Earthquakes, Network function virtualization, Network Functions Virtualization ({NFV}), optimization, Tabu Search},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/BQN6GB9Y/8673549.html:text/html;Mouradian et al\_2019\_Application Component Placement in NFV-Based Hybrid Cloud-Fog Systems With.pdf:/home/volodia/Zotero/storage/HNSS4AEE/Mouradian et al\_2019\_Application Component Placement in NFV-Based Hybrid Cloud-Fog Systems With.pdf:application/pdf}
}
@article{bi_mobility_2018,
	title        = {Mobility Support for Fog Computing: An {SDN} Approach},
	shorttitle   = {Mobility Support for Fog Computing},
	author       = {Bi, Yuanguo and Han, Guangjie and Lin, Chuan and Deng, Qingxu and Guo, Lei and Li, Fuliang},
	volume       = 56,
	number       = 5,
	pages        = {53--59},
	doi          = {10.1109/MCOM.2018.1700908},
	issn         = {1558-1896},
	note         = {Conference Name: {IEEE} Communications Magazine},
	abstract     = {The emerging real-time and computation-intensive services driven by the Internet of Things, augmented reality, automatic driving, and so on, have tight quality of service and quality of experience requirements, which can hardly be supported by conventional cloud computing. Fog computing, which migrates the features of cloud computing to the network edge, guarantees low latency for location-aware services. However, due to the locality feature of fog computing, maintaining service continuity when mobile users travel across different access networks has become a challenging issue. In this article, we propose a novel software-defined-networking-based fog computing architecture by decoupling mobility control and data forwarding. Under the proposed architecture, we design efficient signaling operations to provide seamless and transparent mobility support to mobile users, and present an efficient route optimization algorithm by considering the performance gain in data communications and system overhead in mobile fog computing. Numerical results from extensive simulations have demonstrated that the proposed scheme can not only guarantee service continuity, but also greatly improve handover performance and achieve high data communication efficiency in mobile fog computing.},
	journaltitle = {{IEEE} Communications Magazine},
	date         = {2018-05},
	keywords     = {Edge computing, Routing, Computer architecture, Internet of Things, Energy efficiency, Frequency selective surfaces, Handover},
	file         = {Bi et al\_2018\_Mobility Support for Fog Computing.pdf:/home/volodia/Zotero/storage/7DL4HGHQ/Bi et al\_2018\_Mobility Support for Fog Computing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/P637ZCWW/8360850.html:text/html}
}
@inproceedings{khakimov_iot-fog_2018,
	title        = {{IoT}-fog based system structure with {SDN} enabled},
	author       = {Khakimov, Abdukodir and Ateya, Abdelhamied A. and Muthanna, Ammar and Gudkova, Irina and Markova, Ekaterina and Koucheryavy, Andrey},
	booktitle    = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{ICFNDS} '18},
	pages        = {1--6},
	doi          = {10.1145/3231053.3231129},
	isbn         = {978-1-4503-6428-7},
	url          = {https://doi.org/10.1145/3231053.3231129},
	urldate      = {2022-02-14},
	abstract     = {{IoT} is a new communication paradigm that gains a very high importance in the past few years. Fog computing is a form of edge computing that is developed to provide the computing, storage and management capabilities near to users. Employing Fog computing in {IoT} networks as an intermediate layer between {IoT} devices and the remote cloud becomes a demand to make use of the edge computing benefits. In this work, we provide a framework for {IoT} system structure that employs an edge computing layer of Fog nodes. The system employs {SDN} network with a centralized controller and distributed {OpenFlow} switches; these switches are enabled with limited computing and processing capabilities. The network is operated based on a data offloading algorithm, that allocates certain processing and computing tasks to some {OpenFlow} switches that has unused resources. The proposed work achieves various benefits to the {IoT} network such as the latency reduction and higher efficiency of resources utilization. We perform an experiment over a developed testbed to validate the proposed system and results show that the proposed system achieves higher efficiency in terms of latency and resource utilization.},
	date         = {2018-06-26},
	keywords     = {fog computing, {SDN}, internet of things, latency, openflow},
	file         = {Khakimov et al\_2018\_IoT-fog based system structure with SDN enabled.pdf:/home/volodia/Zotero/storage/TJGKMWQH/Khakimov et al\_2018\_IoT-fog based system structure with SDN enabled.pdf:application/pdf}
}
@article{dabbagh_software-defined_2015,
	title        = {Software-defined networking security: pros and cons},
	shorttitle   = {Software-defined networking security},
	author       = {Dabbagh, Mehiar and Hamdaoui, Bechir and Guizani, Mohsen and Rayes, Ammar},
	volume       = 53,
	number       = 6,
	pages        = {73--79},
	doi          = {10.1109/MCOM.2015.7120048},
	issn         = {1558-1896},
	note         = {Conference Name: {IEEE} Communications Magazine},
	abstract     = {Software-defined networking ({SDN}) is a new networking paradigm that decouples the forwarding and control planes, traditionally coupled with one another, while adopting a logically centralized architecture aiming to increase network agility and programability. While many efforts are currently being made to standardize this emerging paradigm, careful attention needs to be paid to security at this early design stage too, rather than waiting until the technology becomes mature, thereby potentially avoiding previous pitfalls made when designing the Internet in the 1980s. This article focuses on the security aspects of {SDN} networks. We begin by discussing the new security advantages that {SDN} brings and by showing how some of the long-lasting issues in network security can be addressed by exploiting {SDN} capabilities. Then we describe the new security threats that {SDN} is faced with and discuss possible techniques that can be used to prevent and mitigate such threats.},
	journaltitle = {{IEEE} Communications Magazine},
	date         = {2015-06},
	keywords     = {5G mobile communication, Communication standards, {IEEE} standards, Network security, Software radio, Standards, Telecommunication traffic},
	file         = {Dabbagh et al\_2015\_Software-defined networking security.pdf:/home/volodia/Zotero/storage/7C3QD4HS/Dabbagh et al\_2015\_Software-defined networking security.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/H9HY4IBM/7120048.html:text/html}
}
@inproceedings{winzinger_model-based_2019,
	title        = {Model-Based Analysis of Serverless Applications},
	author       = {Winzinger, Stefan and Wirtz, Guido},
	booktitle    = {2019 {IEEE}/{ACM} 11th International Workshop on Modelling in Software Engineering ({MiSE})},
	pages        = {82--88},
	doi          = {10.1109/MiSE.2019.00020},
	note         = {{ISSN}: 2575-4475},
	abstract     = {Serverless computing is a relatively new execution model where the cloud platform provider manages the allocation of resources for containerized functions dynamically. This evolving paradigm is called Function as a Service ({FaaS}). The statelessness of these functions enables the application to be scaled up elastically in the case of peak loads. They can be tested easily in isolation, but the behavior arising by integrating them to an application is both hard to predict and test. The parallel execution of the functions and the shift of its state to data storages can cause several workflows accessing the same data. These workflows are hard to detect, particularly for complex applications. Therefore, we suggest an approach for modelling an existing serverless application based on a specialized graph holding all relevant features. Our serverless-specific model can be applied during the whole life cycle of a complex application and offers a good basis for this specific class of applications. It helps to optimize an existing system by identifying hot spots, supports the generation of test cases and can be used to monitor an existing system. Furthermore, we show how the generation of the model can be automated by realizing a tool supporting Amazon's {AWS} Lambda.},
	eventtitle   = {2019 {IEEE}/{ACM} 11th International Workshop on Modelling in Software Engineering ({MiSE})},
	date         = {2019-05},
	keywords     = {Cloud computing, Computational modeling, Data models, Analytical models, Memory, serverless computing, {FaaS}, dependency graph, model-driven testing, integration testing, cloud functions, Testing, Tools},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/GUHTQ9RF/8877078.html:text/html;Winzinger\_Wirtz\_2019\_Model-Based Analysis of Serverless Applications.pdf:/home/volodia/Zotero/storage/CBRF47LV/Winzinger\_Wirtz\_2019\_Model-Based Analysis of Serverless Applications.pdf:application/pdf}
}
@inproceedings{rossi_gofs_2021,
	title        = {{GOFS}: Geo-distributed Scheduling in {OpenFaaS}},
	shorttitle   = {{GOFS}},
	author       = {Rossi, Fabiana and Falvo, Simone and Cardellini, Valeria},
	booktitle    = {2021 {IEEE} Symposium on Computers and Communications ({ISCC})},
	pages        = {1--6},
	doi          = {10.1109/ISCC53001.2021.9631492},
	note         = {{ISSN}: 2642-7389},
	abstract     = {{OpenFaaS} is a popular open-source serverless platform in the academic and industrial world. Based on Ku-bernetes, {OpenFaaS} includes a simple scheduling policy that spreads functions on cluster computing resources. As such, it is not well-suited for managing latency-sensitive applications in a geo-distributed environment, where network latencies are nonnegligible and negatively affect the application response time. To overcome this issue, in this paper we present {GOFS} (Geo-distributed Scheduling in {OpenFaaS}), which extends {OpenFaaS} with network-aware scheduling capabilities. {GOFS} addresses the serverless application scheduling in a geo-distributed environment by either solving a suitable integer linear programming problem or using a greedy network-aware heuristic. However, its modular architecture facilitates the integration of other custom scheduling policies. A wide set of prototype-based results shows the advantages of the proposed network-aware solutions over other benchmark scheduling policies.},
	eventtitle   = {2021 {IEEE} Symposium on Computers and Communications ({ISCC})},
	date         = {2021-09},
	keywords     = {Computer architecture, Job shop scheduling, Processor scheduling, Fault tolerant systems, Geo-distributed, Measurement, {OpenFaaS}, Optical fibers, Optimal scheduling, Scheduling},
	file         = {Rossi et al\_2021\_GOFS.pdf:/home/volodia/Zotero/storage/AUN6EEQT/Rossi et al\_2021\_GOFS.pdf:application/pdf}
}
@article{yang_edgebench_2020,
	title        = {{EdgeBench}: A Workflow-based Benchmark for Edge Computing},
	shorttitle   = {{EdgeBench}},
	author       = {Yang, Qirui and Jin, Runyu and Gandhi, Nabil and Ge, Xiongzi and Khouzani, Hoda Aghaei and Zhao, Ming},
	url          = {http://arxiv.org/abs/2010.14027},
	urldate      = {2022-02-15},
	note         = {Publication Title: {arXiv} e-prints {ADS} Bibcode: 2020arXiv201014027Y Type: article},
	abstract     = {Edge computing has been developed to utilize multiple tiers of resources for privacy, cost and Quality of Service ({QoS}) reasons. Edge workloads have the characteristics of data-driven and latency-sensitive. Because of this, edge systems have developed to be both heterogeneous and distributed. The unique characteristics of edge workloads and edge systems have motivated {EdgeBench}, a workflow-based benchmark aims to provide the ability to explore the full design space of edge workloads and edge systems. {EdgeBench} is both customizable and representative. It allows users to customize the workflow logic of edge workloads, the data storage backends, and the distribution of the individual workflow stages to different computing tiers. To illustrate the usability of {EdgeBench}, we also implements two representative edge workflows, a video analytics workflow and an {IoT} hub workflow that represents two distinct but common edge workloads. Both workflows are evaluated using the workflow-level and function-level metrics reported by {EdgeBench} to illustrate both the performance bottlenecks of the edge systems and the edge workloads.},
	journaltitle = {{arXiv}:2010.14027 [cs]},
	date         = {2020-10-26},
	eprinttype   = {arxiv},
	eprint       = {2010.14027},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/WGHQMXGA/2010.html:text/html;Yang et al\_2020\_EdgeBench.pdf:/home/volodia/Zotero/storage/TSP9M9VC/Yang et al\_2020\_EdgeBench.pdf:application/pdf}
}
@inproceedings{persson_kappa_2017,
	title        = {Kappa: serverless {IoT} deployment},
	shorttitle   = {Kappa},
	author       = {Persson, Per and Angelsmark, Ola},
	booktitle    = {Proceedings of the 2nd International Workshop on Serverless Computing},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{WoSC} '17},
	pages        = {16--21},
	doi          = {10.1145/3154847.3154853},
	isbn         = {978-1-4503-5434-9},
	url          = {https://doi.org/10.1145/3154847.3154853},
	urldate      = {2022-02-15},
	abstract     = {A recent evolution in cloud computing is the move to serverless applications, where the separation between the server platform and the application is complete, and developers can fully focus on the application, leaving all provisioning details to a cloud provider. In this paper we look at how the serverless computing model can be adopted all the way to the edge devices using the Kappa framework, built on the Calvin platform for distributed cloud and {IoT} applications. Combining the resource management of the platform, where capabilities of nodes are matched with the requirements of the execution units, with a {RESTful} {API} it is possible to build an {IoT} system with a straightforward intuitive interface while still retaining the flexibility of the Calvin platform. We also give examples of how the framework can be used in an industrial {IoT} setting.},
	date         = {2017-12-11},
	keywords     = {cloud computing, serverless, {IoT}, {FaaS}, actor model, data flow},
	file         = {Persson\_Angelsmark\_2017\_Kappa.pdf:/home/volodia/Zotero/storage/EPZ6BE5R/Persson\_Angelsmark\_2017\_Kappa.pdf:application/pdf}
}
@inproceedings{tarneberg_experiences_2016,
	title        = {Experiences Creating a Framework for Smart Traffic Control Using {AWS} {IOT}},
	author       = {T\"{a}rneberg, William and Chandrasekaran, Vishal and Humphrey, Marty},
	booktitle    = {2016 {IEEE}/{ACM} 9th International Conference on Utility and Cloud Computing ({UCC})},
	pages        = {63--69},
	abstract     = {Public clouds such as Amazon Web Services ({AWS}) and Microsoft's Azure provide excellent capabilities for scalable Web applications and Hadoop-based processing. Recent additions to public clouds to support connected devices and {IoT} have the potential to similarly disrupt emerging home-grown and/or proprietary approaches. While early public cloud {IoT} success stories have focused on smaller-scale scenarios such as connected houses, it is unclear to what extent these new public cloud mechanisms and abstractions are suitable and effective for larger-scale and/or scientific scenarios, which often have a different set of constraints or requirements. In this paper, the design and implementation of a representative cloud-based {IoT} infrastructure in a specific public cloud – {AWS} – is presented. The system created is for dynamic vehicle traffic control based on vehicle volumes/patterns and public transport punctuality. We find that constructing server-less, stateful, and data driven {IoT} applications in {AWS} that can operate in real-time is non-trivial. The primary challenges span application manageability and design, latency performance, asynchronicity, and scalability.},
	eventtitle   = {2016 {IEEE}/{ACM} 9th International Conference on Utility and Cloud Computing ({UCC})},
	date         = {2016-12},
	keywords     = {{IoT}, Cloud, Automatic control, {AWS}, Connected vehicles, Data analysis, Data collection, {PaaS}, Public transport, Smart Cities, Tra c, Traffic Signal Priority},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/FAD4VP3G/7881617.html:text/html;T\"{a}rneberg et al\_2016\_Experiences Creating a Framework for Smart Traffic Control Using AWS IOT.pdf:/home/volodia/Zotero/storage/A7E52T4I/T\"{a}rneberg et al\_2016\_Experiences Creating a Framework for Smart Traffic Control Using AWS IOT.pdf:application/pdf}
}
@inproceedings{gabbrielli_no_2019,
	title        = {No More, No Less},
	author       = {Gabbrielli, Maurizio and Giallorenzo, Saverio and Lanese, Ivan and Montesi, Fabrizio and Peressotti, Marco and Zingaro, Stefano Pio},
	booktitle    = {Coordination Models and Languages},
	location     = {Cham},
	publisher    = {Springer International Publishing},
	series       = {Lecture Notes in Computer Science},
	pages        = {148--157},
	doi          = {10.1007/978-3-030-22397-7\_9},
	isbn         = {978-3-030-22397-7},
	abstract     = {Serverless computing, also known as Functions-as-a-Service, is a recent paradigm aimed at simplifying the programming of cloud applications. The idea is that developers design applications in terms of functions, which are then deployed on a cloud infrastructure. The infrastructure takes care of executing the functions whenever requested by remote clients, dealing automatically with distribution and scaling with respect to inbound traffic.While vendors already support a variety of programming languages for serverless computing (e.g. Go, Java, Javascript, Python), as far as we know there is no reference model yet to formally reason on this paradigm. In this paper, we propose the first core formal programming model for serverless computing, which combines ideas from both the 𝜆\ensuremath{\lambda}{\textbackslash}lambda -calculus (for functions) and the 𝜋\ensuremath{\pi}{\textbackslash}pi -calculus (for communication). To illustrate our proposal, we model a real-world serverless system. Thanks to our model, we capture limitations of current vendors and formalise possible amendments.},
	editor       = {Riis Nielson, Hanne and Tuosto, Emilio},
	date         = 2019,
	langid       = {english},
	file         = {Gabbrielli et al\_2019\_No More, No Less.pdf:/home/volodia/Zotero/storage/XC8PLVB7/Gabbrielli et al\_2019\_No More, No Less.pdf:application/pdf}
}
@inproceedings{das_edgebench_2018,
	title        = {{EdgeBench}: Benchmarking Edge Computing Platforms},
	shorttitle   = {{EdgeBench}},
	author       = {Das, Anirban and Patterson, Stacy and Wittie, Mike},
	pages        = {175--180},
	doi          = {10.1109/UCC-Companion.2018.00053},
	date         = {2018-12-01},
	file         = {Das et al\_2018\_EdgeBench.pdf:/home/volodia/Zotero/storage/JDVKKNEJ/Das et al\_2018\_EdgeBench.pdf:application/pdf}
}
@online{noauthor_benchmark_nodate,
	title        = {Benchmark of {IoT} Applications for service placement at the Fog-Edge Computing networks -- {IoT} applications benchmark},
	url          = {https://asfarah.github.io/IoT\%5FBenchmark/README.html},
	urldate      = {2022-02-15},
	file         = {Benchmark of IoT Applications for service placement at the Fog-Edge Computing networks -- IoT applications benchmark:/home/volodia/Zotero/storage/PQSG9WTC/README.html:text/html}
}
@online{noauthor_what_2021,
	title        = {What is edge computing and why it matters},
	url          = {https://www.ericsson.com/en/edge-computing},
	urldate      = {2022-02-15},
	note         = {Last Modified: 2022-01-29T01:07:35+00:00},
	abstract     = {Edge computing is a crucial part of the 5G platform. Explore the winning strategies \& capabilities for service providers to unlock new business opportunities.},
	date         = {2021-02-04},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/RTVTQVLP/edge-computing.html:text/html}
}
@online{noauthor_future_2020,
	title        = {Future of cloud computing: distributed solutions},
	shorttitle   = {Future of cloud computing},
	url          = {https://www.ericsson.com/en/reports-and-papers/ericsson-technology-review/articles/the-future-of-cloud-computing},
	urldate      = {2022-02-15},
	note         = {Last Modified: 2021-02-12T09:14:55+00:00},
	abstract     = {The future of cloud computing is a combination of more distributed solutions with heterogeneous hardware, which presents an opportunity for network operators.},
	date         = {2020-05-12},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/IEUFJS38/the-future-of-cloud-computing.html:text/html}
}
@article{mouradian_comprehensive_2018,
	title        = {A Comprehensive Survey on Fog Computing: State-of-the-Art and Research Challenges},
	shorttitle   = {A Comprehensive Survey on Fog Computing},
	author       = {Mouradian, Carla and Naboulsi, Diala and Yangui, Sami and Glitho, Roch H. and Morrow, Monique J. and Polakos, Paul A.},
	volume       = 20,
	number       = 1,
	pages        = {416--464},
	doi          = {10.1109/COMST.2017.2771153},
	issn         = {1553-877X},
	note         = {Conference Name: {IEEE} Communications Surveys Tutorials},
	abstract     = {Cloud computing with its three key facets (i.e., Infrastructure-as-a-Service, Platform-as-a-Service, and Software-as-a-Service) and its inherent advantages (e.g., elasticity and scalability) still faces several challenges. The distance between the cloud and the end devices might be an issue for latency-sensitive applications such as disaster management and content delivery applications. Service level agreements ({SLAs}) may also impose processing at locations where the cloud provider does not have data centers. Fog computing is a novel paradigm to address such issues. It enables provisioning resources and services outside the cloud, at the edge of the network, closer to end devices, or eventually, at locations stipulated by {SLAs}. Fog computing is not a substitute for cloud computing but a powerful complement. It enables processing at the edge while still offering the possibility to interact with the cloud. This paper presents a comprehensive survey on fog computing. It critically reviews the state of the art in the light of a concise set of evaluation criteria. We cover both the architectures and the algorithms that make fog systems. Challenges and research directions are also introduced. In addition, the lessons learned are reviewed and the prospects are discussed in terms of the key role fog is likely to play in emerging technologies such as tactile Internet.},
	journaltitle = {{IEEE} Communications Surveys Tutorials},
	date         = 2018,
	keywords     = {edge computing, Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Computer architecture, Tutorials, Internet of Things, latency, Classification algorithms, tactile Internet},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/PUKERAJL/8100873.html:text/html;Mouradian et al\_2018\_A Comprehensive Survey on Fog Computing.pdf:/home/volodia/Zotero/storage/JRIYYWBE/Mouradian et al\_2018\_A Comprehensive Survey on Fog Computing.pdf:application/pdf}
}
@article{mouradian_iot_2020,
	title        = {An {IoT} Platform-as-a-Service for {NFV}-Based Hybrid Cloud/Fog Systems},
	author       = {Mouradian, Carla and Ebrahimnezhad, Fereshteh and Jebbar, Yassine and Ahluwalia, Jasmeen Kaur and Afrasiabi, Seyedeh Negar and Glitho, Roch H. and Moghe, Ashok},
	volume       = 7,
	number       = 7,
	pages        = {6102--6115},
	doi          = {10.1109/JIOT.2020.2968235},
	issn         = {2327-4662},
	note         = {Conference Name: {IEEE} Internet of Things Journal},
	abstract     = {Cloud computing, despite its inherent advantages (e.g., resource efficiency), still faces several challenges. The wide area network used to connect the cloud to end users could cause high latency, which may not be tolerable for some applications, especially Internet-of-Things ({IoT}) applications. Fog computing can reduce this latency by extending the traditional cloud architecture to the edge of the network and by enabling the deployment of some application components on fog nodes. Application providers use Platform-as-a-Service ({PaaS}) to provision (i.e., develop, deploy, manage, and orchestrate) applications in cloud. However, existing {PaaS} solutions (including {IoT} {PaaS}) usually focus on cloud and do not enable provisioning of applications with components spanning cloud and fog. Provisioning such applications requires novel functions, such as application graph generation, that are absent from existing {PaaS}. Furthermore, several functions offered by existing {PaaS} (e.g., publication/discovery) need to be significantly extended in order to fit in a hybrid cloud/fog environment. In this article, we propose a novel architecture for {PaaS} for hybrid cloud/fog system. It is {IoT} use case driven, and its applications' components are implemented as virtual network functions ({VNFs}) with execution sequences modeled as graphs with substructures, such as selection and loops. It automates the provisioning of applications with components spanning cloud and fog. In addition, it enables the discovery of existing cloud and fog nodes and generates application graphs. A proof of concept is built based on Cloudify open source. Feasibility is demonstrated by evaluating its performance when the {PaaS} modules and application components are placed in clouds and fogs in different geographical locations.},
	journaltitle = {{IEEE} Internet of Things Journal},
	date         = {2020-07},
	keywords     = {Cloud computing, Edge computing, Internet of Things ({IoT}), fog computing, Accidents, Computer architecture, Internet of Things, Automobiles, Detectors, network functions virtualization ({NFV}), Platform-as-a-Service ({PaaS})},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/6KI39S9W/8964357.html:text/html;Mouradian et al\_2020\_An IoT Platform-as-a-Service for NFV-Based Hybrid Cloud-Fog Systems.pdf:/home/volodia/Zotero/storage/CFC52AE5/Mouradian et al\_2020\_An IoT Platform-as-a-Service for NFV-Based Hybrid Cloud-Fog Systems.pdf:application/pdf}
}
@inproceedings{afrasiabi_application_2019,
	title        = {Application Components Migration in {NFV}-based Hybrid Cloud/Fog Systems},
	author       = {Afrasiabi, Seyedeh Negar and Kianpisheh, Somayeh and Mouradian, Carla and Glitho, Roch H. and Moghe, Ashok},
	booktitle    = {2019 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	pages        = {1--6},
	doi          = {10.1109/LANMAN.2019.8847126},
	note         = {{ISSN}: 1944-0375},
	abstract     = {Fog computing extends the cloud to the edge of the network, close to the end-users enabling the deployment of some application component in the fog while others in the cloud. Network Functions Virtualization ({NFV}) decouples the network functions from the underlying hardware. In {NFV} settings, application components can be implemented as sets of Virtual Network Functions ({VNFs}) chained in specific order representing {VNF}-Forwarding Graphs ({VNF}-{FG}). Many studies have been carried out to map the {VNF}-{FGs} to cloud systems. However, in hybrid cloud/fog systems, an additional challenge arises. The mobility of fog nodes may cause high latency as the distance between the end-users and the nodes hosting the components increases. This may not be tolerable for some applications. In such cases, a prominent solution is to migrate application components to a closer fog node. This paper focuses on application component migration in {NFV}-based hybrid cloud/fog systems. The objective is to minimize the aggregated makespan of the applications. The problem is modeled mathematically, and a heuristic is proposed to find the sub-optimal solution in an acceptable time. The heuristic aims at finding the optimal fog node in each time-slot considering a pre-knowledge of the mobility models of the fog nodes. The experiment's results show that our proposed solution improves the makespan and the number of migrations compared to random migration and No-migration.},
	eventtitle   = {2019 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	date         = {2019-07},
	keywords     = {Cloud computing, Edge computing, Fog computing, Delays, Task analysis, Drones, Network function virtualization, Network Functions Virtualization ({NFV}), optimization, Heuristic, Migration, Optimization},
	file         = {Afrasiabi et al\_2019\_Application Components Migration in NFV-based Hybrid Cloud-Fog Systems.pdf:/home/volodia/Zotero/storage/Q92EVCUD/Afrasiabi et al\_2019\_Application Components Migration in NFV-based Hybrid Cloud-Fog Systems.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/B5RSD25T/8847126.html:text/html}
}
@article{mouradian_nfv_2018,
	title        = {{NFV} and {SDN}-Based Distributed {IoT} Gateway for Large-Scale Disaster Management},
	author       = {Mouradian, Carla and Jahromi, Narjes Tahghigh and Glitho, Roch H.},
	volume       = 5,
	number       = 5,
	pages        = {4119--4131},
	doi          = {10.1109/JIOT.2018.2867255},
	issn         = {2327-4662},
	note         = {Conference Name: {IEEE} Internet of Things Journal},
	abstract     = {Large-scale disaster management applications are among the several realistic applications of the Internet of Things ({IoT}). Fire detection and earthquake early warning applications are just two examples. Several {IoT} devices are used in such applications, e.g., sensors and robots. These sensors and robots are usually heterogeneous. Moreover, in disaster scenarios, the existing communication infrastructure may become completely or partially destroyed, leaving mobile ad-hoc networks the only alternative to provide connectivity. Utilizing these applications raises new challenges such as the need for dynamic, flexible, and distributed gateways which can accommodate new applications and new {IoT} devices. Network functions virtualization ({NFV}) and software defined networking ({SDN}) are emerging paradigms that can help to overcome these challenges. This paper leverages {NFV} and {SDN} to propose an architecture for on-the-fly distributed gateway provisioning in large-scale disaster management. In the proposed architecture, the gateway functions are provisioned as virtual network functions that are chained on-the-fly in the {IoT} domain using {SDN}. A prototype is built and the performance results are presented.},
	journaltitle = {{IEEE} Internet of Things Journal},
	date         = {2018-10},
	keywords     = {Internet of Things ({IoT}), Logic gates, Internet of Things, Protocols, network functions virtualization ({NFV}), Disaster management, Fires, gateway, Robot sensing systems, software defined networking ({SDN})},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/9KYHKWAY/8447195.html:text/html;Mouradian et al\_2018\_NFV and SDN-Based Distributed IoT Gateway for Large-Scale Disaster Management.pdf:/home/volodia/Zotero/storage/GPSI8MXY/Mouradian et al\_2018\_NFV and SDN-Based Distributed IoT Gateway for Large-Scale Disaster Management.pdf:application/pdf}
}
@inproceedings{giang_developing_2015,
	title        = {Developing {IoT} applications in the Fog: A Distributed Dataflow approach},
	shorttitle   = {Developing {IoT} applications in the Fog},
	author       = {Giang, Nam Ky and Blackstock, Michael and Lea, Rodger and Leung, Victor C.M.},
	booktitle    = {2015 5th International Conference on the Internet of Things ({IOT})},
	pages        = {155--162},
	doi          = {10.1109/IOT.2015.7356560},
	abstract     = {In this paper we examine the development of {IoT} applications from the perspective of the Fog Computing paradigm, where computing infrastructure at the network edge in devices and gateways is leverage for efficiency and timeliness. Due to the intrinsic nature of the {IoT}: heterogeneous devices/resources, a tightly coupled perception-action cycle and widely distributed devices and processing, application development in the Fog can be challenging. To address these challenges, we propose a Distributed Dataflow ({DDF}) programming model for the {IoT} that utilises computing infrastructures across the Fog and the Cloud. We evaluate our proposal by implementing a {DDF} framework based on Node-{RED} (Distributed Node-{RED} or D-{NR}), a visual programming tool that uses a flow-based model for building {IoT} applications. Via demonstrations, we show that our approach eases the development process and can be used to build a variety of {IoT} applications that work efficiently in the Fog.},
	eventtitle   = {2015 5th International Conference on the Internet of Things ({IOT})},
	date         = {2015-10},
	keywords     = {Cloud computing, Internet of things, Computational modeling, Logic gates, Programming, Buildings, Internet of Things, Distributed dataflow, Node-{RED}, Programming models, Scalability},
	file         = {Giang et al\_2015\_Developing IoT applications in the Fog.pdf:/home/volodia/Zotero/storage/P6D67XU3/Giang et al\_2015\_Developing IoT applications in the Fog.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DLH6FY55/7356560.html:text/html}
}
@inproceedings{zaheer_multi-provider_2010,
	title        = {Multi-provider service negotiation and contracting in network virtualization},
	author       = {Zaheer, Fida-E and Xiao, Jin and Boutaba, Raouf},
	booktitle    = {2010 {IEEE} Network Operations and Management Symposium - {NOMS} 2010},
	pages        = {471--478},
	doi          = {10.1109/NOMS.2010.5488487},
	note         = {{ISSN}: 2374-9709},
	abstract     = {Network virtualization environment ({VNE}) affords great business flexibility to the customers and the providers as multiple providers can jointly support a customer's virtual network. Under the current network model, a group of Infrastructure Providers ({InPs}) peer with each other to provide a packaged deal. Such a business arrangement is not customer-driven, does not promote fair market competition and does not ensure cost minimization. Furthermore, the on-demand nature of virtual networks requires efficient and automated service negotiation and contracting. In this paper, we present V-Mart. To the {InPs}, V-Mart offers an environment to participate in a faithful and fair competition over the {VN} resources; and to the {SPs}, it offers a customer-driven virtual resource partitioning and contracting engine. V-Mart uses a two-stage Vickrey auction model that is strategy-proof, flexible to diverse {InP} pricing models, and functions over heterogenous multi-commodity market that characterizes the {NVE}. Through analysis and simulation we show the flexibility and effectiveness of V-Mart.},
	eventtitle   = {2010 {IEEE} Network Operations and Management Symposium - {NOMS} 2010},
	date         = {2010-04},
	keywords     = {Pricing, Computer science, Costs, Engines, Indium phosphide, Packaging, Peer to peer computing, Resource virtualization, Routing protocols, Service oriented architecture},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DXW9PT6L/5488487.html:text/html;Zaheer et al\_2010\_Multi-provider service negotiation and contracting in network virtualization.pdf:/home/volodia/Zotero/storage/98YAUWC4/Zaheer et al\_2010\_Multi-provider service negotiation and contracting in network virtualization.pdf:application/pdf}
}
@article{landa_self-tuning_2016,
	title        = {Self-Tuning Service Provisioning for Decentralized Cloud Applications},
	author       = {Landa, Raul and Charalambides, Marinos and Clegg, Richard G. and Griffin, David and Rio, Miguel},
	volume       = 13,
	number       = 2,
	pages        = {197--211},
	doi          = {10.1109/TNSM.2016.2549698},
	issn         = {1932-4537},
	note         = {Conference Name: {IEEE} Transactions on Network and Service Management},
	abstract     = {Cloud computing has revolutionized service delivery by providing on-demand invocation and elasticity. To reap these benefits, computation has been displaced from client devices and into data centers. This partial centralization is undesirable for applications that have stringent locality requirements, e.g., low latency. This problem could be addressed with large numbers of smaller cloud resources closer to users. However, as cloud computing diffuses from within data centers and into the network, there will be a need for cloud resource allocation algorithms that operate on resource-constrained computational units that serve localized subsets of customers. In this paper, we present a mechanism for service provisioning in distributed clouds where applications compete for resources. The mechanism operates by enabling execution zones to assign resources based on Vickrey auctions and provides high-quality probabilistic models that applications can use to predict the outcomes of such auctions. This allows applications to use knowledge of the locality distribution of their clients to accurately select the number of bids to be sent to each execution zone and their value. The proposed mechanism is highly scalable, efficient, and validated by extensive simulations.},
	journaltitle = {{IEEE} Transactions on Network and Service Management},
	date         = {2016-06},
	keywords     = {Cloud computing, Quality of service, Computational modeling, Resource management, Measurement, Bandwidth, Cloud Resource Management, Decentralized Cloud Applications, Heuristic algorithms, Quality of Experience, Vickrey Auctions},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/I7DYIWCF/7445875.html:text/html;Landa et al\_2016\_Self-Tuning Service Provisioning for Decentralized Cloud Applications.pdf:/home/volodia/Zotero/storage/LRTLT3XE/Landa et al\_2016\_Self-Tuning Service Provisioning for Decentralized Cloud Applications.pdf:application/pdf}
}
@inproceedings{cheng_geelytics_2016,
	title        = {Geelytics: Enabling On-Demand Edge Analytics over Scoped Data Sources},
	shorttitle   = {Geelytics},
	author       = {Cheng, Bin and Papageorgiou, Apostolos and Bauer, Martin},
	booktitle    = {2016 {IEEE} International Congress on Big Data ({BigData} Congress)},
	pages        = {101--108},
	doi          = {10.1109/BigDataCongress.2016.21},
	abstract     = {Large-scale Internet of Things ({IoT}) systems typically consist of a large number of sensors and actuators distributed geographically in a physical environment. To react fast on real time situations, it is often required to bridge sensors and actuators via real-time stream processing close to {IoT} devices. Existing stream processing platforms like Apache Storm and S4 are designed for intensive stream processing in a cluster or in the Cloud, but they are unsuitable for large scale {IoT} systems in which processing tasks are expected to be triggered by actuators on-demand and then be allocated and performed in a Cloud-Edge environment. To fill this gap, we designed and implemented a new system called Geelytics, which can enable on-demand edge analytics over scoped data sources via {IoT}-friendly interfaces to sensors and actuators. This paper presents its design, implementation, interfaces, and core algorithms. Three example applications have been built to showcase the potential of Geelytics in enabling advanced {IoT} edge analytics. Our preliminary evaluation results demonstrate that we can reduce the bandwidth cost by 99\% in a face detection example, achieve less than 10 milliseconds reacting latency and about 1.5 seconds startup latency in an outlier detection example, and also save 65\% duplicated computation cost via sharing intermediate results in a data aggregation example.},
	eventtitle   = {2016 {IEEE} International Congress on Big Data ({BigData} Congress)},
	date         = {2016-06},
	keywords     = {edge computing, Cloud computing, Internet of things, Real-time systems, {IoT}, Actuators, edge analytics, Sensor systems, stream processing},
	file         = {Cheng et al\_2016\_Geelytics.pdf:/home/volodia/Zotero/storage/6IVXZ5PR/Cheng et al\_2016\_Geelytics.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/DTJ4K2UB/7584926.html:text/html}
}
@article{grambow_befaas_2021,
	title        = {{BeFaaS}: An Application-Centric Benchmarking Framework for {FaaS} Platforms},
	shorttitle   = {{BeFaaS}},
	author       = {Grambow, Martin and Pfandzelter, Tobias and Burchard, Luk and Schubert, Carsten and Zhao, Max and Bermbach, David},
	url          = {http://arxiv.org/abs/2102.12770},
	urldate      = {2022-02-16},
	abstract     = {Following the increasing interest and adoption of {FaaS} systems, benchmarking frameworks for determining non-functional properties have also emerged. While existing (microbenchmark) frameworks only evaluate single aspects of {FaaS} platforms, a more holistic, application-driven approach is still missing. In this paper, we design and present {BeFaaS}, an extensible application-centric benchmarking framework for {FaaS} environments that focuses on the evaluation of {FaaS} platforms through realistic and typical examples of {FaaS} applications. {BeFaaS} includes a built-in e-commerce benchmark, is extensible for new workload profiles and new platforms, supports federated benchmark runs in which the benchmark application is distributed over multiple providers, and supports a fine-grained result analysis. Our evaluation compares three major {FaaS} providers in single cloud provider setups and shows that {BeFaaS} is capable of running each benchmark automatically with minimal configuration effort and providing detailed insights for each interaction.},
	journaltitle = {{arXiv}:2102.12770 [cs]},
	date         = {2021-11-01},
	eprinttype   = {arxiv},
	eprint       = {2102.12770},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/FKGHBRMP/2102.html:text/html;Grambow et al\_2021\_BeFaaS.pdf:/home/volodia/Zotero/storage/J63SP9W4/Grambow et al\_2021\_BeFaaS.pdf:application/pdf}
}
@online{strycek_deploying_nodate,
	title        = {Deploying Redis to Kubernetes cluster K3s},
	author       = {Strycek, Vladimir},
	url          = {https://rpi4cluster.com/k3s/k3s-redis/},
	urldate      = {2022-02-18},
	abstract     = {Deployment yaml files for simple Redis deployment to Kubernetes K3s cluster on Raspberry Pi 4.},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/QSAZMAED/k3s-redis.html:text/html}
}
@inproceedings{ahmed_docker_2020,
	title        = {Docker Container Deployment in Distributed Fog Infrastructures with Checkpoint/Restart},
	author       = {Ahmed, Arif and Mohan, Apoorve and Cooperman, Gene and Pierre, Guillaume},
	booktitle    = {2020 8th {IEEE} International Conference on Mobile Cloud Computing, Services, and Engineering ({MobileCloud})},
	location     = {Oxford, {GB}},
	publisher    = {{IEEE}},
	pages        = {55--62},
	doi          = {10.1109/MobileCloud48802.2020.00016},
	isbn         = {978-1-72811-035-6},
	url          = {https://ieeexplore.ieee.org/document/9126743/},
	urldate      = {2022-02-21},
	abstract     = {In fog computing environments container deployment is a frequent operation which often lies in the critical path of services being delivered to an end user. Although creating a container can be very fast, the container's application needs to start before the container starts producing useful work. Depending on the application this startup process can be arbitrarily long. To speed up the application startup times we propose to snapshot the state of fully-deployed containers and restart future container instances from a pre-started application state. In our evaluations based on 14 real micro-service containers, this technique effectively reduces the startup phase with speedups between 1x (no speedup) and 60x.},
	eventtitle   = {2020 8th {IEEE} International Conference on Mobile Cloud Computing, Services, and Engineering ({MobileCloud})},
	date         = {2020-08},
	langid       = {english},
	file         = {Ahmed et al. - 2020 - Docker Container Deployment in Distributed Fog Inf.pdf:/home/volodia/Zotero/storage/WGVHSKC6/Ahmed et al. - 2020 - Docker Container Deployment in Distributed Fog Inf.pdf:application/pdf}
}
@inproceedings{siasi_tabu_2019,
	title        = {Tabu Search for Efficient Service Function Chain Provisioning in Fog Networks},
	author       = {Siasi, Nazli and Jaesim, Adrian and Ghani, Nasir},
	booktitle    = {2019 {IEEE} 5th International Conference on Collaboration and Internet Computing ({CIC})},
	pages        = {145--150},
	doi          = {10.1109/CIC48465.2019.00026},
	abstract     = {Fog computing places computation/storage resources at the network edge to overcome delay limitations associated with cloud computing. Namely, fog-based services can provide more responsive relay and caching and alleviate loads at core cloud datacenters. Meanwhile, technologies such as network function virtualization ({NFV}) are virtualizing atomic network functions and allowing provides to build customized service function chains ({SFC}). Hence combining {NFV} with fog computing allows providers to share critical edge resources across clients and achieve much more flexible service designs. However, few efforts have looked at {SFC} provisioning in fog domains. Hence this paper presents one of the first studies in this area, detailing a Tabu search for virtual function placement and heuristic routing schemes with load balancing for efficient resource utilization. Results show reduced processing and propagation times, and lower energy consumption versus cloud-based methods.},
	eventtitle   = {2019 {IEEE} 5th International Conference on Collaboration and Internet Computing ({CIC})},
	date         = {2019-12},
	keywords     = {Cloud computing, Edge computing, Delays, Real-time systems, Network function virtualization, Bandwidth, Cloud computing, fog computing, network function virtualization, service function chaining, Tabu search},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/V8ZTPZ5A/8998512.html:text/html;Siasi et al\_2019\_Tabu Search for Efficient Service Function Chain Provisioning in Fog Networks.pdf:/home/volodia/Zotero/storage/FZZ47BJ4/Siasi et al\_2019\_Tabu Search for Efficient Service Function Chain Provisioning in Fog Networks.pdf:application/pdf}
}
@inproceedings{mouradian_application_2018,
	title        = {Application Component Placement in {NFV}-based Hybrid Cloud/Fog Systems},
	author       = {Mouradian, Carla and Kianpisheh, Somayeh and Glitho, Roch H.},
	booktitle    = {2018 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	pages        = {25--30},
	doi          = {10.1109/LANMAN.2018.8475055},
	note         = {{ISSN}: 1944-0375},
	abstract     = {Applications are sets of interacting components that can be executed in sequence, in parallel, or by using more complex constructs such as selections and loops. They can, therefore, be modeled as structured graphs with sub-structures consisting of these constructs. Fog computing can reduce the latency induced by distant clouds by enabling the deployment of some components at the edge of the network (i.e., closer to end-devices) while keeping others in the cloud. Network Functions Virtualization ({NFV}) decouples software from hardware and enables an agile deployment of network services and applications as Virtual Network Functions ({VNFs}). In {NFV} settings, efficient placement algorithms are required to map the structured graphs representing the {VNF} Forwarding Graphs ({VNF}-{FGs}) onto the infrastructure of the hybrid cloud/fog system. Only deterministic graphs with sequence and parallel sub-structures have been considered thus to date. However, several real-life applications do require non-deterministic graphs with sub-structures as selections and loops. This paper focuses on application component placement in {NFV}-based hybrid cloud/fog systems, with the assumption that the graph representing the application is non-deterministic. The objective is to minimize an aggregated weighted function of makespan and cost. The problem is modeled as an Integer Linear Programming ({ILP}) and evaluated over small-scale scenarios using the {CPLEX} optimization tool.},
	eventtitle   = {2018 {IEEE} International Symposium on Local and Metropolitan Area Networks ({LANMAN})},
	date         = {2018-06},
	keywords     = {Cloud computing, Edge computing, Fog computing, Internet of Things ({IoT}), Delays, Network function virtualization, Network Functions Virtualization ({NFV}), Bandwidth, Hardware, Minimization, {VNF} Forwarding Graph Placement},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/J5F6DWY5/8475055.html:text/html;Mouradian et al\_2018\_Application Component Placement in NFV-based Hybrid Cloud-Fog Systems.pdf:/home/volodia/Zotero/storage/CIZZII3U/Mouradian et al\_2018\_Application Component Placement in NFV-based Hybrid Cloud-Fog Systems.pdf:application/pdf}
}
@inproceedings{ebrahimzadeh_h-horizon_2021,
	title        = {h-Horizon Sequential Look-ahead Greedy Algorithm for {VNF}-{FG} Embedding},
	author       = {Ebrahimzadeh, Amin and Promwongsa, Nattakorn and Afrasiabi, Seyedeh Negar and Mouradian, Carla and Li, Wubin and Recse, \'{A}kos and Szab\'{o}, R\'{o}bert and Glitho, Roch. H.},
	booktitle    = {2021 {IEEE} Conference on Network Function Virtualization and Software Defined Networks ({NFV}-{SDN})},
	pages        = {41--46},
	doi          = {10.1109/NFV-SDN53031.2021.9665063},
	abstract     = {5G service providers consider Network Function Virtualization ({NFV}) as an enabler to foster new opportunities to scale their business while reducing operational expenses. {NFV} builds on cloud native technologies, automation, and reusability. Central to the success of {NFV} is the ability to design service templates once and to on-demand deploy those template services into specific service contexts, e.g., network slices. Therefore, on-demand homing and assigning of service designs with service level requirements over distributed cloud resources and capabilities is one of the main challenges for the transition to {NFV}. Towards this end, it is important to embed service graphs over the given infrastructure such that the total cost is minimized while satisfying service requirements. To get around the lack of scalability of optimization-based approaches, a viable approach is to rely on efficient Virtual Network Function ({VNF}) embedding heuristics. Despite their low complexity, {VNF} embedding heuristics suffer from the so-called causality issue, which means that embedding decisions must be made before all neighboring dependencies were embedded. This, as a result, may lead to an inferior embedding outcome. In this paper, we propose our novel h-horizon sequential greedy look-ahead embedding algorithm, which allows embedding and re-embedding of {VNFs} based on embedding decisions of other {VNFs} to overcome the causality issue. Our simulation results indicate that our proposed algorithm outperforms the existing greedy benchmark in terms of total embedding cost.},
	eventtitle   = {2021 {IEEE} Conference on Network Function Virtualization and Software Defined Networks ({NFV}-{SDN})},
	date         = {2021-11},
	keywords     = {Cloud computing, Simulation, Conferences, Scalability, Costs, Greedy algorithms, Software algorithms},
	file         = {Ebrahimzadeh et al\_2021\_h-Horizon Sequential Look-ahead Greedy Algorithm for VNF-FG Embedding.pdf:/home/volodia/Zotero/storage/SPD5UBRJ/Ebrahimzadeh et al\_2021\_h-Horizon Sequential Look-ahead Greedy Algorithm for VNF-FG Embedding.pdf:application/pdf;IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/SUS3E9ZA/9665063.html:text/html}
}
@inproceedings{pereira_energy_2017,
	title        = {Energy efficiency across programming languages: how do energy, time, and memory relate?},
	shorttitle   = {Energy efficiency across programming languages},
	author       = {Pereira, Rui and Couto, Marco and Ribeiro, Francisco and Rua, Rui and Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and Saraiva, Jo\~{a}o},
	booktitle    = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Software Language Engineering},
	location     = {Vancouver {BC} Canada},
	publisher    = {{ACM}},
	pages        = {256--267},
	doi          = {10.1145/3136014.3136031},
	isbn         = {978-1-4503-5525-4},
	url          = {https://dl.acm.org/doi/10.1145/3136014.3136031},
	urldate      = {2022-02-22},
	abstract     = {This paper presents a study of the runtime, memory usage and energy consumption of twenty seven well-known software languages. We monitor the performance of such languages using ten different programming problems, expressed in each of the languages. Our results show interesting findings, such as, slower/faster languages consuming less/more energy, and how memory usage influences energy consumption. We show how to use our results to provide software engineers support to decide which language to use when energy efficiency is a concern.},
	eventtitle   = {{SPLASH} '17: Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
	date         = {2017-10-23},
	langid       = {english},
	file         = {Pereira et al. - 2017 - Energy efficiency across programming languages ho.pdf:/home/volodia/Zotero/storage/ZXVJYD5I/Pereira et al. - 2017 - Energy efficiency across programming languages ho.pdf:application/pdf}
}
@online{noauthor_getting_nodate,
	title        = {Getting Started - Grid5000},
	url          = {https://www.grid5000.fr/w/Getting\%5FStarted\#Connecting\%5Ffor\%5Fthe\%5Ffirst\%5Ftime},
	urldate      = {2022-02-22},
	file         = {Getting Started - Grid5000:/home/volodia/Zotero/storage/YIABZM73/Getting\_Started.html:text/html}
}
@incollection{mittal_mu_2021,
	title        = {Mu: An Efficient, Fair and Responsive Serverless Framework for Resource-Constrained Edge Clouds},
	shorttitle   = {Mu},
	author       = {Mittal, Viyom and Qi, Shixiong and Bhattacharya, Ratnadeep and Lyu, Xiaosu and Li, Junfeng and Kulkarni, Sameer G. and Li, Dan and Hwang, Jinho and Ramakrishnan, K. K. and Wood, Timothy},
	booktitle    = {Proceedings of the {ACM} Symposium on Cloud Computing},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	pages        = {168--181},
	isbn         = {978-1-4503-8638-8},
	url          = {https://doi.org/10.1145/3472883.3487014},
	urldate      = {2022-02-25},
	abstract     = {Serverless computing platforms simplify development, deployment, and automated management of modular software functions. However, existing serverless platforms typically assume an over-provisioned cloud, making them a poor fit for Edge Computing environments where resources are scarce. In this paper we propose a redesigned serverless platform that comprehensively tackles the key challenges for serverless functions in a resource constrained Edge Cloud. Our Mu platform cleanly integrates the core resource management components of a serverless platform: autoscaling, load balancing, and placement. Each worker node in Mu transparently propagates metrics such as service rate and queue length in response headers, feeding this information to the load balancing system so that it can better route requests, and to our autoscaler to anticipate workload fluctuations and proactively meet {SLOs}. Data from the Autoscaler is then used by the placement engine to account for heterogeneity and fairness across competing functions, ensuring overall resource efficiency, and minimizing resource fragmentation. We implement our design as a set of extensions to the Knative serverless platform and demonstrate its improvements in terms of resource efficiency, fairness, and response time. Evaluating Mu, shows that it improves fairness by more than 2x over the default Kubernetes placement engine, improves 99th percentile response times by 62\% through better load balancing, reduces {SLO} violations and resource consumption by pro-active and precise autoscaling. Mu reduces the average number of pods required by more than {\textasciitilde}15\% for a set of real Azure workloads.},
	date         = {2021-11-01},
	keywords     = {serverless, Edge clouds, resource management},
	file         = {Mittal et al\_2021\_Mu.pdf:/home/volodia/Zotero/storage/6RSWI84C/Mittal et al\_2021\_Mu.pdf:application/pdf}
}
@online{noauthor_fogbus2_nodate,
	title        = {{FogBus}2 {\textbar} Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
	url          = {https://dl.acm.org/doi/abs/10.1145/3460866.3461768},
	urldate      = {2022-02-25},
	file         = {FogBus2 \vert{} Proceedings of the International Workshop on Big Data in Emergent Distributed Environments:/home/volodia/Zotero/storage/7UT85HBP/3460866.html:text/html}
}
@incollection{deng_fogbus2_2021,
	title        = {{FogBus}2: a lightweight and distributed container-based framework for integration of {IoT}-enabled systems with edge and cloud computing},
	shorttitle   = {{FogBus}2},
	author       = {Deng, Qifan and Goudarzi, Mohammad and Buyya, Rajkumar},
	booktitle    = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	number       = 4,
	pages        = {1--8},
	isbn         = {978-1-4503-8465-0},
	url          = {https://doi.org/10.1145/3460866.3461768},
	urldate      = {2022-02-25},
	abstract     = {Edge/Fog computing is a novel computing paradigm that provides resource-limited Internet of Things ({IoT}) devices with scalable computing and storage resources. Compared to cloud computing, edge/fog servers have fewer resources, but they can be accessed with higher bandwidth and less communication latency. Thus, integrating edge/fog and cloud infrastructures can support the execution of diverse latency-sensitive and computation-intensive {IoT} applications. Although some frameworks attempt to provide such integration, there are still several challenges to be addressed, such as dynamic scheduling of different {IoT} applications, scalability mechanisms, multi-platform support, and supporting different interaction models. To overcome these challenges, we propose a lightweight and distributed container-based framework, called {FogBus}2. It provides a mechanism for scheduling heterogeneous {IoT} applications and implements several scheduling policies. Also, it proposes an optimized genetic algorithm to obtain fast convergence to well-suited solutions. Besides, it offers a scalability mechanism to ensure efficient responsiveness when either the number of {IoT} devices increases or the resources become overburdened. Also, the dynamic resource discovery mechanism of {FogBus}2 assists new entities to quickly join the system. We have also developed two {IoT} applications, called Conway's Game of Life and Video Optical Character Recognition to demonstrate the effectiveness of {FogBus}2 for handling real-time and non-real-time {IoT} applications. Experimental results show {FogBus}2's scheduling policy improves the response time of {IoT} applications by 53\% compared to other policies. Also, the scalability mechanism can reduce up to 48\% of the queuing waiting time compared to frameworks that do not support scalability.},
	date         = {2021-06-20},
	keywords     = {internet of things, containers scheduling, edge/fog computing, scalability},
	file         = {Deng et al\_2021\_FogBus2.pdf:/home/volodia/Zotero/storage/QWBCTYYX/Deng et al\_2021\_FogBus2.pdf:application/pdf}
}
@inproceedings{mortazavi_cloudpath_2017,
	title        = {Cloudpath: a multi-tier cloud computing framework},
	shorttitle   = {Cloudpath},
	author       = {Mortazavi, Seyed Hossein and Salehe, Mohammad and Gomes, Carolina Simoes and Phillips, Caleb and de Lara, Eyal},
	booktitle    = {Proceedings of the Second {ACM}/{IEEE} Symposium on Edge Computing},
	location     = {San Jose California},
	publisher    = {{ACM}},
	pages        = {1--13},
	doi          = {10.1145/3132211.3134464},
	isbn         = {978-1-4503-5087-7},
	url          = {https://dl.acm.org/doi/10.1145/3132211.3134464},
	urldate      = {2022-02-25},
	abstract     = {Path computing is a new paradigm that generalizes the edge computing vision into a multi-tier cloud architecture deployed over the geographic span of the network. Path computing supports scalable and localized processing by providing storage and computation along a succession of datacenters of increasing sizes, positioned between the client device and the traditional wide-area cloud datacenter. {CloudPath} is a platform that implements the path computing paradigm. {CloudPath} consists of an execution environment that enables the dynamic installation of light-weight stateless event handlers, and a distributed eventual consistent storage system that replicates application data on-demand. {CloudPath} handlers are small, allowing them to be rapidly instantiated on demand on any server that runs the {CloudPath} execution framework. In turn, {CloudPath} automatically migrates application data across the multiple datacenter tiers to optimize access latency and reduce bandwidth consumption.},
	eventtitle   = {{SEC} '17: {IEEE}/{ACM} Symposium on Edge Computing},
	date         = {2017-10-12},
	langid       = {english},
	file         = {Mortazavi et al. - 2017 - Cloudpath a multi-tier cloud computing framework.pdf:/home/volodia/Zotero/storage/VW3SRA2C/Mortazavi et al. - 2017 - Cloudpath a multi-tier cloud computing framework.pdf:application/pdf}
}
@article{weyl_online_2017,
	title        = {An Online Appendix to 'Depreciating Licenses'},
	author       = {Weyl, E. Glen and Zhang, Anthony Lee},
	doi          = {10.2139/ssrn.3034480},
	issn         = {1556-5068},
	url          = {https://www.ssrn.com/abstract=3034480},
	urldate      = {2022-03-02},
	journaltitle = {{SSRN} Electronic Journal},
	shortjournal = {{SSRN} Journal},
	date         = 2017,
	langid       = {english},
	file         = {Weyl and Zhang - 2017 - An Online Appendix to 'Depreciating Licenses'.pdf:/home/volodia/Zotero/storage/C9CSDNYZ/Weyl and Zhang - 2017 - An Online Appendix to 'Depreciating Licenses'.pdf:application/pdf}
}
@report{weyl_depreciating_2021,
	title        = {Depreciating Licenses},
	author       = {Weyl, E. Glen and Zhang, Anthony Lee},
	location     = {Rochester, {NY}},
	number       = {{ID} 3698941},
	doi          = {10.2139/ssrn.3698941},
	url          = {https://papers.ssrn.com/abstract=3698941},
	urldate      = {2022-03-02},
	abstract     = {Many governments assign use licenses for natural resources, such as radio spectrum, fishing rights, and mineral extraction rights, through auctions or other market-like mechanisms. License design affects resource users' investment incentives, as well as the efficiency of asset allocation. No existing license design achieves first-best outcomes on both dimensions. Long-term licenses have high-investment incentives, but impede reallocation to high-valued entrants. Short-term licenses improve allocative efficiency but discourage investment. We propose a simple new mechanism, the depreciating license, and we argue that it navigates this tradeoff more effectively than existing license designs.},
	institution  = {Social Science Research Network},
	type         = {{SSRN} Scholarly Paper},
	date         = {2021-04-28},
	langid       = {english},
	keywords     = {depreciating license, investment, misallocation, property rights},
	file         = {Snapshot:/home/volodia/Zotero/storage/XSYIE2UF/papers.html:text/html;Weyl\_Zhang\_2021\_Depreciating Licenses.pdf:/home/volodia/Zotero/storage/QINBPA5H/Weyl\_Zhang\_2021\_Depreciating Licenses.pdf:application/pdf}
}
@article{baranwal_fair_2015,
	title        = {A fair multi-attribute combinatorial double auction model for resource allocation in cloud computing},
	author       = {Baranwal, Gaurav and Vidyarthi, Deo Prakash},
	volume       = 108,
	pages        = {60--76},
	doi          = {10.1016/j.jss.2015.06.025},
	issn         = {0164-1212},
	url          = {https://www.sciencedirect.com/science/article/pii/S0164121215001272},
	urldate      = {2022-03-03},
	abstract     = {Recently, Cloud computing has emerged as a market where computing related resources are treated as a utility and are priced. There is a big competition among the Cloud service providers and therefore, the providers offer the services strategically. Auction, a market based resource allocation strategy, has received the attention among the Cloud researchers recently. The auction principal of resource allocation is based on demand and supply. This work proposes a multi-attribute combinatorial double auction for the allocation of Cloud resources, which not only considers the price but other quality of service parameters also. Auctioneer extends some of the parameters to the offered bids from the bidders in order to provide fairness and robustness. In case of not meeting the assured quality, a penalty is imposed on the provider and customer is compensated. The reputation of the provider also diminishes in the forthcoming rounds. Performance study of the proposed model is done by simulation which reflects the usefulness of the method.},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	date         = {2015-10-01},
	langid       = {english},
	keywords     = {Cloud resources, Double auction, Multi-attribute},
	file         = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/TRCWP5QM/S0164121215001272.html:text/html}
}
@article{nguyen_market-based_2019,
	title        = {A Market-Based Framework for Multi-Resource Allocation in Fog Computing},
	author       = {Nguyen, Duong Tung and Le, Long Bao and Bhargava, Vijay K.},
	volume       = 27,
	number       = 3,
	pages        = {1151--1164},
	doi          = {10.1109/TNET.2019.2912077},
	issn         = {1558-2566},
	note         = {Conference Name: {IEEE}/{ACM} Transactions on Networking},
	abstract     = {Fog computing is transforming the network edge into an intelligent platform by bringing storage, computing, control, and networking functions closer to end users, things, and sensors. How to allocate multiple resource types (e.g., {CPU}, memory, bandwidth) of capacity-limited heterogeneous fog nodes to competing services with diverse requirements and preferences in a fair and efficient manner is a challenging task. To this end, we propose a novel market-based resource allocation framework in which the services act as buyers and fog resources act as divisible goods in the market. The proposed framework aims to compute a market equilibrium ({ME}) solution at which every service obtains its favorite resource bundle under the budget constraint, while the system achieves high resource utilization. This paper extends the general equilibrium literature by considering a practical case of satiated utility functions. In addition, we introduce the notions of non-wastefulness and frugality for equilibrium selection and rigorously demonstrate that all the non-wasteful and frugal {ME} are the optimal solutions to a convex program. Furthermore, the proposed equilibrium is shown to possess salient fairness properties, including envy-freeness, sharing-incentive, and proportionality. Another major contribution of this paper is to develop a privacy-preserving distributed algorithm, which is of independent interest, for computing an {ME} while allowing market participants to obfuscate their private information. Finally, extensive performance evaluation is conducted to verify our theoretical analyses.},
	journaltitle = {{IEEE}/{ACM} Transactions on Networking},
	date         = {2019-06},
	keywords     = {Cloud computing, Edge computing, Computational modeling, fog computing, Resource management, Sensors, Companies, General equilibrium, Germanium, multi-resource allocation, privacy-preserving distributed optimization},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/C24ZP4JR/8700615.html:text/html;Nguyen et al\_2019\_A Market-Based Framework for Multi-Resource Allocation in Fog Computing.pdf:/home/volodia/Zotero/storage/MV3JL6CG/Nguyen et al\_2019\_A Market-Based Framework for Multi-Resource Allocation in Fog Computing.pdf:application/pdf}
}
@inproceedings{kayal_distributed_2019,
	title        = {Distributed Service Placement in Fog Computing: An Iterative Combinatorial Auction Approach},
	shorttitle   = {Distributed Service Placement in Fog Computing},
	author       = {Kayal, Paridhika and Liebeherr, J\"{o}rg},
	booktitle    = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	pages        = {2145--2156},
	doi          = {10.1109/ICDCS.2019.00211},
	note         = {{ISSN}: 2575-8411},
	abstract     = {A primary concern in fog computing is how to efficiently allocate limited fog resources to applications with diverse resource requirements. In fog computing, applications that consist of a set of interdependent microservices are mapped to computing and communication devices, referred to as fog nodes. While placement of microservices can be done centrally, the essentially decentralized infrastructure of participating end-user devices motivates the search for distributed solutions. In this paper, we present a distributed placement strategy that seeks to optimize energy consumption and communication costs. We devise a game-theoretic approximation method that is inspired by an iterative combinatorial auction. By properly restricting the types of bids that can be made in an auction, we can avoid the need for a centralized auctioneer. We devise a fully distributed service placement algorithm without central coordination or global state information. The algorithm operates in rounds, where the number of rounds is bounded by the number of applications and the total number of microservices. Numerical examples show that our placement algorithm outperforms existing heuristics in terms of efficiency and network utilization while achieving comparable utilization and load balancing.},
	eventtitle   = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	date         = {2019-07},
	keywords     = {Edge computing, Resource management, Internet of Things, Optimization, Approximation algorithms, Energy consumption, Fog computing, resource allocation, iterative combinatorial auction, Indexes},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/SLQSMDN9/8885368.html:text/html;Kayal\_Liebeherr\_2019\_Distributed Service Placement in Fog Computing.pdf:/home/volodia/Zotero/storage/7P5HWUQB/Kayal\_Liebeherr\_2019\_Distributed Service Placement in Fog Computing.pdf:application/pdf}
}
@article{babaioff_era_2017,
	title        = {{ERA}: A Framework for Economic Resource Allocation for the Cloud},
	shorttitle   = {{ERA}},
	author       = {Babaioff, Moshe and Mansour, Yishay and Nisan, Noam and Noti, Gali and Curino, Carlo and Ganapathy, Nar and Menache, Ishai and Reingold, Omer and Tennenholtz, Moshe and Timnat, Erez},
	pages        = {635--642},
	doi          = {10.1145/3041021.3054186},
	url          = {http://arxiv.org/abs/1702.07311},
	urldate      = {2022-03-09},
	abstract     = {Cloud computing has reached significant maturity from a systems perspective, but currently deployed solutions rely on rather basic economics mechanisms that yield suboptimal allocation of the costly hardware resources. In this paper we present Economic Resource Allocation ({ERA}), a complete framework for scheduling and pricing cloud resources, aimed at increasing the efficiency of cloud resources usage by allocating resources according to economic principles. The {ERA} architecture carefully abstracts the underlying cloud infrastructure, enabling the development of scheduling and pricing algorithms independently of the concrete lower-level cloud infrastructure and independently of its concerns. Specifically, {ERA} is designed as a flexible layer that can sit on top of any cloud system and interfaces with both the cloud resource manager and with the users who reserve resources to run their jobs. The jobs are scheduled based on prices that are dynamically calculated according to the predicted demand. Additionally, {ERA} provides a key internal {API} to pluggable algorithmic modules that include scheduling, pricing and demand prediction. We provide a proof-of-concept software and demonstrate the effectiveness of the architecture by testing {ERA} over both public and private cloud systems -- Azure Batch of Microsoft and Hadoop/{YARN}. A broader intent of our work is to foster collaborations between economics and system communities. To that end, we have developed a simulation platform via which economics and system experts can test their algorithmic implementations.},
	journaltitle = {Proceedings of the 26th International Conference on World Wide Web Companion - {WWW} '17 Companion},
	date         = 2017,
	eprinttype   = {arxiv},
	eprint       = {1702.07311},
	keywords     = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Computer Science and Game Theory},
	file         = {arXiv.org Snapshot:/home/volodia/Zotero/storage/KMM8WGG5/1702.html:text/html;Babaioff et al\_2017\_ERA.pdf:/home/volodia/Zotero/storage/H5QL5DWH/Babaioff et al\_2017\_ERA.pdf:application/pdf}
}
@article{cherrueau_enoslib_2022,
	title        = {{EnosLib}: A Library for Experiment-Driven Research in Distributed Computing},
	shorttitle   = {{EnosLib}},
	author       = {Cherrueau, Ronan-Alexandre and Delavergne, Marie and van Kempen, Alexandre and Lebre, Adrien and Pertin, Dimitri and Balderrama, Javier Rojas and Simonet, Anthony and Simonin, Matthieu},
	volume       = 33,
	number       = 6,
	pages        = {1464--1477},
	doi          = {10.1109/TPDS.2021.3111159},
	issn         = {1558-2183},
	note         = {Conference Name: {IEEE} Transactions on Parallel and Distributed Systems},
	abstract     = {Despite the importance of experiment-driven research in the distributed computing community, there has been little progress in helping researchers conduct their experiments. In most cases, they have to achieve tedious and time-consuming development and instrumentation activities to deal with the specifics of testbeds and the system under study. In order to relieve researchers of the burden of those efforts, we have developed {EnosLib}: a Python library that takes into account best experimentation practices and leverages modern toolkits on automatic deployment and configuration systems. {EnosLib} helps researchers not only in the process of developing their experimental artifacts, but also in running them over different infrastructures. To demonstrate the relevance of our library, we discuss three experimental engines built on top of {EnosLib}, and used to conduct empirical studies on complex software stacks between 2016 and 2019 (database systems, communication buses and {OpenStack}). By introducing {EnosLib}, our goal is to gather academic and industrial actors of our community around a library that aggregates everyday experiment-driven research operations. A library that has been already adopted by open-source projects and members of the scientific community thanks to its ease of use and extension.},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	date         = {2022-06},
	keywords     = {performance evaluation, Task analysis, Protocols, Tools, Benchmark testing, Codes, distributed computing experimentation library, Experiment-driven research, Libraries, Software},
	file         = {IEEE Xplore Abstract Record:/home/volodia/Zotero/storage/PPL2B4Y4/authors.html:text/html;IEEE Xplore Full Text PDF:/home/volodia/Zotero/storage/3JAH7EDG/Cherrueau et al. - 2022 - EnosLib A Library for Experiment-Driven Research .pdf:application/pdf}
}
@inproceedings{battulga_livingfog_2022,
	title        = {{LivingFog}: Leveraging fog computing and {LoRaWAN} technologies for smart marina management (experience paper)},
	shorttitle   = {{LivingFog}},
	author       = {Battulga, Davaadorj and Farhadi, Mozhdeh and Tamiru, Mulugeta Ayalew and Wu, Li and Pierre, Guillaume},
	booktitle    = {2022 25th Conference on Innovation in Clouds, Internet and Networks ({ICIN})},
	location     = {Paris, France},
	publisher    = {{IEEE}},
	pages        = {9--16},
	doi          = {10.1109/ICIN53892.2022.9758124},
	isbn         = {978-1-72818-688-7},
	url          = {https://ieeexplore.ieee.org/document/9758124/},
	urldate      = {2022-05-30},
	abstract     = {In recent years, fog computing has emerged as a paradigm that brings computing, storage and networking resources closer to end users and devices at the edge of the network. One of the use cases for fog computing is {IoT}, where a large amount of data is generated by sensors that need to be pre-processed in place before the results are sent to the cloud for further processing and long-term storage. However, actual fog deployments are at their infancy. In this paper, we present the smart-marina project at La Marina de Valencia in which the {LivingFog} fog computing platform integrating opensource software and {LoRaWAN} technologies were used to process data collected from several sensors. We show the benefits of the platform in terms of latency reduction and bandwidth saving. Moreover, the platform has been used by particpants of the ``Hack the fog'' hackathon to deploy applications to test different innovative ideas on using the sensor data.},
	eventtitle   = {2022 25th Conference on Innovation in Clouds, Internet and Networks and Workshops ({ICIN})},
	date         = {2022-03-07},
	langid       = {english},
	file         = {Battulga et al. - 2022 - LivingFog Leveraging fog computing and LoRaWAN te.pdf:/home/volodia/Zotero/storage/WU9LIJ54/Battulga et al. - 2022 - LivingFog Leveraging fog computing and LoRaWAN te.pdf:application/pdf}
}
@inproceedings{bouizem_active-standby_2020,
	title        = {Active-Standby for High-Availability in {FaaS}},
	author       = {Bouizem, Yasmina and Parlavantzas, Nikos and Dib, Djawida and Morin, Christine},
	booktitle    = {Proceedings of the 2020 Sixth International Workshop on Serverless Computing},
	location     = {New York, {NY}, {USA}},
	publisher    = {Association for Computing Machinery},
	series       = {{WoSC}'20},
	pages        = {31--36},
	doi          = {10.1145/3429880.3430097},
	isbn         = {978-1-4503-8204-5},
	url          = {https://doi.org/10.1145/3429880.3430097},
	urldate      = {2022-05-31},
	abstract     = {Serverless computing is becoming more and more attractive for cloud solution architects and developers. This new computing paradigm relies on Function-as-a-Service ({FaaS}) platforms that enable deploying functions without being concerned with the underlying infrastructure. An important challenge in designing {FaaS} platforms is ensuring the availability of deployed functions. Existing {FaaS} platforms address this challenge principally through retrying function executions. In this paper, we propose and implement an alternative fault-tolerance approach based on active-standby failover. Results from an experimental evaluation show that our approach increases availability and performance compared to the retry-based approach.},
	date         = {2020-12-07},
	keywords     = {{FaaS}, availability, fault tolerance},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/8ZYSATRZ/Bouizem et al. - 2020 - Active-Standby for High-Availability in FaaS.pdf:application/pdf}
}
@inproceedings{costache_economic_2012,
	title        = {An Economic Approach for Application {QoS} Management in Clouds},
	author       = {Costache, Stefania and Parlavantzas, Nikos and Morin, Christine and Kortas, Samuel},
	booktitle    = {Euro-Par 2011: Parallel Processing Workshops},
	location     = {Berlin, Heidelberg},
	publisher    = {Springer},
	series       = {Lecture Notes in Computer Science},
	pages        = {426--435},
	doi          = {10.1007/978-3-642-29740-3\_48},
	isbn         = {978-3-642-29740-3},
	abstract     = {Virtualization provides increased control and flexibility in how resources are allocated to applications. However, common resource provisioning mechanisms do not fully use these advantages; either they provide limited support for applications demanding quality of service, or the resource allocation complexity is high. To address this problem we propose a novel resource management architecture for virtualized infrastructures based on a virtual economy. By limiting the coupling between the applications and the resource management, this architecture can support diverse types of applications and performance goals while ensuring an efficient resource usage. We validate its use through simple policies that scale the resource allocations of the applications vertically and horizontally to meet application performance goals.},
	editor       = {Alexander, Michael and D'Ambra, Pasqua and Belloum, Adam and Bosilca, George and Cannataro, Mario and Danelutto, Marco and Di Martino, Beniamino and Gerndt, Michael and Jeannot, Emmanuel and Namyst, Raymond and Roman, Jean and Scott, Stephen L. and Traff, Jesper Larsson and Vall\'{e}e, Geoffroy and Weidendorfer, Josef},
	date         = 2012,
	langid       = {english},
	keywords     = {Cloud Infrastructure, Performance Goal, Resource Management System, Schedule Period, Virtual Machine},
	file         = {Full Text PDF:/home/volodia/Zotero/storage/6GZ3894M/Costache et al. - 2012 - An Economic Approach for Application QoS Managemen.pdf:application/pdf}
}
@article{costache_resource_2017,
	title        = {Resource management in cloud platform as a service systems: Analysis and opportunities},
	shorttitle   = {Resource management in cloud platform as a service systems},
	author       = {Costache, Stefania and Dib, Djawida and Parlavantzas, Nikos and Morin, Christine},
	volume       = 132,
	pages        = {98--118},
	doi          = {10.1016/j.jss.2017.05.035},
	issn         = {0164-1212},
	url          = {https://www.sciencedirect.com/science/article/pii/S0164121217300845},
	urldate      = {2022-05-31},
	abstract     = {Platform-as-a-Service ({PaaS}) clouds offer services to automate the deployment and management of applications, relieving application owners of the complexity of managing the underlying infrastructure resources. However, application owners have an increasingly larger diversity and volume of workloads, which they want to execute at minimum cost while maintaining desired performance guarantees. In this paper we investigate how existing {PaaS} systems cope with this challenge. In particular, we first present a taxonomy of commonly-encountered design decisions regarding how {PaaS} systems manage underlying resources. We then use this taxonomy to analyze an extensive set of {PaaS} systems targeting different application domains. Based on this analysis, we identify several future research opportunities in the {PaaS} design space, which will enable {PaaS} owners to reduce hosting costs while coping with the workload variety.},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	date         = {2017-10-01},
	langid       = {english},
	keywords     = {Cloud computing, Resource management, Platform-as-a-service},
	file         = {ScienceDirect Snapshot:/home/volodia/Zotero/storage/PF2NDB5W/S0164121217300845.html:text/html}
}
@report{longuevergne_terra_2022,
	title        = {{TERRA} {FORMA}: Developing the observation platform of the Anthropocene\&nbsp;},
	shorttitle   = {{TERRA} {FORMA}},
	author       = {Longuevergne, Laurent and Elger, Arnaud and Girard, Virginie},
	number       = {{EGU}22-13559},
	doi          = {10.5194/egusphere-egu22-13559},
	url          = {https://meetingorganizer.copernicus.org/EGU22/EGU22-13559.html},
	urldate      = {2022-06-03},
	note         = {Conference Name: {EGU}22},
	institution  = {Copernicus Meetings},
	date         = {2022-03-25},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/XY8DYCKQ/EGU22-13559.html:text/html}
}
@misc{kuo_proportionnet_2020,
	title        = {{ProportionNet}: Balancing Fairness and Revenue for Auction Design with Deep Learning},
	shorttitle   = {{ProportionNet}},
	author       = {Kuo, Kevin and Ostuni, Anthony and Horishny, Elizabeth and Curry, Michael J. and Dooley, Samuel and Chiang, Ping-yeh and Goldstein, Tom and Dickerson, John P.},
	publisher    = {{arXiv}},
	url          = {http://arxiv.org/abs/2010.06398},
	urldate      = {2022-06-07},
	note         = {Number: {arXiv}:2010.06398},
	abstract     = {The design of revenue-maximizing auctions with strong incentive guarantees is a core concern of economic theory. Computational auctions enable online advertising, sourcing, spectrum allocation, and myriad financial markets. Analytic progress in this space is notoriously difficult; since Myerson's 1981 work characterizing single-item ``optimal'' auctions, there has been limited progress outside of restricted settings. A recent paper by D\"{u}tting et al. circumvents analytic difficulties by applying deep learning techniques to, instead, approximate optimal auctions. In parallel, new research from Ilvento et al. and other groups has developed notions of fairness in the context of auction design. Inspired by these advances, in this paper, we extend techniques for approximating auctions using deep learning to address concerns of fairness while maintaining high revenue and strong incentive guarantees.},
	date         = {2020-10-13},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2010.06398 [cs]},
	keywords     = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
	file         = {Kuo et al. - 2020 - ProportionNet Balancing Fairness and Revenue for .pdf:/home/volodia/Zotero/storage/P3YD5AWN/Kuo et al. - 2020 - ProportionNet Balancing Fairness and Revenue for .pdf:application/pdf}
}
@online{fiware_foundation_fiware_2021,
	title        = {{FIWARE} - Open {APIs} for Open Minds},
	author       = {{Fiware foundation}},
	url          = {https://www.fiware.org/},
	urldate      = {2022-06-07},
	note         = {Running Time: 227},
	abstract     = {A curated framework of Open Source Platform components to accelerate the development of Smart Solutions.},
	date         = {2021-02-02},
	langid       = {american},
	file         = {Snapshot:/home/volodia/Zotero/storage/KKKUZND6/www.fiware.org.html:text/html}
}
@online{prometheus_authors_prometheus_nodate,
	title        = {Prometheus - Monitoring system \& time series database},
	author       = {{Prometheus Authors}},
	url          = {https://prometheus.io/},
	urldate      = {2022-06-07},
	abstract     = {An open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.},
	langid       = {english},
	file         = {Snapshot:/home/volodia/Zotero/storage/DRF5FS5H/prometheus.io.html:text/html}
}
@online{benitez_rocket_2022,
	title        = {rocket - crates.io: Rust Package Registry},
	author       = {Benitez, Sergio},
	url          = {https://crates.io/crates/rocket},
	urldate      = {2022-06-07},
	date         = 2022,
	file         = {rocket - crates.io\: Rust Package Registry:/home/volodia/Zotero/storage/LAD9J6G8/rocket.html:text/html}
}
@online{sully_rocket_prometheus_2022,
	title        = {rocket\_prometheus - crates.io: Rust Package Registry},
	author       = {Sully, Ben},
	url          = {https://crates.io/crates/rocket\%5Fprometheus},
	urldate      = {2022-06-07},
	date         = 2022
}
